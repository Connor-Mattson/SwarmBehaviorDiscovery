{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# View Clusters and Simulate Behaviors\n",
    "Based on provided behavior and controller files in the pheno_home and geno_home variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from NovelSwarmBehavior.novel_swarms.behavior.AngularMomentum import AngularMomentumBehavior\n",
    "from NovelSwarmBehavior.novel_swarms.behavior.AverageSpeed import AverageSpeedBehavior\n",
    "from NovelSwarmBehavior.novel_swarms.behavior.GroupRotationBehavior import GroupRotationBehavior\n",
    "from NovelSwarmBehavior.novel_swarms.behavior.RadialVariance import RadialVarianceBehavior\n",
    "from NovelSwarmBehavior.novel_swarms.behavior.ScatterBehavior import ScatterBehavior\n",
    "from NovelSwarmBehavior.novel_swarms.behavior.SensorOffset import GeneElementDifference\n",
    "from NovelSwarmBehavior.novel_swarms.config.AgentConfig import DiffDriveAgentConfig\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.BehaviorDiscovery import BehaviorDiscovery\n",
    "from NovelSwarmBehavior.novel_swarms.config.EvolutionaryConfig import GeneticEvolutionConfig\n",
    "from NovelSwarmBehavior.novel_swarms.config.WorldConfig import RectangularWorldConfig\n",
    "from NovelSwarmBehavior.novel_swarms.config.defaults import ConfigurationDefaults\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.GeneRule import GeneRule\n",
    "from NovelSwarmBehavior.novel_swarms.config.OutputTensorConfig import OutputTensorConfig\n",
    "from NovelSwarmBehavior.novel_swarms.sensors.BinaryLOSSensor import BinaryLOSSensor\n",
    "from NovelSwarmBehavior.novel_swarms.sensors.GenomeDependentSensor import GenomeBinarySensor\n",
    "from NovelSwarmBehavior.novel_swarms.sensors.SensorSet import SensorSet\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.NoveltyArchive import NoveltyArchive\n",
    "from NovelSwarmBehavior.novel_swarms.results.results import main as report\n",
    "import os\n",
    "import numpy as np\n",
    "from ui.clustering_gui import ClusteringGUI\n",
    "\n",
    "agent_config = ConfigurationDefaults.FOV_DIFF_DRIVE_AGENT\n",
    "world_config = ConfigurationDefaults.RECTANGULAR_WORLD\n",
    "world_config.addAgentConfig(agent_config)\n",
    "\n",
    "# Load the files into a novelty archive\n",
    "# Evolutionary archives are saved to files if GeneticEvolutionConfig.save_archive\n",
    "#   is set to True. Files can be found in /out,\n",
    "\n",
    "##################################################\n",
    "# Augmented Genome on Base Behavior Vector\n",
    "##################################################\n",
    "# pheno_home = \"/home/connor/Desktop/AAMAS/Baseline/AugmentedTests/B_normal_Vector_100g/behaviors_through_time\"\n",
    "# geno_home = \"/home/connor/Desktop/AAMAS/Baseline/AugmentedTests/B_normal_Vector_100g/controllers_through_time\"\n",
    "#\n",
    "pheno_files = [\n",
    "    \"b_1671210866_5_1671211187.csv\",\n",
    "    \"b_1671210866_6_1671211187.csv\",\n",
    "    \"b_1671210866_7_1671211187.csv\",\n",
    "    \"b_1671210866_8_1671211187.csv\",\n",
    "    \"b_1671210866_9_1671211187.csv\",\n",
    "    \"b_1671210866_10_1671211187.csv\",\n",
    "    \"b_1671210866_11_1671211187.csv\",\n",
    "    \"b_1671210866_12_1671211187.csv\",\n",
    "    \"b_1671210866_13_1671211187.csv\",\n",
    "    \"b_1671210866_14_1671211187.csv\",\n",
    "]\n",
    "\n",
    "geno_files = [\n",
    "    \"g_1671210866_5_1671211187.csv\",\n",
    "    \"g_1671210866_6_1671211187.csv\",\n",
    "    \"g_1671210866_7_1671211187.csv\",\n",
    "    \"g_1671210866_8_1671211187.csv\",\n",
    "    \"g_1671210866_9_1671211187.csv\",\n",
    "    \"g_1671210866_10_1671211187.csv\",\n",
    "    \"g_1671210866_11_1671211187.csv\",\n",
    "    \"g_1671210866_12_1671211187.csv\",\n",
    "    \"g_1671210866_13_1671211187.csv\",\n",
    "    \"g_1671210866_14_1671211187.csv\",\n",
    "]\n",
    "\n",
    "pheno_home = \"/home/connor/Desktop/Experiments/Final6960Project/augmented_brown/behaviors\"\n",
    "geno_home = \"/home/connor/Desktop/Experiments/Final6960Project/augmented_brown/controllers\"\n",
    "\n",
    "\n",
    "for i, file_name in enumerate(pheno_files):\n",
    "\n",
    "    print(\"RESULTS AT \", i)\n",
    "\n",
    "    archive = NoveltyArchive(\n",
    "        pheno_file=os.path.join(pheno_home, file_name),\n",
    "        geno_file=os.path.join(geno_home, geno_files[i]),\n",
    "        absolute=True\n",
    "    )\n",
    "\n",
    "    sensors = SensorSet([\n",
    "        GenomeBinarySensor(genome_id=8),\n",
    "        GenomeBinarySensor(genome_id=9)\n",
    "    ])\n",
    "\n",
    "    agent_config = DiffDriveAgentConfig(\n",
    "        sensors=sensors,\n",
    "        seed=None,\n",
    "    )\n",
    "\n",
    "    genotype = [\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=((1/3) * np.pi), _min=-((2/3) * np.pi), mutation_step=(np.pi/2), round_digits=4),\n",
    "        GeneRule(_max=((2/3) * np.pi), _min=-((1/3) * np.pi), mutation_step=(np.pi/2), round_digits=4),\n",
    "    ]\n",
    "\n",
    "    phenotype = [\n",
    "        AverageSpeedBehavior(),\n",
    "        AngularMomentumBehavior(),\n",
    "        RadialVarianceBehavior(),\n",
    "        ScatterBehavior(),\n",
    "        GroupRotationBehavior()\n",
    "    ]\n",
    "\n",
    "    world_config = RectangularWorldConfig(\n",
    "        size=(500, 500),\n",
    "        n_agents=24,\n",
    "        seed=None,\n",
    "        behavior=phenotype,\n",
    "        agentConfig=agent_config,\n",
    "        padding=15\n",
    "    )\n",
    "\n",
    "    novelty_config = GeneticEvolutionConfig(\n",
    "        gene_rules=genotype,\n",
    "        phenotype_config=phenotype,\n",
    "        n_generations=100,\n",
    "        n_population=100,\n",
    "        crossover_rate=0.7,\n",
    "        mutation_rate=0.15,\n",
    "        world_config=world_config,\n",
    "        k_nn=15,\n",
    "        simulation_lifespan=600,\n",
    "        display_novelty=True,\n",
    "        save_archive=True,\n",
    "        show_gui=True,\n",
    "    )\n",
    "\n",
    "    results_config = ConfigurationDefaults.RESULTS\n",
    "    results_config.world = world_config\n",
    "    results_config.archive = archive\n",
    "    results_config.k = 10\n",
    "\n",
    "    # Cluster and Explore Reduced Behavior Space\n",
    "    gui = ClusteringGUI(config=results_config, cluster_after=False)\n",
    "    gui.displayGUI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pygame\n",
    "pygame.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Disagreement in Ensamble - Baseline Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "networkA = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkA.load_model(\"two_sensor_subz1\")\n",
    "networkA.eval()\n",
    "\n",
    "networkB = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkB.load_model(\"two_sensor_nov_4\")\n",
    "networkB.eval()\n",
    "\n",
    "networkC = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkC.load_model(\"two_sensors_r15_final\")\n",
    "networkC.eval()\n",
    "\n",
    "def batch_eval_network(network, anchor_images, pos_images, neg_images):\n",
    "    loss_fn = torch.nn.TripletMarginLoss(margin=15)\n",
    "    anchor_out, pos_out, neg_out = network.batch_network_from_numpy(anchor_images, pos_images, neg_images)\n",
    "    loss = loss_fn(anchor_out, pos_out, neg_out)\n",
    "    return loss\n",
    "\n",
    "def biased_log(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    return np.log(x)\n",
    "\n",
    "def trip_eq(a, b, c):\n",
    "    return a == b and b == c and a == c\n",
    "\n",
    "def getDisagreement(anchor, negative):\n",
    "    pos_images = np.stack([\n",
    "        # [ndimage.rotate(anchor, 90)],\n",
    "        # [ndimage.rotate(anchor, 180)],\n",
    "        # [ndimage.rotate(anchor, 270)],\n",
    "        [ndimage.gaussian_filter(anchor, 1)],\n",
    "        [ndimage.gaussian_filter(anchor, 3)],\n",
    "        [ndimage.gaussian_filter(anchor, 5)],\n",
    "    ])\n",
    "\n",
    "    anchor_images = np.stack([[anchor] for _ in pos_images])\n",
    "    neg_images = np.stack([[negative] for _ in pos_images])\n",
    "\n",
    "    lossA = batch_eval_network(networkA, anchor_images, pos_images, neg_images)\n",
    "    lossA = lossA.detach().cpu()\n",
    "\n",
    "    lossB = batch_eval_network(networkB, anchor_images, pos_images, neg_images)\n",
    "    lossB = lossB.detach().cpu()\n",
    "\n",
    "    lossC = batch_eval_network(networkC, anchor_images, pos_images, neg_images)\n",
    "    lossC = lossC.detach().cpu()\n",
    "\n",
    "    return lossA, lossB, lossC\n",
    "    # return (lossA * biased_log(lossA)) + (lossB * biased_log(lossB)) + (lossC * biased_log(lossC)), (lossA, lossB, lossC)\n",
    "\n",
    "sampled_dataset = SwarmDataset(\"data/full-dual-sensors\", rank=0)\n",
    "\n",
    "disagreements = []\n",
    "total_disagreements = 0\n",
    "# for i in range(len(sampled_dataset)):\n",
    "#     for j in range(i, len(sampled_dataset)):\n",
    "\n",
    "for i in range(500):\n",
    "    for j in range(i, i + 5):\n",
    "        print(f\"Sampling Anchors from {i}-{j}\")\n",
    "        anchor = sampled_dataset[i][0]\n",
    "        negative = sampled_dataset[j][0]\n",
    "\n",
    "        lA, lB, lC = getDisagreement(anchor, negative)\n",
    "        d = int(not trip_eq(lA == 0.0, lB == 0.0, lC == 0.0))\n",
    "        disagreements.append(d)\n",
    "        if d > 0:\n",
    "            total_disagreements += 1\n",
    "\n",
    "# for i in range(2500):\n",
    "#     print(f\"Sampling Anchors from {i}-blank\")\n",
    "#     anchor = sampled_dataset[i][0]\n",
    "#     negative = np.zeros((500, 500))\n",
    "#\n",
    "#     lA, lB, lC = getDisagreement(anchor, negative)\n",
    "#     d = int(not trip_eq(lA == 0.0, lB == 0.0, lC == 0.0))\n",
    "#     disagreements.append(d)\n",
    "#     if d > 0:\n",
    "#         total_disagreements += 1\n",
    "\n",
    "for i in range(len(disagreements)):\n",
    "    if disagreements[i] != 0:\n",
    "        disagreements[i] = 1\n",
    "\n",
    "print(f\"Total Disagreement: {total_disagreements}\")\n",
    "plot.bar([0, 1], [len(disagreements) - total_disagreements, total_disagreements], color=[(0,0,1), (1,0,0)])\n",
    "plot.suptitle(\"Total Agreement within Ensamble\", y=1.0, fontsize=14)\n",
    "plot.title(\"Anchor, Anchor w/ Blur, Negative\")\n",
    "plot.ylabel(\"Number of samples\")\n",
    "plot.xticks([0, 1], [\"Agree\", \"Disagree\"])\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.bar([0, 1], [len(disagreements) - total_disagreements, total_disagreements], color=[(0,0,1), (1,0,0)])\n",
    "plot.suptitle(\"Total Agreement within Ensamble\", y=1.0, fontsize=14)\n",
    "plot.title(\"Anchor, Anchor w/ Blur, Negative\")\n",
    "plot.ylabel(\"Number of samples\")\n",
    "plot.xticks([0, 1], [\"Agree\", \"Disagree\"])\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Disagreement in Ensamble - Evolved Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "networkA = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkA.load_model(\"two_sensor_subz1\")\n",
    "networkA.eval()\n",
    "\n",
    "networkB = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkB.load_model(\"two_sensor_nov_4\")\n",
    "networkB.eval()\n",
    "\n",
    "networkC = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkC.load_model(\"two_sensors_r15_final\")\n",
    "networkC.eval()\n",
    "\n",
    "parent_folder = \"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7\"\n",
    "sub_folder = \"data\"\n",
    "retrieved_data = ContinuingDataset(directory=parent_folder, create=False, folder_name=sub_folder)\n",
    "\n",
    "archive = NoveltyArchive(\n",
    "    pheno_file=os.path.join(\"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7/behaviors\", \"1667764573_b__1667801491.csv\"),\n",
    "    geno_file=os.path.join(\"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7/controllers\", \"1667764573_g__1667801491.csv\"),\n",
    "    absolute=True\n",
    ")\n",
    "\n",
    "def batch_eval_network(network, anchor_images, pos_images, neg_images):\n",
    "    loss_fn = torch.nn.TripletMarginLoss(margin=15)\n",
    "    anchor_out, pos_out, neg_out = network.batch_network_from_numpy(anchor_images, pos_images, neg_images)\n",
    "    loss = loss_fn(anchor_out, pos_out, neg_out)\n",
    "    return loss\n",
    "\n",
    "def biased_log(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    return np.log(x)\n",
    "\n",
    "def trip_eq(a, b, c):\n",
    "    return a == b and b == c and a == c\n",
    "\n",
    "def getDisagreement(anchor, negative):\n",
    "    pos_images = np.stack([\n",
    "        [ndimage.rotate(anchor, 90)],\n",
    "        [ndimage.rotate(anchor, 180)],\n",
    "        [ndimage.rotate(anchor, 270)],\n",
    "        # [ndimage.gaussian_filter(anchor, 1)],\n",
    "        # [ndimage.gaussian_filter(anchor, 3)],\n",
    "        # [ndimage.gaussian_filter(anchor, 5)],\n",
    "    ])\n",
    "\n",
    "    anchor_images = np.stack([[anchor] for _ in pos_images])\n",
    "    neg_images = np.stack([[negative] for _ in pos_images])\n",
    "\n",
    "    lossA = batch_eval_network(networkA, anchor_images, pos_images, neg_images)\n",
    "    lossA = lossA.detach().cpu()\n",
    "\n",
    "    lossB = batch_eval_network(networkB, anchor_images, pos_images, neg_images)\n",
    "    lossB = lossB.detach().cpu()\n",
    "\n",
    "    lossC = batch_eval_network(networkC, anchor_images, pos_images, neg_images)\n",
    "    lossC = lossC.detach().cpu()\n",
    "\n",
    "    return lossA, lossB, lossC\n",
    "    # return (lossA * biased_log(lossA)) + (lossB * biased_log(lossB)) + (lossC * biased_log(lossC)), (lossA, lossB, lossC)\n",
    "\n",
    "sampled_dataset = SwarmDataset(\"data/full-dual-sensors\", rank=0)\n",
    "\n",
    "disagreements = []\n",
    "total_disagreements = 0\n",
    "# for i in range(len(sampled_dataset)):\n",
    "#     for j in range(i, len(sampled_dataset)):\n",
    "\n",
    "for i in range(500):\n",
    "    for j in range(i + 1, i + 6):\n",
    "        print(f\"Sampling Anchors from {i}-{j}\")\n",
    "        anchor = retrieved_data[i][0]\n",
    "        negative = retrieved_data[j][0]\n",
    "\n",
    "        lA, lB, lC = getDisagreement(anchor, negative)\n",
    "        d = int(not trip_eq(lA == 0.0, lB == 0.0, lC == 0.0))\n",
    "        disagreements.append(d)\n",
    "        if d > 0:\n",
    "            total_disagreements += 1\n",
    "\n",
    "for i in range(len(disagreements)):\n",
    "    if disagreements[i] != 0:\n",
    "        disagreements[i] = 1\n",
    "\n",
    "print(f\"Total Disagreement: {total_disagreements}\")\n",
    "plot.bar([0, 1], [len(disagreements)  - total_disagreements, total_disagreements], color=[(0,0,1), (1,0,0)])\n",
    "plot.suptitle(\"Total Agreement within Ensamble\", y=1.0, fontsize=14)\n",
    "plot.title(\"Evolved Visuals - Anchor, Anchor w/ Rotation, Blank Image\")\n",
    "plot.ylabel(\"Number of samples\")\n",
    "plot.xticks([0, 1], [\"Agree\", \"Disagree\"])\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Disagreement Based on Sampling from Medoids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plot\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.NoveltyArchive import NoveltyArchive\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "networkA = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkA.load_model(\"two_sensor_subz1\")\n",
    "networkA.eval()\n",
    "\n",
    "networkB = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkB.load_model(\"two_sensor_nov_4\")\n",
    "networkB.eval()\n",
    "\n",
    "networkC = NoveltyEmbedding(out_size=15).to(device)\n",
    "networkC.load_model(\"two_sensors_r15_final\")\n",
    "networkC.eval()\n",
    "\n",
    "parent_folder = \"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7\"\n",
    "sub_folder = \"data\"\n",
    "retrieved_data = ContinuingDataset(directory=parent_folder, create=False, folder_name=sub_folder)\n",
    "\n",
    "archive = NoveltyArchive(\n",
    "    pheno_file=os.path.join(\"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7/behaviors\", \"1667764573_b__1667801491.csv\"),\n",
    "    geno_file=os.path.join(\"/home/connor/Desktop/SwarmsResults/AugmentedTests/Encoder_plus_original_bvec_Nov_7/controllers\", \"1667764573_g__1667801491.csv\"),\n",
    "    absolute=True\n",
    ")\n",
    "\n",
    "def batch_eval_network(network, anchor_images, pos_images, neg_images):\n",
    "    loss_fn = torch.nn.TripletMarginLoss(margin=15)\n",
    "    anchor_out, pos_out, neg_out = network.batch_network_from_numpy(anchor_images, pos_images, neg_images)\n",
    "    loss = loss_fn(anchor_out, pos_out, neg_out)\n",
    "    return loss\n",
    "\n",
    "def biased_log(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    return np.log(x)\n",
    "\n",
    "def trip_eq(a, b, c):\n",
    "    return a == b and b == c and a == c\n",
    "\n",
    "def getDisagreement(anchor, positive, negative):\n",
    "    pos_images = np.stack([\n",
    "        [ndimage.rotate(positive, 90)],\n",
    "        [ndimage.rotate(positive, 180)],\n",
    "        [ndimage.rotate(positive, 270)],\n",
    "    ])\n",
    "\n",
    "    anchor_images = np.stack([[anchor] for _ in pos_images])\n",
    "    neg_images = np.stack([[negative] for _ in pos_images])\n",
    "\n",
    "    lossA = batch_eval_network(networkA, anchor_images, pos_images, neg_images)\n",
    "    lossA = lossA.detach().cpu()\n",
    "\n",
    "    lossB = batch_eval_network(networkB, anchor_images, pos_images, neg_images)\n",
    "    lossB = lossB.detach().cpu()\n",
    "\n",
    "    lossC = batch_eval_network(networkC, anchor_images, pos_images, neg_images)\n",
    "    lossC = lossC.detach().cpu()\n",
    "\n",
    "    return lossA, lossB, lossC\n",
    "    # return (lossA * biased_log(lossA)) + (lossB * biased_log(lossB)) + (lossC * biased_log(lossC)), (lossA, lossB, lossC)\n",
    "\n",
    "sampled_dataset = SwarmDataset(\"data/full-dual-sensors\", rank=0)\n",
    "disagreements = []\n",
    "total_disagreements = 0\n",
    "\n",
    "MIN_K, MAX_K = 6, 22\n",
    "SKIP = 1\n",
    "SELECT_CLUSTERS = 5\n",
    "SELECT_SAME = 15\n",
    "SELECT_DIFF_EACH = 3\n",
    "\n",
    "for k in range(MIN_K, MAX_K, SKIP):\n",
    "    print(f\"Pre-Computing for {k}...\")\n",
    "    total = 0\n",
    "    k_disagreement_cnt = 0\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=0).fit(archive.archive)\n",
    "    medoids = kmedoids.medoid_indices_\n",
    "    labels = kmedoids.labels_\n",
    "    clusters = { l : [] for l in range(k)}\n",
    "    nn = {l : None for l in range(k)}\n",
    "\n",
    "    # Sort the labels into clusters ahead of time - O(n)\n",
    "    for i, label in enumerate(labels):\n",
    "        clusters[label].append(i)\n",
    "\n",
    "    # Initialize the nearest neighbors scheme for each cluster\n",
    "    # for i in range(k):\n",
    "    #     NEAREST = 1\n",
    "    #     pool = [archive.archive[j] for j in clusters[i]]\n",
    "    #     nn[i] = NearestNeighbors(n_neighbors=NEAREST, algorithm='ball_tree').fit(pool)\n",
    "\n",
    "    print(f\"Sampling for {k}...\")\n",
    "    for i in np.random.choice([p for p in range(k)], SELECT_CLUSTERS, replace=False):\n",
    "        medoid = medoids[i]\n",
    "        anchor = retrieved_data[medoid][0]\n",
    "        # for m in range(k):\n",
    "        #     if m != i:\n",
    "        #         # Select the element of the cluster that is closest to the medoid of the cluster in question.\n",
    "        #         negative = archive.archive[medoids[m]]\n",
    "        #         nearest_neighbor = nn[i].kneighbors(negative)[0]\n",
    "        #         index = -1\n",
    "        #         for s in clusters[i]:\n",
    "        #             if archive.archive[s] == nearest_neighbor:\n",
    "        #                 index = s\n",
    "        #                 break\n",
    "\n",
    "\n",
    "        for j in np.random.choice(clusters[i], min(SELECT_SAME, len(clusters[i])), replace=False):\n",
    "            positive = retrieved_data[j][0]\n",
    "            counter = 0\n",
    "            for m in np.random.choice([p for p in range(k)], SELECT_CLUSTERS + 1, replace=False):\n",
    "                counter += 1\n",
    "                if m != i and counter != SELECT_CLUSTERS:\n",
    "                    print(f\"Anchor {medoid} - Positive {j} - Negative Cluster {m}\")\n",
    "                    for n in np.random.choice(clusters[m], min(SELECT_DIFF_EACH, len(clusters[m])), replace=False):\n",
    "                        if n >= len(sampled_dataset):\n",
    "                            continue\n",
    "                        negative = retrieved_data[n][0]\n",
    "                        lA, lB, lC = getDisagreement(anchor, positive, negative)\n",
    "                        d = int(lA > 0.0) + int(lB > 0.0) + int(lC > 0.0)\n",
    "                        total += 1\n",
    "                        if d >= 3:\n",
    "                            k_disagreement_cnt += 1\n",
    "\n",
    "    disagreements.append(k_disagreement_cnt * 100 / total)\n",
    "    print(f\"Total Disagreement for k={k}: {k_disagreement_cnt}\")\n",
    "\n",
    "\n",
    "plot.bar([i for i in range(MIN_K, MAX_K, SKIP)], disagreements, color=(1, 0, 0))\n",
    "plot.title(\"Ensamble Alignment for kMedoids\")\n",
    "plot.ylabel(\"% Disagreement\")\n",
    "plot.xticks([i for i in range(MIN_K, MAX_K, SKIP)], [f\"k={i}\" for i in range(MIN_K, MAX_K, SKIP)])\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.bar([i for i in range(MIN_K, MAX_K)], disagreements, color=(1, 0, 0))\n",
    "plot.title(\"Ensamble Alignment with kMedoids\")\n",
    "plot.ylabel(\"% Disagreement between Ensamble and kMedoids\")\n",
    "plot.xlabel(\"k\")\n",
    "plot.xticks([i for i in range(MIN_K, MAX_K)], [f\"{i}\" for i in range(MIN_K, MAX_K)])\n",
    "plot.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base= [4,4,4,4,3,4,3,5,4,5,4,5,6,5]\n",
    "new = [4,5,4,4,5,6,4,3,5,6,5,3,4,5]\n",
    "\n",
    "print(sum(base)/len(base))\n",
    "print(sum(new)/len(new))\n",
    "\n",
    "plt.bar([0, 1], [sum(base)/len(base), sum(new)/len(new)], color=[(0.6, 0.6, 0.6),(0, 0, 1)])\n",
    "plt.xticks([0, 1], [\"Brown et al.\", \"Latent Learning\"])\n",
    "plt.ylabel(\"Average Emergent Behaviors Discovered\")\n",
    "plt.ylim(0, 6.5)\n",
    "plt.show()\n",
    "\n",
    "plt.bar([i for i in range(1, len(new) + 1)], new, color=(0, 0, 1), label=\"Latent Learning\")\n",
    "plt.xlabel(\"Generations of Novelty Search\")\n",
    "plt.ylabel(\"Emergent Behaviors Discovered\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar([i for i in range(1, len(new) + 1)], base, color=(0.6, 0.6, 0.6), label=\"Brown et al.\")\n",
    "plt.xlabel(\"Generations of Novelty Search\")\n",
    "plt.ylabel(\"Emergent Behaviors Discovered\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
