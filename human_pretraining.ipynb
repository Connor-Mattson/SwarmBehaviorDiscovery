{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Build Human Created Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pygame\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from scipy import ndimage\n",
    "\n",
    "def resizeInput(X, w=200):\n",
    "    frame = X.astype(np.uint8)\n",
    "    resized = cv2.resize(frame, dsize=(w, w), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def translate(img, offset=(10, 10)):\n",
    "    h, w = img.shape\n",
    "    xoff, yoff = offset\n",
    "    if xoff < 0: xpadding = (0, -xoff)\n",
    "    else: xpadding = (xoff, 0)\n",
    "    if yoff < 0: ypadding = (0, -yoff)\n",
    "    else: ypadding = (yoff, 0)\n",
    "    img = np.pad(img, (xpadding, ypadding))\n",
    "\n",
    "    if xoff >= 0 and yoff >= 0:\n",
    "        return img[:w, :w]\n",
    "    elif xoff < 0 and yoff >= 0:\n",
    "        return img[-w:, :w]\n",
    "    elif xoff >= 0 and yoff < 0:\n",
    "        return img[:w, -w:]\n",
    "    return img[-w:, -w:]\n",
    "\n",
    "def zoom_at(img, zoom, coord=None):\n",
    "    # Adapted from https://stackoverflow.com/questions/69050464/zoom-into-image-with-opencv\n",
    "    h, w = [ zoom * i for i in img.shape ]\n",
    "    if coord is None: cx, cy = w/2, h/2\n",
    "    else: cx, cy = [ zoom*c for c in coord ]\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[ int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "               int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "def getRotation(image, index=None):\n",
    "    angles = [30 * i for i in range(1, 12)]\n",
    "    if index:\n",
    "        theta = angles[index]\n",
    "    else:\n",
    "        theta = random.choice(angles)\n",
    "    rot = ndimage.rotate(image, theta)\n",
    "    return resizeInput(rot, 50)\n",
    "\n",
    "def getBlur(image, index=None):\n",
    "    blurs = [0.5, 1.0, 1.5]\n",
    "    if index:\n",
    "        blur = blurs[index]\n",
    "    else:\n",
    "        blur = random.choice(blurs)\n",
    "    return ndimage.gaussian_filter(image, sigma=blur)\n",
    "\n",
    "def getZoomOut(image, index=None):\n",
    "    paddings = [10, 20, 30]\n",
    "    if index:\n",
    "        padding = paddings[index]\n",
    "    else:\n",
    "        padding = random.choice(paddings)\n",
    "    padded = np.pad(image, padding, mode='constant')\n",
    "    return resizeInput(padded, 50)\n",
    "\n",
    "def getRandomTransformation(image):\n",
    "    transformation_choices = [\"Rotation\", \"Blur\", \"Zoom\", \"Translate\"]\n",
    "    weights = [0.4, 0.3, 0.0, 0.3]\n",
    "    # weights = [1.0, 0.0, 0.0, 0.0]\n",
    "    choice = random.choices(transformation_choices, weights, k=1)[0]\n",
    "    if choice == \"Rotation\":\n",
    "        theta = random.choice([30 * i for i in range(1, 12)])\n",
    "        rot = ndimage.rotate(image, theta)\n",
    "        rot = resizeInput(rot, 50)\n",
    "        return rot\n",
    "    elif choice == \"Blur\":\n",
    "        blur = random.choice([0.5, 1.0, 1.5])\n",
    "        return ndimage.gaussian_filter(image, sigma=blur)\n",
    "    elif choice == \"Zoom\":\n",
    "        # zoom = random.choice([1.06, 1.12, 1.18])\n",
    "        padding = random.choice([10])\n",
    "        padded = np.pad(image, padding, mode='constant')\n",
    "        return resizeInput(padded, 50)\n",
    "    elif choice == \"Translate\":\n",
    "        # offsets = [i for i in range(-10, 10, 2)]\n",
    "        # offset = (random.choice(offsets), random.choice(offsets))\n",
    "        offset = (2, 2)\n",
    "        return translate(image, offset)\n",
    "\n",
    "def rand_shape(scr, index=None):\n",
    "    scr.fill((0, 0, 0))\n",
    "    AGENTS = 24\n",
    "    choices = [\"Cir\", \"Tri\", \"Sqr\", \"Ellipse\", \"Random-Dots\", \"Random-Arcs\", \"Dispersal\", \"Aggregation\"]\n",
    "    classes = [0, 1, 2, 3, 4, 4, 5, 6]\n",
    "    if index is not None:\n",
    "        choice = choices[index]\n",
    "    else:\n",
    "        choice = random.choice(choices)\n",
    "\n",
    "    if choice == \"Cir\":\n",
    "        r = 100\n",
    "        pygame.draw.circle(screen, (255, 255, 255), (200, 200), r, 3)\n",
    "    elif choice == \"Tri\":\n",
    "        pygame.draw.polygon(screen, (255, 255, 255), [[250, 20], [20, 480], [480, 480]], 3)\n",
    "    elif choice == \"Sqr\":\n",
    "        rect = pygame.Rect(100, 100, 300, 300)\n",
    "        pygame.draw.rect(scr, (255, 255, 255), rect, 3)\n",
    "    elif choice == \"Ellipse\":\n",
    "        rect = pygame.Rect(100, 150, 300, 200)\n",
    "        pygame.draw.ellipse(scr, (255, 255, 255), rect, 3)\n",
    "    elif choice == \"Random-Dots\":\n",
    "        for i in range(AGENTS):\n",
    "            x, y = random.randint(10, 490), random.randint(10, 490)\n",
    "            r = 10\n",
    "            pygame.draw.circle(screen, (255, 255, 255), [x, y], r, 0)\n",
    "    elif choice == \"Random-Arcs\":\n",
    "        for i in range(AGENTS):\n",
    "            x, y = random.randint(10, 490), random.randint(10, 490)\n",
    "            rect = pygame.Rect(x, y, 75, 75)\n",
    "            start_angle = random.random() * np.pi * 2\n",
    "            end_angle = start_angle + (2 * np.pi / 3)\n",
    "            pygame.draw.arc(screen, (255, 255, 255), rect, start_angle, end_angle, 3)\n",
    "    elif choice == \"Dispersal\":\n",
    "        for i in range(AGENTS):\n",
    "            x, y = random.choice([(random.choice([15, 485]), random.randint(15, 485)), (random.randint(15, 485), random.choice([15, 485]))])\n",
    "            r = 17\n",
    "            pygame.draw.circle(screen, (255, 255, 255), [x, y], r, 3)\n",
    "    elif choice == \"Aggregation\":\n",
    "        for i in range(AGENTS):\n",
    "            x, y = (random.randint(175, 225), random.randint(175, 225))\n",
    "            r = 25\n",
    "            pygame.draw.circle(screen, (255, 255, 255), [x, y], r, 3)\n",
    "    else:\n",
    "        raise Exception(\"Bad Shape!\")\n",
    "\n",
    "    pygame.display.flip()\n",
    "    out = pygame.surfarray.array2d(scr)\n",
    "    _class = classes[choices.index(choice)]\n",
    "    return resizeInput(out, 50), _class\n",
    "\n",
    "SAMPLES = 8\n",
    "NUM_CREATIONS = 8\n",
    "pygame.init()\n",
    "pygame.display.set_caption(\"Evolutionary Novelty Search\")\n",
    "screen = pygame.display.set_mode((500, 500))\n",
    "\n",
    "dataset = SwarmDataset(\"data/human-mini\")\n",
    "\n",
    "import time\n",
    "\n",
    "#Generate \"Of interest\" First\n",
    "for i in range(SAMPLES):\n",
    "    if i == 4 or i == 5: continue\n",
    "    original, shape = rand_shape(screen, index=i)\n",
    "    dataset.new_sample(original, [shape], [shape])\n",
    "    for j in range(11):\n",
    "        newA, _ = rand_shape(screen, index=i)\n",
    "        rot = getRotation(newA, index=j)\n",
    "    for j in range(3):\n",
    "        newB, _ = rand_shape(screen, index=i)\n",
    "        newC, _ = rand_shape(screen, index=i)\n",
    "        blurred = getBlur(newB, index=j)\n",
    "        z_out = getZoomOut(newC, index=j)\n",
    "        dataset.new_sample(original, [shape], [shape])\n",
    "        dataset.new_sample(blurred, [shape], [shape])\n",
    "        dataset.new_sample(z_out, [shape], [shape])\n",
    "    for j in range(-8, 9, 4):\n",
    "        for k in range(-8, 9, 4):\n",
    "            if j == 0 and k == 0: continue\n",
    "            new, _ = rand_shape(screen, index=i)\n",
    "            translation = translate(new, offset=(j, k))\n",
    "            dataset.new_sample(translation, [shape], [shape])\n",
    "\n",
    "    print(f\"{i} - {(i*100) / SAMPLES}% Complete\")\n",
    "\n",
    "# Generate \"Out of Interest\" Next\n",
    "for i in range(SAMPLES):\n",
    "    original, shape = rand_shape(screen, index=(4 if i % 2 == 0 else 5))\n",
    "    # original, shape = rand_shape(screen, index=5)\n",
    "    dataset.new_sample(original, [shape], [shape])\n",
    "    for j in range(11):\n",
    "        newA, _ = rand_shape(screen, index=i)\n",
    "        rot = getRotation(newA, index=j)\n",
    "    for j in range(3):\n",
    "        newB, _ = rand_shape(screen, index=i)\n",
    "        newC, _ = rand_shape(screen, index=i)\n",
    "        blurred = getBlur(newB, index=j)\n",
    "        z_out = getZoomOut(newC, index=j)\n",
    "        dataset.new_sample(original, [shape], [shape])\n",
    "        dataset.new_sample(blurred, [shape], [shape])\n",
    "        dataset.new_sample(z_out, [shape], [shape])\n",
    "    for j in range(-8, 9, 4):\n",
    "        for k in range(-8, 9, 4):\n",
    "            if j == 0 and k == 0: continue\n",
    "            new, _ = rand_shape(screen, index=i)\n",
    "            translation = translate(new, offset=(j, k))\n",
    "            dataset.new_sample(translation, [shape], [shape])\n",
    "\n",
    "    print(f\"{i} - {(i*100) / SAMPLES}% Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretraining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "\n",
    "PRETRAINING = True\n",
    "target = 0.0005\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr_series=[30e-4, 30e-4, 30e-4], learning_decay=0.9, decay_step=4, threshold=9.0, weight_decay=1e-4, new_model=True)\n",
    "ensemble.load_ensemble(\"human-mini-E\")\n",
    "sampled_dataset = SwarmDataset(\"data/human-mini\", rank=0)\n",
    "\n",
    "class_distinction = {i:[] for i in range(7)}\n",
    "for i in range(len(sampled_dataset)):\n",
    "    _class = sampled_dataset[i][1][0]\n",
    "    class_distinction[_class].append(i)\n",
    "\n",
    "triplets = []\n",
    "\n",
    "RAND_CLASS = 4\n",
    "for j in range(len(class_distinction[RAND_CLASS])):\n",
    "    anchor = class_distinction[RAND_CLASS][j]\n",
    "    for k in range(3): # Select 3 positive examples and move on\n",
    "        k = random.randint(j, len(class_distinction[RAND_CLASS]) - 1)\n",
    "        pos = class_distinction[RAND_CLASS][k]\n",
    "        for l in range(len(class_distinction)):\n",
    "            if l == j: continue\n",
    "            if not class_distinction[l]: continue\n",
    "            for m in range(5): # Select 3 negative examples and move on\n",
    "                m = random.randint(0, len(class_distinction[l]) - 1)\n",
    "                neg = class_distinction[l][m]\n",
    "                if not [anchor, pos, neg] in triplets:\n",
    "                    triplets.append([anchor, pos, neg])\n",
    "\n",
    "for i in class_distinction:\n",
    "    if i == RAND_CLASS: continue\n",
    "    for j in range(len(class_distinction[i])):\n",
    "        anchor = class_distinction[i][j]\n",
    "        for k in range(3): # Select 3 positive examples and move on\n",
    "            k = random.randint(j, len(class_distinction[i]) - 1)\n",
    "            pos = class_distinction[i][k]\n",
    "            for l in range(i + 1, len(class_distinction)):\n",
    "                if not class_distinction[l]: continue\n",
    "                for m in range(3): # Select 3 negative examples and move on\n",
    "                    m = random.randint(0, len(class_distinction[l]) - 1)\n",
    "                    neg = class_distinction[l][m]\n",
    "                    if not [anchor, pos, neg] in triplets:\n",
    "                        triplets.append([anchor, pos, neg])\n",
    "\n",
    "print(len(triplets))\n",
    "random.shuffle(triplets)\n",
    "triplets = triplets[:2000]\n",
    "\n",
    "def pretraining(data, ensemble, data_cutoff=None, data_size=500):\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "    total_updates = 0\n",
    "    BATCH_SIZE = 3\n",
    "\n",
    "    random.shuffle(triplets)\n",
    "    pull_set = [k for k in range(min(len(triplets), data_size))]\n",
    "    random.shuffle(pull_set)\n",
    "    for index in range(0, len(pull_set), BATCH_SIZE):\n",
    "        i = pull_set[index]\n",
    "        if total_updates % 20 == 0:\n",
    "            print(f\"Unsupervised Training.. {(total_updates * BATCH_SIZE * 100) / data_size}\")\n",
    "\n",
    "        AUGMENT_SIZE = 1\n",
    "        if i + (BATCH_SIZE * AUGMENT_SIZE) >= len(pull_set):\n",
    "            continue\n",
    "\n",
    "        temp_losses = np.array([0.0 for _ in ensemble.ensemble])\n",
    "\n",
    "        anchors = np.array([data[triplets[i + (j % AUGMENT_SIZE)][0]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        positives = np.array([data[triplets[i + (j % AUGMENT_SIZE)][1]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        negatives = np.array([data[triplets[i + (j % AUGMENT_SIZE)][2]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        temp_losses += losses\n",
    "\n",
    "        total_loss += temp_losses\n",
    "        total_updates += 1\n",
    "\n",
    "    return total_loss, total_updates\n",
    "\n",
    "t_1 = time.time()\n",
    "if PRETRAINING:\n",
    "    epochs = 0\n",
    "    loss_history = []\n",
    "    while loss > target:\n",
    "        losses, total_updates = pretraining(sampled_dataset, ensemble, data_cutoff=None, data_size=1000)\n",
    "        average_loss = losses / total_updates\n",
    "        lr = ensemble.evaluate_lr(average_loss)\n",
    "        locale_loss = sum(average_loss) / len(average_loss)\n",
    "        loss_history.append(locale_loss)\n",
    "        loss = (sum(loss_history[-3:]) / 3) if len(loss_history) > 3 else 50\n",
    "        print(f\"LR: {lr}\")\n",
    "        print(f\"Losses: {average_loss}\")\n",
    "        print(f\"Epoch {epochs}, loss: {locale_loss}, windowed_loss: {loss}\")\n",
    "        epochs += 1\n",
    "\n",
    "print(f\"Total Pre-training Time: {time.time() - t_1}\")\n",
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "classification_set = {\n",
    "    0 : [],\n",
    "    1 : [],\n",
    "    2 : []\n",
    "}\n",
    "\n",
    "PRETRAINING = True\n",
    "target = 0.01\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr_series=[15e-4, 15e-4, 15e-4], learning_decay=0.9, decay_step=4, threshold=6.0, weight_decay=1e-4)\n",
    "ensemble.load_ensemble(\"toy-surgery\")\n",
    "sampled_dataset = SwarmDataset(\"data/toy\", rank=0)\n",
    "data = sampled_dataset\n",
    "\n",
    "# Separate\n",
    "for i in range(len(sampled_dataset)):\n",
    "    _class = sampled_dataset[i][1][0]\n",
    "    classification_set[_class].append(i)\n",
    "\n",
    "# Pair Up\n",
    "SAMPLES = 3000\n",
    "triplets = []\n",
    "for i in range(SAMPLES):\n",
    "    classA = random.randint(0, 2)\n",
    "    classB = random.randint(0, 2)\n",
    "\n",
    "    anchor = random.choice(classification_set[classA])\n",
    "    positive = random.choice(classification_set[classA])\n",
    "    negative = random.choice(classification_set[classB])\n",
    "    triplet = [anchor, positive, negative]\n",
    "    if triplet not in triplets:\n",
    "        triplets.append(triplet)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 5\n",
    "EPOCH_DATA_LIM = 500\n",
    "while loss > target:\n",
    "    total_updates = 0\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "    random.shuffle(triplets)\n",
    "    temp_triplets = triplets[:EPOCH_DATA_LIM]\n",
    "    for i in range(0, len(temp_triplets), BATCH_SIZE):\n",
    "        if total_updates % 10 == 0:\n",
    "            print(f\"Unsupervised Training.. {(total_updates * BATCH_SIZE * 100) / len(temp_triplets)}\")\n",
    "\n",
    "        if i + BATCH_SIZE > len(triplets):\n",
    "            break\n",
    "\n",
    "        anchors = np.array([data[temp_triplets[i + j][0]][0] for j in range(BATCH_SIZE)])\n",
    "        positives = np.array([data[temp_triplets[i + j][1]][0] for j in range(BATCH_SIZE)])\n",
    "        negatives = np.array([data[temp_triplets[i + j][2]][0] for j in range(BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        total_loss += losses\n",
    "        total_updates += 1\n",
    "\n",
    "    l = total_loss / total_updates\n",
    "    lr = ensemble.evaluate_lr(l)\n",
    "    loss = sum(l) / len(l)\n",
    "    print(f\"Losses: {l}, LR: {lr}, Loss: {loss}\")\n",
    "\n",
    "print(\"Complete!\")\n",
    "# ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Embeddings with Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "PRETRAINING = True\n",
    "ENSEMBLE_MEMBER = 1\n",
    "target = 0.01\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr_series=[15e-4, 15e-4, 15e-4], learning_decay=0.7, decay_step=1, threshold=9.0, weight_decay=1e-4, new_model=True)\n",
    "ensemble.load_ensemble(\"human-mini-G\")\n",
    "# ensemble.load_ensemble(\"tiny-toy-C\")\n",
    "# ensemble.load_ensemble(\"toy-HIL-forced\")\n",
    "ensemble.eval_mode()\n",
    "sampled_dataset = SwarmDataset(\"data/human-mini\", rank=0)\n",
    "data = sampled_dataset\n",
    "\n",
    "embeddings = []\n",
    "classes = []\n",
    "for i in range(len(data)):\n",
    "    image, _class = sampled_dataset[i][0], sampled_dataset[i][1][0]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    embed = ensemble.ensemble[ENSEMBLE_MEMBER].forward(torch.tensor(image, device=device, dtype=torch.float))\n",
    "    embed = embed.detach().cpu().squeeze(dim=0).numpy()\n",
    "    embeddings.append(embed)\n",
    "    classes.append(_class)\n",
    "\n",
    "embeddings = np.array(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduced = TSNE(\n",
    "    n_components=2,\n",
    "    learning_rate=\"auto\",\n",
    "    init=\"pca\",\n",
    "    perplexity=40,\n",
    "    early_exaggeration=1\n",
    ").fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "color_classes = {\n",
    "    -1: [0.33, 0.33, 0.33],\n",
    "    0: [1, 0, 0], # Red\n",
    "    1: [0, 1, 0], # Green\n",
    "    2: [0, 0, 1], # Blue\n",
    "    3: [0, 1, 1], # Cyan\n",
    "    4: [1, 1, 0], # Yellow\n",
    "    5: [0.5, 0, 0.25], # Pink\n",
    "    6: [0.75, 0.325, 0.0] # Brown\n",
    "}\n",
    "\n",
    "label_classes = {\n",
    "    -1: \"Unlabeled\",\n",
    "    0: \"Cyclic\",\n",
    "    1: \"Triangle\",\n",
    "    2: \"Square\",\n",
    "    3: \"Ellipse\",\n",
    "    4: \"Random-Dots\",\n",
    "    5: \"Dispersal\",\n",
    "    6: \"Aggregation\"\n",
    "}\n",
    "\n",
    "lim = len(reduced)\n",
    "x = [reduced[i][0] for i in range(lim)]\n",
    "y = [reduced[i][1] for i in range(lim)]\n",
    "colors = [color_classes[classes[i]] for i in range(lim)]\n",
    "labels = [label_classes[classes[i]] for i in range(lim)]\n",
    "plot.grid(True)\n",
    "plot.scatter(x, y, c=colors)\n",
    "plot.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list\n",
    "\n",
    "color_classes = {\n",
    "    0: [1, 0, 0],\n",
    "    1: [0, 1, 0],\n",
    "    2: [0, 0, 1],\n",
    "}\n",
    "\n",
    "label_classes = {\n",
    "    0: \"Circles\",\n",
    "    1: \"Triangles\",\n",
    "    2: \"Squares\",\n",
    "}\n",
    "\n",
    "triples = []\n",
    "ensemble.eval_mode()\n",
    "OUT = \"data/toy-oracle\"\n",
    "with open(os.path.join(OUT, \"triplets.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        triples.append([int(triplet[0]), int(triplet[1]), int(triplet[2])])\n",
    "\n",
    "target_triplet = triples[13]\n",
    "lim = 500\n",
    "x = [reduced[i][0] for i in range(lim)]\n",
    "y = [reduced[i][1] for i in range(lim)]\n",
    "colors = [color_classes[classes[i]] for i in range(lim)]\n",
    "labels = [label_classes[classes[i]] for i in range(lim)]\n",
    "\n",
    "# colors[target_triplet[0]] = [0, 0, 0]\n",
    "# colors[target_triplet[1]] = [0, 0, 0]\n",
    "# colors[target_triplet[2]] = [0.2, 0, 0]\n",
    "\n",
    "plot.grid(True)\n",
    "plot.scatter(x, y, c=colors)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
