{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2852243/2830919202.py:99: DeprecationWarning: This function is deprecated. Please call randint(0, 500 + 1) instead\n",
      "  samples = np.random.random_integers(0, data_cutoff, (data_size, 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.060468749999999995], [0.060468749999999995], [0.060468749999999995]]\n",
      "Losses: [ 4453.71340481 11499.54998571    25.50813214]\n",
      "Epoch 0, loss: 5326.25717422035, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.060468749999999995], [0.060468749999999995], [0.060468749999999995]]\n",
      "Losses: [ 236.21773293   96.46597599 1312.44556706]\n",
      "Epoch 1, loss: 548.3764253296212, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.060468749999999995], [0.060468749999999995], [0.060468749999999995]]\n",
      "Losses: [  0.77213971   0.         519.56458333]\n",
      "Epoch 2, loss: 173.4455743489442, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.042328124999999994], [0.042328124999999994], [0.060468749999999995]]\n",
      "Losses: [ 10.31553255  10.05231253 303.63789368]\n",
      "Epoch 3, loss: 108.00191291876966, windowed_loss: 276.6079708657783\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.029629687499999995], [0.042328124999999994], [0.060468749999999995]]\n",
      "Losses: [19.7461141   0.09918733  0.        ]\n",
      "Epoch 4, loss: 6.61510047647688, windowed_loss: 96.02086258139691\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.029629687499999995], [0.029629687499999995], [0.042328124999999994]]\n",
      "Losses: [18.0642492   0.18847946 40.87279105]\n",
      "Epoch 5, loss: 19.708506570640186, windowed_loss: 44.77517332196225\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.020740781249999996], [0.020740781249999996], [0.042328124999999994]]\n",
      "Losses: [36.05415719  1.2125346  17.90848794]\n",
      "Epoch 6, loss: 18.39172657979589, windowed_loss: 14.905111208970984\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.020740781249999996], [0.014518546874999996], [0.042328124999999994]]\n",
      "Losses: [27.1712366  26.42525272  0.        ]\n",
      "Epoch 7, loss: 17.86549644098214, windowed_loss: 18.655243197139406\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.020740781249999996], [0.014518546874999996], [0.029629687499999995]]\n",
      "Losses: [2.32675591 0.15855027 0.41321463]\n",
      "Epoch 8, loss: 0.9661736034211658, windowed_loss: 12.407798874733066\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.014518546874999996], [0.014518546874999996], [0.020740781249999996]]\n",
      "Losses: [ 3.25656439  0.         84.30102041]\n",
      "Epoch 9, loss: 29.185861600499578, windowed_loss: 16.005843881634295\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.010162982812499997], [0.010162982812499997], [0.020740781249999996]]\n",
      "Losses: [  4.96100289  28.68301578 497.91629464]\n",
      "Epoch 10, loss: 177.18677110736874, windowed_loss: 69.1129354370965\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.010162982812499997], [0.010162982812499997], [0.020740781249999996]]\n",
      "Losses: [0.         1.89039466 0.        ]\n",
      "Epoch 11, loss: 0.6301315524053912, windowed_loss: 69.00092142009125\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.007114087968749998], [0.010162982812499997], [0.014518546874999996]]\n",
      "Losses: [0.         1.06061885 0.        ]\n",
      "Epoch 12, loss: 0.353539616072259, windowed_loss: 59.39014742528213\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.004979861578124998], [0.007114087968749998], [0.010162982812499997]]\n",
      "Losses: [0.08305489 7.37735982 0.        ]\n",
      "Epoch 13, loss: 2.4868049037699795, windowed_loss: 1.1568253574158767\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.003485903104687498], [0.007114087968749998], [0.007114087968749998]]\n",
      "Losses: [1.53666126 0.         0.        ]\n",
      "Epoch 14, loss: 0.512220421615912, windowed_loss: 1.117521647152717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.003485903104687498], [0.004979861578124998], [0.004979861578124998]]\n",
      "Losses: [0.31692905 0.         0.        ]\n",
      "Epoch 15, loss: 0.10564301538129224, windowed_loss: 1.0348894469223946\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.003485903104687498], [0.003485903104687498], [0.003485903104687498]]\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 16, loss: 0.0, windowed_loss: 0.20595447899906807\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0024401321732812485], [0.0024401321732812485], [0.0024401321732812485]]\n",
      "Losses: [0.         0.38256058 0.        ]\n",
      "Epoch 17, loss: 0.12752019225599917, windowed_loss: 0.07772106921243048\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.001708092521296874], [0.001708092521296874], [0.001708092521296874]]\n",
      "Losses: [ 0.        42.7574139  0.       ]\n",
      "Epoch 18, loss: 14.252471301020408, windowed_loss: 4.793330497758802\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0011956647649078117], [0.001708092521296874], [0.0011956647649078117]]\n",
      "Losses: [ 0.         10.54665332  0.        ]\n",
      "Epoch 19, loss: 3.5155511064594296, windowed_loss: 5.965180866578613\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0008369653354354682], [0.001708092521296874], [0.0008369653354354682]]\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 20, loss: 0.0, windowed_loss: 5.922674135826612\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0005858757348048277], [0.0011956647649078117], [0.0005858757348048277]]\n",
      "Losses: [0.87074312 0.         0.        ]\n",
      "Epoch 21, loss: 0.29024770524766713, windowed_loss: 1.2685996039023657\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0005858757348048277], [0.0008369653354354682], [0.00041011301436337934]]\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 22, loss: 0.0, windowed_loss: 0.09674923508255572\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.00041011301436337934], [0.0005858757348048277], [0.0002870791100543655]]\n",
      "Losses: [0.52491137 4.66250859 0.        ]\n",
      "Epoch 23, loss: 1.7291399897361286, windowed_loss: 0.6731292316612653\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0002870791100543655], [0.0005858757348048277], [0.00020095537703805584]]\n",
      "Losses: [5.26043141 0.         2.4576511 ]\n",
      "Epoch 24, loss: 2.572694168609827, windowed_loss: 1.4339447194486519\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.0002870791100543655], [0.00041011301436337934], [0.00020095537703805584]]\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 25, loss: 0.0, windowed_loss: 1.4339447194486519\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n",
      "Unsupervised Training.. 82.56\n",
      "LR: [[0.00020095537703805584], [0.00041011301436337934], [0.00020095537703805584]]\n",
      "Losses: [  33.15007905  100.40707938 1171.15445964]\n",
      "Epoch 26, loss: 434.90387268861133, windowed_loss: 145.8255222857404\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 41.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 138\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# while loss > target:\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m epochs \u001B[38;5;241m<\u001B[39m EPOCHS:\n\u001B[0;32m--> 138\u001B[0m     losses, total_updates \u001B[38;5;241m=\u001B[39m \u001B[43mpretraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampled_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensemble\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m     average_loss \u001B[38;5;241m=\u001B[39m losses \u001B[38;5;241m/\u001B[39m total_updates\n\u001B[1;32m    140\u001B[0m     lr \u001B[38;5;241m=\u001B[39m ensemble\u001B[38;5;241m.\u001B[39mevaluate_lr(average_loss)\n",
      "Cell \u001B[0;32mIn [9], line 123\u001B[0m, in \u001B[0;36mpretraining\u001B[0;34m(data, ensemble, data_cutoff, data_size)\u001B[0m\n\u001B[1;32m    120\u001B[0m positives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(positives, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    121\u001B[0m negatives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(negatives, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 123\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[43mensemble\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpositives\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnegatives\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m temp_losses \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m losses\n\u001B[1;32m    126\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m temp_losses\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/networks/ensemble.py:51\u001B[0m, in \u001B[0;36mEnsemble.train_batch\u001B[0;34m(self, anchor, positive, negative)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, network \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mensemble):\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizers[i]\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 51\u001B[0m     anchor_out, pos_out, neg_out \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_network_from_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpositive\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnegative\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(anchor_out, pos_out, neg_out)\n\u001B[1;32m     53\u001B[0m     losses\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/networks/embedding.py:76\u001B[0m, in \u001B[0;36mNoveltyEmbedding.batch_network_from_numpy\u001B[0;34m(self, anchor_list, pos_list, neg_list)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbatch_network_from_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m, anchor_list, pos_list, neg_list):\n\u001B[1;32m     75\u001B[0m     device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 76\u001B[0m     anchor_input \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43manchor_list\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     77\u001B[0m     pos_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(pos_list)\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[1;32m     78\u001B[0m     neg_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(neg_list)\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from src.networks.embedding import NoveltyEmbedding\n",
    "from src.networks.archive import DataAggregationArchive\n",
    "from src.networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "BATCH_SIZE = 516\n",
    "PRETRAINING = True\n",
    "target = 0.0001\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 0.03 * BATCH_SIZE / 256\n",
    "ensemble = Ensemble(size=3, output_size=32, lr_series=[lr, lr, lr], learning_decay=0.7, decay_step=1, threshold=100.0, weight_decay=10e-6, new_model=True, margin=100)\n",
    "# ensemble.load_ensemble(\"../checkpoints/ensembles/toy-SIMCLR\", full=True)\n",
    "sampled_dataset = SwarmDataset(\"../data/tinytoy\", rank=0)\n",
    "\n",
    "def resizeInput(X, w=200):\n",
    "    frame = X.astype(np.uint8)\n",
    "    resized = cv2.resize(frame, dsize=(w, w), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def translate(img, offset=(10, 10)):\n",
    "    h, w = img.shape\n",
    "    xoff, yoff = offset\n",
    "    if xoff < 0: xpadding = (0, -xoff)\n",
    "    else: xpadding = (xoff, 0)\n",
    "    if yoff < 0: ypadding = (0, -yoff)\n",
    "    else: ypadding = (yoff, 0)\n",
    "    img = np.pad(img, (xpadding, ypadding))\n",
    "\n",
    "    if xoff >= 0 and yoff >= 0:\n",
    "        return img[:w, :w]\n",
    "    elif xoff < 0 and yoff >= 0:\n",
    "        return img[-w:, :w]\n",
    "    elif xoff >= 0 and yoff < 0:\n",
    "        return img[:w, -w:]\n",
    "    return img[-w:, -w:]\n",
    "\n",
    "def zoom_at(img, zoom, coord=None):\n",
    "    # Adapted from https://stackoverflow.com/questions/69050464/zoom-into-image-with-opencv\n",
    "    h, w = [ zoom * i for i in img.shape ]\n",
    "    if coord is None: cx, cy = w/2, h/2\n",
    "    else: cx, cy = [ zoom*c for c in coord ]\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[ int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "               int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "def get_color_distortion(X, s=3.0):\n",
    "    X = X + s * np.random.randn(X.shape[0], X.shape[1])\n",
    "    return X\n",
    "\n",
    "def getRandomTransformation(image, k=2):\n",
    "    transformation_choices = [\"Rotation\", \"Blur\", \"Zoom\", \"Translate\", \"Distort\", \"ResizedCrop\"]\n",
    "    # weights = [0.4, 0.3, 0.0, 0.2]\n",
    "    # weights = [1.0, 0.0, 0.0, 0.0]\n",
    "    # choices = random.choices(transformation_choices, weights, k=k)\n",
    "    choices = [\"Distort\", \"ResizedCrop\"]\n",
    "    if \"Rotation\" in choices:\n",
    "        theta = random.choice([90, 180, 270])\n",
    "        image = ndimage.rotate(image, theta)\n",
    "    elif \"Blur\" in choices:\n",
    "        blur = random.choice([0.5, 1.0, 1.5])\n",
    "        image = ndimage.gaussian_filter(image, sigma=blur)\n",
    "    elif \"Zoom\" in choices:\n",
    "        # zoom = random.choice([1.06, 1.12, 1.18])\n",
    "        padding = random.choice([10])\n",
    "        padded = np.pad(image, padding, mode='constant')\n",
    "        image = resizeInput(padded, 50)\n",
    "    elif \"Translate\" in choices:\n",
    "        offsets = [i for i in range(-10, 10, 2)]\n",
    "        offset = (random.choice(offsets), random.choice(offsets))\n",
    "        # offset = (2, 2)\n",
    "        image = translate(image, offset)\n",
    "    elif \"Distort\" in choices:\n",
    "        strength = random.choice([0.0, 0.5, 1.0, 3.0, 5.0])\n",
    "        image = get_color_distortion(image, s=strength)\n",
    "    elif \"ResizedCrop\" in choices:\n",
    "        cropper = RandomResizedCrop(size=(50,50))\n",
    "        image = cropper(image)\n",
    "    return image\n",
    "\n",
    "def pretraining(data, ensemble, data_cutoff=None, data_size=500):\n",
    "    if data_cutoff is None:\n",
    "        data_cutoff = len(data) - 1\n",
    "    # np.random.seed(0)\n",
    "    samples = np.random.random_integers(0, data_cutoff, (data_size, 2))\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "    total_updates = 0\n",
    "    pull_set = [k for k in range(len(samples))]\n",
    "    random.shuffle(pull_set)\n",
    "    for index in range(0, len(pull_set), BATCH_SIZE):\n",
    "        i = pull_set[index]\n",
    "        if total_updates % 20 == 0:\n",
    "            print(f\"Unsupervised Training.. {(total_updates * BATCH_SIZE * 100) / data_size}\")\n",
    "\n",
    "        AUGMENT_SIZE = 1\n",
    "        if i + (BATCH_SIZE * AUGMENT_SIZE) >= len(pull_set):\n",
    "            continue\n",
    "\n",
    "        temp_losses = np.array([0.0 for _ in ensemble.ensemble])\n",
    "\n",
    "        anchors = np.array([data[samples[i + (j % AUGMENT_SIZE)][0]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        positives = np.array([getRandomTransformation(data[samples[i + (j % AUGMENT_SIZE)][0]][0], k=2) for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        negatives = np.array([data[samples[i + (j % AUGMENT_SIZE)][1]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        temp_losses += losses\n",
    "\n",
    "        total_loss += temp_losses\n",
    "        total_updates += 1\n",
    "\n",
    "    return total_loss, total_updates\n",
    "\n",
    "t_1 = time.time()\n",
    "EPOCHS = 100\n",
    "if PRETRAINING:\n",
    "    epochs = 0\n",
    "    loss_history = []\n",
    "    # while loss > target:\n",
    "    while epochs < EPOCHS:\n",
    "        losses, total_updates = pretraining(sampled_dataset, ensemble, data_cutoff=None, data_size=25000)\n",
    "        average_loss = losses / total_updates\n",
    "        lr = ensemble.evaluate_lr(average_loss)\n",
    "        locale_loss = sum(average_loss) / len(average_loss)\n",
    "        loss_history.append(locale_loss)\n",
    "        loss = (sum(loss_history[-3:]) / 3) if len(loss_history) > 3 else 50\n",
    "        print(f\"LR: {lr}\")\n",
    "        print(f\"Losses: {average_loss}\")\n",
    "        print(f\"Epoch {epochs}, loss: {locale_loss}, windowed_loss: {loss}\")\n",
    "        epochs += 1\n",
    "\n",
    "print(f\"Total Pre-training Time: {time.time() - t_1}\")\n",
    "ensemble.save_ensemble(f\"../checkpoints/ensembles/{int(time.time())}\", full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE4ElEQVR4nO3VMQHAMAzAsKz8OWefKbSHhMCfv93dAYCZObcDAHiHKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBATAGAmAIAMQUAYgoAxBQAiCkAEFMAIKYAQEwBgJgCADEFAGIKAMQUAIgpABBTACCmAEBMAYCYAgAxBQBiCgDEFACIKQAQUwAgpgBAfu8DBwYENNNsAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomResizedCrop\n",
    "def get_color_distortion(X, s=3.0):\n",
    "    X = X + s * torch.randn(X.shape)\n",
    "    return X\n",
    "\n",
    "sampled_dataset = SwarmDataset(\"../data/tinytoy\", rank=0)\n",
    "img = torch.tensor(sampled_dataset[0][0]).unsqueeze(0)\n",
    "print(img.shape)\n",
    "\n",
    "cropper = RandomResizedCrop(size=(50,50))\n",
    "img = cropper(img)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(0), cmap=\"Greys\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
