{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from src.networks.embedding import NoveltyEmbedding\n",
    "from src.networks.archive import DataAggregationArchive\n",
    "from src.networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For single Sensor Baseline Model\n",
    "TRUTH_FILE = \"validation-data-baseline.txt\"\n",
    "OUT = \"../data/oracle\"\n",
    "classes = [-1 for i in range(1000)]\n",
    "controllers = []\n",
    "sampled_dataset = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "\n",
    "with open(os.path.join(OUT, TRUTH_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        triplet = CSVLineToVec(line)\n",
    "        classes[int(triplet[0])] = int(triplet[1])\n",
    "        controllers.append(sampled_dataset[i][1])\n",
    "\n",
    "for i in range(len(controllers)):\n",
    "    print(f\"{classes[i]}, {controllers[i][0]}, {controllers[i][1]}, {controllers[i][2]}, {controllers[i][3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr=15e-4, learning_decay=0.7, decay_step=1, threshold=9.0, weight_decay=1e-4, new_model=True, init=\"Random\")\n",
    "# ensemble.load_ensemble(\"../checkpoints/ensembles/01-20-23-baseline\", full=True)\n",
    "# ensemble.load_ensemble(\"../checkpoints/ensembles/01-20-23-filtered-C\", full=True)\n",
    "# ensemble.load_ensemble(\"../checkpoints/ensembles/01-23-23-two-s-pre-final\", full=True)\n",
    "ensemble.load_ensemble(\"../checkpoints/ensembles/01-23-23-baseline-hil-A\", full=True)\n",
    "ensemble.eval_mode()\n",
    "\n",
    "# Source the Original Dataset\n",
    "sampled_dataset = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# sampled_dataset = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "# sampled_dataset = SwarmDataset(\"../data/filtered-full\", rank=0)\n",
    "\n",
    "a = []\n",
    "for i in range(len(ensemble.ensemble)):\n",
    "    embedded_positions = []\n",
    "    for j, c in enumerate(classes):\n",
    "        image, _ = sampled_dataset[j][0], sampled_dataset[j][1][0]\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        embed = ensemble.ensemble[i].forward(torch.tensor(image, device=device, dtype=torch.float))\n",
    "        embed = embed.detach().cpu().squeeze(dim=0).numpy()\n",
    "        embedded_positions.append(embed)\n",
    "\n",
    "    # Evaluate Accuracy\n",
    "    MAX_SEARCH = 30000\n",
    "    correct, total = 0, 0\n",
    "    for x, _classX in validation_set:\n",
    "        for y, _classY in validation_set:\n",
    "            if x == y:\n",
    "                continue\n",
    "            for z, _classZ in validation_set:\n",
    "                if x == z or y == z:\n",
    "                    continue\n",
    "                # If _classX and _classY are both random, ignore.\n",
    "                if _classX == 0 and _classY == 0:\n",
    "                    continue\n",
    "                if _classZ != _classX and _classX == _classY:\n",
    "                    positive_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[y])\n",
    "                    negative_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[z])\n",
    "                    if positive_dist < negative_dist:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "                if total > 30000:\n",
    "                    break\n",
    "            if total > 30000:\n",
    "                break\n",
    "        if total > 30000:\n",
    "            break\n",
    "\n",
    "    acc = correct * 100 / total\n",
    "    a.append(acc)\n",
    "    print(f\"Ensemble {i} ~ Accuracy: {acc}\")\n",
    "\n",
    "print(f\"Average: {sum(a) / 3}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
