{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 1000\n"
     ]
    }
   ],
   "source": [
    "# For single Sensor Baseline Model\n",
    "# TRUTH_FILE = \"validation-data-two-sensor.txt\"\n",
    "# TRUTH_FILE = \"validation-data-baseline.txt\"\n",
    "\n",
    "\"\"\"\n",
    "RANDOM - Only Random Weight Initialization\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = None\n",
    "\n",
    "\"\"\"\n",
    "BASELINE - Pretraining only. No HIL.\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-20-23-baseline\"\n",
    "\n",
    "\"\"\"\n",
    "BASELINE - Pretraining + HIL.\n",
    "\"\"\"\n",
    "VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# TESTING_FILE = \"heuristic-simple-model-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/filtered-full\", rank=0)\n",
    "ENSEMBLE_PATH = \"../checkpoints/ensembles/01-27-23-BLH-HIL-B\"\n",
    "\n",
    "\n",
    "OUT = \"../data/oracle\"\n",
    "validation_classes = []\n",
    "with open(os.path.join(OUT, VALIDATION_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    validation_classes = [-1 for i in range(len(lines))]\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        validation_classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "testing_classes = []\n",
    "with open(os.path.join(OUT, TESTING_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    testing_classes = [-1 for i in range(len(lines))]\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        testing_classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "validation_set = []\n",
    "testing_set = []\n",
    "for i, _class in enumerate(testing_classes):\n",
    "    testing_set.append((i, _class))\n",
    "\n",
    "for i, _class in enumerate(validation_classes):\n",
    "    validation_set.append((i, _class))\n",
    "\n",
    "print(len(validation_set), len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "====================\n",
      "VAL results\n",
      "Class Set of Size: 200\n",
      "{0: 0, 1: 60723, 2: 27846, 3: 6876, 4: 108558, 5: 12408}\n",
      "CLASS ACCURACY (Out of 216411 triplets):\n",
      "1: 95.60463086474647\n",
      "2: 73.90648567119155\n",
      "3: 95.08435136707388\n",
      "4: 90.5396193739752\n",
      "5: 86.78272082527401\n",
      "Ensemble 0 ~ Accuracy: 89.74959683195401\n",
      "{0: 0, 1: 60723, 2: 27846, 3: 6876, 4: 108558, 5: 12408}\n",
      "CLASS ACCURACY (Out of 216411 triplets):\n",
      "1: 80.94791100571447\n",
      "2: 67.3202614379085\n",
      "3: 80.36649214659685\n",
      "4: 67.37964958823855\n",
      "5: 75.99129593810444\n",
      "Ensemble 1 ~ Accuracy: 72.0855224549584\n",
      "{0: 0, 1: 60723, 2: 27846, 3: 6876, 4: 108558, 5: 12408}\n",
      "CLASS ACCURACY (Out of 216411 triplets):\n",
      "1: 94.00885990481366\n",
      "2: 75.88522588522588\n",
      "3: 88.91797556719023\n",
      "4: 89.39092466699829\n",
      "5: 92.69825918762089\n",
      "Ensemble 2 ~ Accuracy: 89.12347339090897\n",
      "Average: 83.65286422594046\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr=15e-4, learning_decay=0.7, decay_step=1, threshold=9.0, weight_decay=1e-4, new_model=True, init=\"Random\")\n",
    "if ENSEMBLE_PATH:\n",
    "    ensemble.load_ensemble(ENSEMBLE_PATH, full=True)\n",
    "ensemble.eval_mode()\n",
    "\n",
    "\n",
    "# for metric in [\"TRAIN\", \"VAL\"]:\n",
    "for metric in [\"VAL\"]:\n",
    "    a = []\n",
    "    sampled_dataset = TESTING_DATA if metric == \"TRAIN\" else VALIDATION_DATA\n",
    "    c_set = testing_set if metric == \"TRAIN\" else validation_set\n",
    "    classes = testing_classes if metric == \"TRAIN\" else validation_classes\n",
    "\n",
    "    # random.shuffle(c_set)\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"{metric} results\")\n",
    "    print(f\"Class Set of Size: {len(c_set)}\")\n",
    "    for i in range(len(ensemble.ensemble)):\n",
    "        embedded_positions = []\n",
    "        for j, c in enumerate(classes):\n",
    "            image, _ = sampled_dataset[j][0], sampled_dataset[j][1][0]\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            embed = ensemble.ensemble[i].forward(torch.tensor(image, device=device, dtype=torch.float))\n",
    "            embed = embed.detach().cpu().squeeze(dim=0).numpy()\n",
    "            embedded_positions.append(embed)\n",
    "\n",
    "        # Evaluate Accuracy\n",
    "        correct, total = 0, 0\n",
    "        class_counts = {i:0 for i in range(max(classes) + 1)}\n",
    "        class_accuracy = {i:0 for i in range(max(classes) + 1)}\n",
    "        for l in range(len(c_set)):\n",
    "            x, _classX = c_set[l]\n",
    "            break_class_X = False\n",
    "            if _classX == 0:\n",
    "                continue\n",
    "            for j in range(l, len(c_set)):\n",
    "                y, _classY = c_set[j]\n",
    "                if x == y or _classX != _classY:\n",
    "                    continue\n",
    "                for k in range(len(c_set)):\n",
    "                    z, _classZ = c_set[k]\n",
    "                    # if _classZ == 0:\n",
    "                    #     continue\n",
    "                    if _classZ == _classX or x == z or y == z:\n",
    "                        continue\n",
    "                    positive_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[y])\n",
    "                    negative_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[z])\n",
    "                    if positive_dist < negative_dist:\n",
    "                        correct += 1\n",
    "                        class_accuracy[_classX] += 1\n",
    "                    total += 1\n",
    "                    class_counts[_classX] += 1\n",
    "\n",
    "        print(class_counts)\n",
    "        print(f\"CLASS ACCURACY (Out of {total} triplets):\")\n",
    "        for class_value in class_accuracy:\n",
    "            if class_value == 0:\n",
    "                continue\n",
    "            print(f\"{class_value}: {class_accuracy[class_value] * 100 / class_counts[class_value]}\")\n",
    "        acc = correct * 100 / total\n",
    "        a.append(acc)\n",
    "        print(f\"Ensemble {i} ~ Accuracy: {acc}\")\n",
    "\n",
    "    print(f\"Average: {sum(a) / 3}\")\n",
    "    print(\"=\" * 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
