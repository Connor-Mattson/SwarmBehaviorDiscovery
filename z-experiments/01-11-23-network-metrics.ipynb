{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def getAttributeVector(controller):\n",
    "    v0_l, v0_r = controller[0],controller[1]\n",
    "    v1_l, v1_r = controller[2], controller[3]\n",
    "    v0_l, v0_r, v1_l, v1_r = round(v0_l, 1), round(v0_r, 1), round(v1_l, 1), round(v1_r, 1)\n",
    "\n",
    "    k = 0.5\n",
    "    max_elem_score = max(-min(controllers[i]), max(controllers[i]))\n",
    "    # max_elem_score = -max_elem_score if max_elem_score < k else max_elem_score\n",
    "\n",
    "    k_2 = 0.75\n",
    "    magnitude_score = np.linalg.norm(controllers[i])\n",
    "    # magnitude_score = -magnitude_score if magnitude_score < k_2 else magnitude_score\n",
    "\n",
    "    k_3 = 0.3\n",
    "    average_score = np.average(np.sqrt(np.power(controllers[i], 2)))\n",
    "    # average_score = -average_score if average_score < k_3 else average_score\n",
    "\n",
    "    # Sensor off magnitude (trial i)\n",
    "    on_magnitude = (v0_l**2) + (v0_r**2)\n",
    "\n",
    "    # Sensor on magnitude (trial i)\n",
    "    off_magnitude = (v1_l**2) + (v1_r**2)\n",
    "\n",
    "    # Spinning Detection (sensor off - trial ii)\n",
    "    if v0_l == 0.0 and v0_r == 0.0:\n",
    "        off_spin_variance = 0.0\n",
    "    else:\n",
    "        denom = v0_l if v0_l != 0.0 else v0_r\n",
    "        off_spin_variance = min(abs((v0_l + v0_r) / denom), 1.0)\n",
    "\n",
    "    # Spinning Detection (sensor on - trial ii)\n",
    "    if v1_l == 0.0 and v1_r == 0.0:\n",
    "        on_spin_variance = 0.0\n",
    "    else:\n",
    "        denom = v1_l if v1_l != 0.0 else v1_r\n",
    "        on_spin_variance = min(abs((v1_l + v1_r) / denom), 1)\n",
    "\n",
    "    # Mirror Property\n",
    "    mirrored_controller = np.array([v0_l, v0_r, -v0_l, -v0_r])\n",
    "    mirror_score = np.linalg.norm(mirrored_controller - controllers[i])\n",
    "\n",
    "    # Independence Property\n",
    "    independent_controller = np.array([v0_l, v0_r, v0_l, v0_r])\n",
    "    indep = np.linalg.norm(independent_controller - controllers[i])\n",
    "\n",
    "    return [indep, mirror_score, on_spin_variance, off_spin_variance, on_magnitude, off_magnitude, max_elem_score, magnitude_score, average_score]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 100\n"
     ]
    }
   ],
   "source": [
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list\n",
    "\n",
    "sampled_dataset = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "data = sampled_dataset\n",
    "\n",
    "lim = 1000\n",
    "controllers = []\n",
    "classes = [-1 for i in range(lim)]\n",
    "for i in range(lim):\n",
    "    image, genome, behavior = sampled_dataset[i][0], sampled_dataset[i][1], sampled_dataset[i][2]\n",
    "    for j in range(len(behavior)):\n",
    "        if behavior[j] < 0.0:\n",
    "            behavior[j] *= -1\n",
    "    controllers.append(genome)\n",
    "\n",
    "OUT = \"../data/oracle\"\n",
    "with open(os.path.join(OUT, \"original-hand-labeled-classes.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "training_data = []\n",
    "testing_data = []\n",
    "for i, controller in enumerate(controllers):\n",
    "    if i % 10 == 0:\n",
    "        testing_data.append([controller, getAttributeVector(controller), int(classes[i] > 0)])\n",
    "    else:\n",
    "        training_data.append([controller, getAttributeVector(controller), int(classes[i] > 0)])\n",
    "\n",
    "print(len(training_data), len(testing_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class RandomDetectionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.single_layer = nn.Sequential(\n",
    "            nn.Linear(9, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.single_layer(x)\n",
    "        return logits\n",
    "\n",
    "model = RandomDetectionNetwork().to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [17], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Training\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (controller, attributes, y_truth) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(training_data):\n\u001B[0;32m----> 7\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattributes\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m         y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(y_truth)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m         pred \u001B[38;5;241m=\u001B[39m model(X)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    # Training\n",
    "    for i, (controller, attributes, y_truth) in enumerate(training_data):\n",
    "        X = torch.tensor(attributes).to(device)\n",
    "        y = torch.tensor(y_truth).to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{len(training_data):>5d}]\")\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (controller, attributes, y_truth) in enumerate(testing_data):\n",
    "            X = torch.tensor(attributes).to(device)\n",
    "            y = torch.tensor(y_truth).to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred) == y_truth)\n",
    "    test_loss /= len(testing_data)\n",
    "    correct /= len(testing_data)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
