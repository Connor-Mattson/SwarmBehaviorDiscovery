{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import random\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from torchvision.transforms import RandomResizedCrop, RandomHorizontalFlip, RandomVerticalFlip\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list\n",
    "\n",
    "def resizeInput(X, w=200):\n",
    "    frame = X.astype(np.uint8)\n",
    "    resized = cv2.resize(frame, dsize=(w, w), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def translate(img, offset=(10, 10)):\n",
    "    h, w = img.shape\n",
    "    xoff, yoff = offset\n",
    "    if xoff < 0: xpadding = (0, -xoff)\n",
    "    else: xpadding = (xoff, 0)\n",
    "    if yoff < 0: ypadding = (0, -yoff)\n",
    "    else: ypadding = (yoff, 0)\n",
    "    img = np.pad(img, (xpadding, ypadding))\n",
    "\n",
    "    if xoff >= 0 and yoff >= 0:\n",
    "        return img[:w, :w]\n",
    "    elif xoff < 0 and yoff >= 0:\n",
    "        return img[-w:, :w]\n",
    "    elif xoff >= 0 and yoff < 0:\n",
    "        return img[:w, -w:]\n",
    "    return img[-w:, -w:]\n",
    "\n",
    "def zoom_at(img, zoom, coord=None):\n",
    "    # Adapted from https://stackoverflow.com/questions/69050464/zoom-into-image-with-opencv\n",
    "    h, w = [ zoom * i for i in img.shape ]\n",
    "    if coord is None: cx, cy = w/2, h/2\n",
    "    else: cx, cy = [ zoom*c for c in coord ]\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[ int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "               int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "def get_color_distortion(X, s=3.0):\n",
    "    X = X + s * np.random.randn(X.shape[0], X.shape[1])\n",
    "    return X\n",
    "\n",
    "def getRandomFlip(X):\n",
    "    tmp = torch.tensor(X).unsqueeze(0)\n",
    "    flipper_A = RandomHorizontalFlip(0.5)\n",
    "    flipper_B = RandomVerticalFlip(0.5)\n",
    "    image = flipper_A(flipper_B(tmp))\n",
    "    image = image.squeeze(0).numpy()\n",
    "    return image\n",
    "\n",
    "def getRandomTransformation(image, k=2):\n",
    "    transformation_choices = [\"Rotation\", \"Blur\", \"Zoom\", \"Translate\", \"Distort\", \"ResizedCrop\"]\n",
    "    # weights = [0.4, 0.3, 0.0, 0.2]\n",
    "    # weights = [1.0, 0.0, 0.0, 0.0]\n",
    "    # choices = random.choices(transformation_choices, weights, k=k)\n",
    "    choices = [\"ResizedCrop\"]\n",
    "    # choices = []\n",
    "    if \"RandomFlip\" in choices:\n",
    "        image = getRandomFlip(image)\n",
    "    if \"ResizedCrop\" in choices:\n",
    "        tmp = torch.tensor(image).unsqueeze(0)\n",
    "        flipper = RandomHorizontalFlip(0.5)\n",
    "        cropper = RandomResizedCrop(size=(50,50), scale=(0.6, 1.0), ratio=(1.0, 1.0))\n",
    "        image = flipper(cropper(tmp))\n",
    "        image = image.squeeze(0).numpy()\n",
    "    if \"Rotation\" in choices:\n",
    "        theta = random.choice([90, 180, 270])\n",
    "        image = ndimage.rotate(image, theta)\n",
    "    if \"Blur\" in choices:\n",
    "        blur = random.choice([0.5, 1.0, 1.5])\n",
    "        image = ndimage.gaussian_filter(image, sigma=blur)\n",
    "    if \"Zoom\" in choices:\n",
    "        # zoom = random.choice([1.06, 1.12, 1.18])\n",
    "        padding = random.choice([10])\n",
    "        padded = np.pad(image, padding, mode='constant')\n",
    "        image = resizeInput(padded, 50)\n",
    "    if \"Translate\" in choices:\n",
    "        offsets = [i for i in range(-10, 10, 2)]\n",
    "        offset = (random.choice(offsets), random.choice(offsets))\n",
    "        # offset = (2, 2)\n",
    "        image = translate(image, offset)\n",
    "    if \"Distort\" in choices:\n",
    "        strength = random.choice([3.0, 5.0, 10.0])\n",
    "        image = get_color_distortion(image, s=strength)\n",
    "    if \"Flip\" in choices:\n",
    "        tmp = torch.tensor(image).unsqueeze(0)\n",
    "        flipper = RandomHorizontalFlip(1.0)\n",
    "        image = flipper(tmp)\n",
    "        image = image.squeeze(0).numpy()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168612\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate Triplets based off of labeled classes (IID_TRIPLETS) or triplets based off ensemble Queries\n",
    "\"\"\"\n",
    "FROM_SCRATCH = False\n",
    "HEURISTIC = False\n",
    "IID_TRIPLETS = True\n",
    "TWO_SENSOR = False\n",
    "\n",
    "if TWO_SENSOR:\n",
    "    TRUTH_FILE = \"gecco-two-sensor-classes.txt\" if not HEURISTIC else \"heuristic-two-sensor.txt\"\n",
    "    DATASET = SwarmDataset(\"../data/gecco-two-sensor\", rank=0) if not HEURISTIC else SwarmDataset(\"../data/gecco-filtered-two-sensor\")\n",
    "    ENSEMBLE_PATH = \"../checkpoints/ensembles/01-28-23-2S-Pre-B\" if not HEURISTIC else \"../checkpoints/ensembles/01-30-23-2S-Heur-Pre-B\"\n",
    "else:\n",
    "    TRUTH_FILE = \"original-hand-labeled-classes.txt\" if not HEURISTIC else \"heuristic-simple-model-classes.txt\"\n",
    "    DATASET = SwarmDataset(\"../data/full-mini\", rank=0) if not HEURISTIC else SwarmDataset(\"../data/filtered-full\")\n",
    "    ENSEMBLE_PATH = \"../checkpoints/ensembles/01-20-23-baseline\" if not HEURISTIC else \"../checkpoints/ensembles/01-26-23-heuristic-BL-pretraining\"\n",
    "\n",
    "if FROM_SCRATCH:\n",
    "    ENSEMBLE_PATH = None\n",
    "OUT = \"../data/oracle\"\n",
    "classes = [-1 for i in range(400)]\n",
    "with open(os.path.join(OUT, TRUTH_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > len(classes) - 1:\n",
    "            break\n",
    "        triplet = CSVLineToVec(line)\n",
    "        classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "triplets = []\n",
    "\n",
    "if IID_TRIPLETS:\n",
    "    for i, i_c in enumerate(classes):\n",
    "        if i_c == 0:\n",
    "            continue\n",
    "        continue_to_top = False\n",
    "        for j, j_c in enumerate(classes):\n",
    "            if j_c != i_c:\n",
    "                continue\n",
    "            if i == j:\n",
    "                continue\n",
    "            for k, k_c in enumerate(classes):\n",
    "                if k_c == 0:\n",
    "                    continue\n",
    "                if k_c == i_c or k_c == j_c:\n",
    "                    continue\n",
    "                # if i_c == 0:\n",
    "                #     if not (i, i, k) in triplets:\n",
    "                #         triplets.append((i, i, k))\n",
    "                #         continue_to_top = True\n",
    "                triplets.append((i, j, k))\n",
    "            if continue_to_top:\n",
    "                break\n",
    "\n",
    "# Else, use an ensemble to create the triplets.\n",
    "else:\n",
    "    print(\"No Implementation Yet\")\n",
    "\n",
    "print(len(triplets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 322, 366) (5, 5, 3)\n",
      "(51, 88, 139) (2, 2, 4)\n",
      "(227, 133, 197) (4, 4, 5)\n",
      "(184, 190, 22) (4, 4, 5)\n",
      "(188, 59, 302) (4, 4, 2)\n",
      "(148, 67, 306) (3, 3, 2)\n",
      "(127, 96, 345) (3, 3, 5)\n",
      "(159, 258, 299) (4, 4, 8)\n",
      "(222, 292, 92) (4, 4, 5)\n",
      "(188, 156, 67) (4, 4, 3)\n",
      "(287, 324, 220) (5, 5, 3)\n",
      "(127, 220, 101) (3, 3, 5)\n",
      "(313, 89, 321) (4, 4, 5)\n",
      "(61, 322, 313) (5, 5, 4)\n",
      "(32, 52, 203) (5, 5, 1)\n",
      "(113, 182, 328) (4, 4, 2)\n",
      "(42, 139, 393) (4, 4, 5)\n",
      "(236, 298, 88) (1, 1, 2)\n",
      "(352, 201, 260) (5, 5, 6)\n",
      "(235, 214, 22) (3, 3, 5)\n",
      "(227, 258, 327) (4, 4, 2)\n",
      "(285, 244, 232) (4, 4, 3)\n",
      "(223, 52, 188) (5, 5, 4)\n",
      "(193, 170, 362) (1, 1, 5)\n",
      "(221, 231, 223) (3, 3, 5)\n",
      "(61, 270, 222) (5, 5, 4)\n",
      "(190, 80, 223) (4, 4, 5)\n",
      "(88, 243, 42) (2, 2, 4)\n",
      "(248, 366, 133) (3, 3, 4)\n",
      "(278, 142, 264) (3, 3, 5)\n",
      "(63, 302, 161) (2, 2, 5)\n",
      "(274, 317, 10) (2, 2, 3)\n",
      "(277, 324, 7) (5, 5, 2)\n",
      "(126, 302, 343) (2, 2, 3)\n",
      "(63, 328, 235) (2, 2, 3)\n",
      "(68, 287, 389) (5, 5, 4)\n",
      "(274, 368, 284) (2, 2, 4)\n",
      "(197, 61, 111) (5, 5, 3)\n",
      "(142, 221, 89) (3, 3, 4)\n",
      "(19, 341, 343) (5, 5, 3)\n",
      "(357, 9, 393) (4, 4, 5)\n",
      "(328, 23, 142) (2, 2, 3)\n",
      "(209, 357, 302) (4, 4, 2)\n",
      "(45, 78, 328) (4, 4, 2)\n",
      "(66, 366, 318) (3, 3, 4)\n",
      "(22, 180, 45) (5, 5, 4)\n",
      "(178, 384, 399) (4, 4, 2)\n",
      "(120, 350, 188) (3, 3, 4)\n",
      "(88, 126, 298) (2, 2, 1)\n",
      "(214, 232, 284) (3, 3, 4)\n",
      "(278, 343, 28) (3, 3, 4)\n",
      "(156, 80, 243) (4, 4, 2)\n",
      "(77, 328, 258) (2, 2, 4)\n",
      "(148, 232, 153) (3, 3, 4)\n",
      "(236, 193, 276) (1, 1, 2)\n",
      "(357, 318, 218) (4, 4, 2)\n",
      "(108, 378, 368) (5, 5, 2)\n",
      "(161, 180, 312) (5, 5, 4)\n",
      "(184, 389, 314) (4, 4, 3)\n",
      "(3, 362, 314) (5, 5, 3)\n",
      "(249, 236, 45) (1, 1, 4)\n",
      "(36, 195, 257) (5, 5, 4)\n",
      "(366, 189, 186) (3, 3, 2)\n",
      "(378, 372, 240) (5, 5, 6)\n",
      "(388, 328, 197) (2, 2, 5)\n",
      "(322, 52, 152) (5, 5, 2)\n",
      "(201, 277, 116) (5, 5, 2)\n",
      "(389, 244, 186) (4, 4, 2)\n",
      "(101, 32, 388) (5, 5, 2)\n",
      "(179, 127, 180) (3, 3, 5)\n",
      "(243, 302, 118) (2, 2, 3)\n",
      "(344, 245, 85) (2, 2, 4)\n",
      "(244, 318, 234) (4, 4, 6)\n",
      "(36, 372, 182) (5, 5, 4)\n",
      "(180, 321, 159) (5, 5, 4)\n",
      "(63, 368, 129) (2, 2, 5)\n",
      "(101, 68, 63) (5, 5, 2)\n",
      "(287, 68, 120) (5, 5, 3)\n",
      "(80, 85, 141) (4, 4, 1)\n",
      "(190, 78, 72) (4, 4, 5)\n",
      "(142, 248, 28) (3, 3, 4)\n",
      "(245, 77, 396) (2, 2, 6)\n",
      "(270, 180, 206) (5, 5, 1)\n",
      "(132, 253, 177) (3, 3, 2)\n",
      "(368, 51, 107) (2, 2, 1)\n",
      "(352, 161, 344) (5, 5, 2)\n",
      "(180, 277, 306) (5, 5, 2)\n",
      "(39, 223, 77) (5, 5, 2)\n",
      "(362, 358, 114) (5, 5, 4)\n",
      "(59, 389, 253) (4, 4, 3)\n",
      "(127, 118, 159) (3, 3, 4)\n",
      "(173, 22, 288) (5, 5, 2)\n",
      "(126, 288, 298) (2, 2, 1)\n",
      "(313, 133, 71) (4, 4, 2)\n",
      "(221, 10, 312) (3, 3, 4)\n",
      "(245, 368, 111) (2, 2, 3)\n",
      "(178, 114, 321) (4, 4, 5)\n",
      "(153, 100, 117) (4, 4, 6)\n",
      "(233, 114, 242) (4, 4, 5)\n",
      "(141, 249, 264) (1, 1, 5)\n",
      "(97, 227, 278) (4, 4, 3)\n",
      "(322, 161, 10) (5, 5, 3)\n",
      "(393, 180, 357) (5, 5, 4)\n",
      "(258, 318, 22) (4, 4, 5)\n",
      "(184, 17, 51) (4, 4, 2)\n",
      "(209, 85, 68) (4, 4, 5)\n",
      "(133, 184, 317) (4, 4, 2)\n",
      "(203, 338, 62) (1, 1, 4)\n",
      "(22, 353, 369) (5, 5, 6)\n",
      "(318, 209, 299) (4, 4, 8)\n",
      "(234, 303, 141) (6, 6, 1)\n",
      "(135, 277, 88) (5, 5, 2)\n",
      "(222, 59, 260) (4, 4, 6)\n",
      "(116, 245, 118) (2, 2, 3)\n",
      "(290, 370, 264) (6, 6, 5)\n",
      "(277, 197, 103) (5, 5, 3)\n",
      "(129, 135, 258) (5, 5, 4)\n",
      "(3, 345, 157) (5, 5, 8)\n",
      "(116, 65, 350) (2, 2, 3)\n",
      "(179, 132, 290) (3, 3, 6)\n",
      "(389, 9, 126) (4, 4, 2)\n",
      "(312, 182, 245) (4, 4, 2)\n",
      "(153, 257, 323) (4, 4, 3)\n",
      "(318, 182, 328) (4, 4, 2)\n",
      "(351, 231, 344) (3, 3, 2)\n",
      "(352, 19, 28) (5, 5, 4)\n",
      "(344, 126, 45) (2, 2, 4)\n",
      "(278, 248, 116) (3, 3, 2)\n",
      "(36, 393, 120) (5, 5, 3)\n",
      "(132, 232, 257) (3, 3, 4)\n",
      "(22, 101, 67) (5, 5, 3)\n",
      "(7, 243, 358) (2, 2, 5)\n",
      "(72, 92, 368) (5, 5, 2)\n",
      "(324, 197, 220) (5, 5, 3)\n",
      "(243, 245, 19) (2, 2, 5)\n",
      "(350, 148, 104) (3, 3, 1)\n",
      "(61, 277, 396) (5, 5, 6)\n",
      "(186, 310, 263) (2, 2, 5)\n",
      "(227, 89, 161) (4, 4, 5)\n",
      "(171, 314, 236) (3, 3, 1)\n",
      "(223, 3, 303) (5, 5, 6)\n",
      "(22, 201, 318) (5, 5, 4)\n",
      "(179, 314, 261) (3, 3, 4)\n",
      "(351, 111, 206) (3, 3, 1)\n",
      "(226, 170, 341) (1, 1, 5)\n",
      "(312, 133, 277) (4, 4, 5)\n",
      "(350, 235, 9) (3, 3, 4)\n",
      "(127, 278, 152) (3, 3, 2)\n",
      "(7, 116, 120) (2, 2, 3)\n",
      "(118, 366, 59) (3, 3, 4)\n",
      "(264, 101, 96) (5, 5, 3)\n",
      "(223, 324, 158) (5, 5, 1)\n",
      "(10, 232, 178) (3, 3, 4)\n",
      "(61, 22, 132) (5, 5, 3)\n",
      "(180, 92, 227) (5, 5, 4)\n",
      "(62, 233, 362) (4, 4, 5)\n",
      "(203, 158, 96) (1, 1, 3)\n",
      "(178, 257, 135) (4, 4, 5)\n",
      "(153, 261, 189) (4, 4, 3)\n",
      "(298, 104, 372) (1, 1, 5)\n",
      "(362, 223, 190) (5, 5, 4)\n",
      "(314, 220, 116) (3, 3, 2)\n",
      "(310, 302, 67) (2, 2, 3)\n",
      "(358, 39, 396) (5, 5, 6)\n",
      "(285, 209, 19) (4, 4, 5)\n",
      "(141, 294, 274) (1, 1, 2)\n",
      "(188, 156, 72) (4, 4, 5)\n",
      "(235, 118, 15) (3, 3, 1)\n",
      "(193, 249, 189) (1, 1, 3)\n",
      "(253, 120, 294) (3, 3, 1)\n",
      "(85, 78, 277) (4, 4, 5)\n",
      "(159, 284, 323) (4, 4, 3)\n",
      "(244, 357, 393) (4, 4, 5)\n",
      "(328, 71, 158) (2, 2, 1)\n",
      "(345, 52, 399) (5, 5, 2)\n",
      "(323, 96, 195) (3, 3, 5)\n",
      "(223, 322, 89) (5, 5, 4)\n",
      "(231, 132, 399) (3, 3, 2)\n",
      "(142, 253, 197) (3, 3, 5)\n",
      "(22, 270, 63) (5, 5, 2)\n",
      "(9, 178, 157) (4, 4, 8)\n",
      "(92, 242, 278) (5, 5, 3)\n",
      "(195, 129, 221) (5, 5, 3)\n",
      "(231, 343, 353) (3, 3, 5)\n",
      "(36, 72, 235) (5, 5, 3)\n",
      "(263, 287, 9) (5, 5, 4)\n",
      "(393, 135, 118) (5, 5, 3)\n",
      "(36, 270, 182) (5, 5, 4)\n",
      "(92, 352, 303) (5, 5, 6)\n",
      "(388, 65, 17) (2, 2, 4)\n",
      "(197, 277, 71) (5, 5, 2)\n",
      "(201, 362, 245) (5, 5, 2)\n",
      "(227, 209, 243) (4, 4, 2)\n",
      "(80, 62, 232) (4, 4, 3)\n",
      "(173, 393, 132) (5, 5, 3)\n",
      "(159, 100, 96) (4, 4, 3)\n",
      "(341, 195, 78) (5, 5, 4)\n",
      "(171, 103, 378) (3, 3, 5)\n",
      "(261, 100, 148) (4, 4, 3)\n",
      "(22, 353, 350) (5, 5, 3)\n",
      "(17, 28, 252) (4, 4, 8)\n",
      "(195, 378, 314) (5, 5, 3)\n",
      "(177, 7, 182) (2, 2, 4)\n",
      "(182, 284, 65) (4, 4, 2)\n",
      "(126, 262, 108) (2, 2, 5)\n",
      "(285, 313, 39) (4, 4, 5)\n",
      "(62, 139, 226) (4, 4, 1)\n",
      "(92, 324, 13) (5, 5, 6)\n",
      "(133, 313, 274) (4, 4, 2)\n",
      "(38, 88, 78) (2, 2, 4)\n",
      "(353, 322, 327) (5, 5, 2)\n",
      "(9, 78, 68) (4, 4, 5)\n",
      "(118, 235, 97) (3, 3, 4)\n",
      "(262, 327, 253) (2, 2, 3)\n",
      "(201, 270, 89) (5, 5, 4)\n",
      "(353, 19, 148) (5, 5, 3)\n",
      "(353, 277, 114) (5, 5, 4)\n",
      "(222, 209, 157) (4, 4, 8)\n",
      "(15, 298, 389) (1, 1, 4)\n",
      "(178, 73, 263) (4, 4, 5)\n",
      "(352, 223, 299) (5, 5, 8)\n",
      "(232, 67, 3) (3, 3, 5)\n",
      "(161, 372, 323) (5, 5, 3)\n",
      "(59, 45, 328) (4, 4, 2)\n",
      "(220, 214, 209) (3, 3, 4)\n",
      "(277, 264, 206) (5, 5, 1)\n",
      "(222, 184, 104) (4, 4, 1)\n",
      "(343, 66, 31) (3, 3, 5)\n",
      "(276, 7, 223) (2, 2, 5)\n",
      "(184, 265, 341) (4, 4, 5)\n",
      "(62, 227, 104) (4, 4, 1)\n",
      "(306, 88, 384) (2, 2, 4)\n",
      "(61, 352, 278) (5, 5, 3)\n",
      "(214, 103, 184) (3, 3, 4)\n",
      "(261, 85, 186) (4, 4, 2)\n",
      "(107, 236, 313) (1, 1, 4)\n",
      "(257, 100, 71) (4, 4, 2)\n",
      "(292, 209, 141) (4, 4, 1)\n",
      "(231, 111, 157) (3, 3, 8)\n",
      "(358, 135, 253) (5, 5, 3)\n",
      "(248, 351, 322) (3, 3, 5)\n",
      "(38, 388, 108) (2, 2, 5)\n",
      "(73, 209, 393) (4, 4, 5)\n",
      "(120, 323, 97) (3, 3, 4)\n",
      "(244, 209, 323) (4, 4, 3)\n",
      "(201, 322, 388) (5, 5, 2)\n",
      "(80, 42, 104) (4, 4, 1)\n",
      "(231, 343, 113) (3, 3, 4)\n",
      "(318, 184, 369) (4, 4, 6)\n",
      "(19, 352, 45) (5, 5, 4)\n",
      "(28, 209, 327) (4, 4, 2)\n",
      "(177, 51, 294) (2, 2, 1)\n",
      "(285, 284, 274) (4, 4, 2)\n",
      "(127, 189, 240) (3, 3, 6)\n",
      "(96, 111, 270) (3, 3, 5)\n",
      "(195, 353, 314) (5, 5, 3)\n",
      "(358, 129, 221) (5, 5, 3)\n",
      "(178, 265, 63) (4, 4, 2)\n",
      "(384, 17, 180) (4, 4, 5)\n",
      "(89, 133, 214) (4, 4, 3)\n",
      "(190, 9, 245) (4, 4, 2)\n",
      "(68, 321, 328) (5, 5, 2)\n",
      "(203, 298, 127) (1, 1, 3)\n",
      "(357, 227, 343) (4, 4, 3)\n",
      "(63, 399, 72) (2, 2, 5)\n",
      "(234, 303, 344) (6, 6, 2)\n",
      "(111, 314, 242) (3, 3, 5)\n",
      "(88, 186, 350) (2, 2, 3)\n",
      "(23, 245, 209) (2, 2, 4)\n",
      "(77, 51, 318) (2, 2, 4)\n",
      "(249, 338, 260) (1, 1, 6)\n",
      "(322, 72, 206) (5, 5, 1)\n",
      "(72, 263, 113) (5, 5, 4)\n",
      "(322, 263, 209) (5, 5, 4)\n",
      "(171, 127, 3) (3, 3, 5)\n",
      "(62, 139, 61) (4, 4, 5)\n",
      "(78, 227, 197) (4, 4, 5)\n",
      "(100, 159, 352) (4, 4, 5)\n",
      "(61, 197, 209) (5, 5, 4)\n",
      "(73, 89, 36) (4, 4, 5)\n",
      "(153, 9, 350) (4, 4, 3)\n",
      "(61, 277, 117) (5, 5, 6)\n",
      "(59, 182, 51) (4, 4, 2)\n",
      "(277, 201, 104) (5, 5, 1)\n",
      "(214, 343, 276) (3, 3, 2)\n",
      "(257, 318, 65) (4, 4, 2)\n",
      "(32, 68, 7) (5, 5, 2)\n",
      "(85, 357, 350) (4, 4, 3)\n",
      "(59, 139, 299) (4, 4, 8)\n",
      "(257, 233, 369) (4, 4, 6)\n",
      "(159, 85, 243) (4, 4, 2)\n",
      "(52, 36, 221) (5, 5, 3)\n",
      "(114, 80, 262) (4, 4, 2)\n",
      "(97, 178, 253) (4, 4, 3)\n",
      "(107, 170, 389) (1, 1, 4)\n",
      "(353, 36, 249) (5, 5, 1)\n",
      "(184, 312, 51) (4, 4, 2)\n",
      "(372, 161, 294) (5, 5, 1)\n",
      "(220, 214, 62) (3, 3, 4)\n",
      "(173, 22, 343) (5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(triplets)\n",
    "for j in triplets[:300]:\n",
    "    print(j, (classes[j[0]], classes[j[1]], classes[j[2]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.12287313 1.9685363  2.46622639]\n",
      "Epoch 0, loss: 2.185878603747397, windowed_loss: 50\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.5612395  1.30639334 1.19089539]\n",
      "Epoch 1, loss: 1.352842741843426, windowed_loss: 50\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.00268668 0.64376445 0.51837886]\n",
      "Epoch 2, loss: 0.7216099983814991, windowed_loss: 50\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.1274671  0.81709481 0.61959608]\n",
      "Epoch 3, loss: 0.8547193313186819, windowed_loss: 0.9763906905145356\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.50510651 0.34517334 0.26567127]\n",
      "Epoch 4, loss: 0.37198370785424206, windowed_loss: 0.6494376791848077\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.71351198 0.49658227 0.36082154]\n",
      "Epoch 5, loss: 0.5236385970404653, windowed_loss: 0.5834472120711298\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.35010556 0.24943641 0.1960311 ]\n",
      "Epoch 6, loss: 0.26519102399999445, windowed_loss: 0.38693777629823395\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.24519241 0.17354695 0.12938538]\n",
      "Epoch 7, loss: 0.18270824872183078, windowed_loss: 0.32384595658743015\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.11187277 0.07575964 0.07022687]\n",
      "Epoch 8, loss: 0.08595309327497626, windowed_loss: 0.17795078866560052\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.06630702 0.04744554 0.04001862]\n",
      "Epoch 9, loss: 0.05125706134872004, windowed_loss: 0.10663946778184236\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.05718174 0.03052499 0.02889962]\n",
      "Epoch 10, loss: 0.03886878120741158, windowed_loss: 0.05869297861036929\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.03247749 0.01675124 0.01826178]\n",
      "Epoch 11, loss: 0.02249683750172456, windowed_loss: 0.037540893352618725\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.02923061 0.0203867  0.02099648]\n",
      "Epoch 12, loss: 0.023537928055068758, windowed_loss: 0.028301182254734963\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.01709886 0.0134937  0.01312643]\n",
      "Epoch 13, loss: 0.01457299862169858, windowed_loss: 0.0202025880594973\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.02613755 0.01352561 0.01482477]\n",
      "Epoch 14, loss: 0.018162642930154547, windowed_loss: 0.01875785653564063\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.01637917 0.01067961 0.01052654]\n",
      "Epoch 15, loss: 0.012528440957380968, windowed_loss: 0.015088027503078033\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.02142459 0.01039351 0.0144239 ]\n",
      "Epoch 16, loss: 0.015414003169897833, windowed_loss: 0.015368362352477781\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.01570072 0.00657511 0.01457482]\n",
      "Epoch 17, loss: 0.012283550236712801, windowed_loss: 0.013408664787997201\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.01498819 0.00541037 0.00940375]\n",
      "Epoch 18, loss: 0.0099341030317274, windowed_loss: 0.01254388547944601\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.01527077 0.0027586  0.01127399]\n",
      "Epoch 19, loss: 0.009767785442597939, windowed_loss: 0.01066181290367938\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00771354 0.0064349  0.0063845 ]\n",
      "Epoch 20, loss: 0.006844311853814305, windowed_loss: 0.008848733442713214\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0065441  0.00279246 0.00578215]\n",
      "Epoch 21, loss: 0.005039570443896632, windowed_loss: 0.007217222580102958\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0048827  0.00379569 0.00213219]\n",
      "Epoch 22, loss: 0.003603525036437945, windowed_loss: 0.00516246911138296\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00336088 0.00249566 0.004154  ]\n",
      "Epoch 23, loss: 0.0033368495377627282, windowed_loss: 0.003993315006032435\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0037393  0.00264179 0.0028184 ]\n",
      "Epoch 24, loss: 0.0030664987297672214, windowed_loss: 0.003335624434655965\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00343581 0.00162543 0.00211388]\n",
      "Epoch 25, loss: 0.0023917057410334096, windowed_loss: 0.0029316846695211195\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00582558 0.00377448 0.00449726]\n",
      "Epoch 26, loss: 0.004699104832428875, windowed_loss: 0.0033857697677431684\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00188771 0.00423635 0.00246315]\n",
      "Epoch 27, loss: 0.002862402745945887, windowed_loss: 0.0033177377731360568\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00397415 0.00210286 0.00202798]\n",
      "Epoch 28, loss: 0.002701661690618052, windowed_loss: 0.0034210564229976044\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0019677  0.00110682 0.00049326]\n",
      "Epoch 29, loss: 0.0011892618724342549, windowed_loss: 0.0022511087696660648\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00281806 0.00102055 0.00213918]\n",
      "Epoch 30, loss: 0.0019925941402713456, windowed_loss: 0.0019611725677745506\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00243213 0.00134033 0.00057543]\n",
      "Epoch 31, loss: 0.0014492960251641998, windowed_loss: 0.0015437173459566002\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00350204 0.00148951 0.00119823]\n",
      "Epoch 32, loss: 0.0020632616554697356, windowed_loss: 0.001835050606968427\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00187856 0.00175227 0.0015343 ]\n",
      "Epoch 33, loss: 0.0017217089224493866, windowed_loss: 0.0017447555343611074\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0013458  0.00121632 0.00063937]\n",
      "Epoch 34, loss: 0.0010671632533723657, windowed_loss: 0.0016173779437638292\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00122712 0.00049825 0.0011859 ]\n",
      "Epoch 35, loss: 0.0009704233626976156, windowed_loss: 0.0012530985128397893\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00142354 0.0010604  0.00036531]\n",
      "Epoch 36, loss: 0.0009497489328637267, windowed_loss: 0.000995778516311236\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0003779  0.0012037  0.00052712]\n",
      "Epoch 37, loss: 0.000702904537320137, windowed_loss: 0.0008743589442938264\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00018419 0.00043267 0.00012128]\n",
      "Epoch 38, loss: 0.0002460473245291999, windowed_loss: 0.0006329002649043545\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00118557 0.00092565 0.00040599]\n",
      "Epoch 39, loss: 0.0008390685261198969, windowed_loss: 0.0005960067959897445\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00128774 0.00089442 0.00033297]\n",
      "Epoch 40, loss: 0.0008383776823228055, windowed_loss: 0.0006411645109906341\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00068473 0.00134674 0.00032888]\n",
      "Epoch 41, loss: 0.0007867832865678903, windowed_loss: 0.0008214098316701975\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.80228698e-04 5.16815450e-05 1.43043528e-04]\n",
      "Epoch 42, loss: 0.000124984590167349, windowed_loss: 0.0005833818530193483\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00037965 0.00045433 0.00064283]\n",
      "Epoch 43, loss: 0.0004922679315010706, windowed_loss: 0.00046801193607877\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00061659 0.00085757 0.00020426]\n",
      "Epoch 44, loss: 0.000559473777133407, windowed_loss: 0.00039224209960060885\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0010551  0.00113021 0.00063754]\n",
      "Epoch 45, loss: 0.0009409501076196179, windowed_loss: 0.0006642306054180318\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00072363 0.00043817 0.00062513]\n",
      "Epoch 46, loss: 0.0005956437212951255, windowed_loss: 0.0006986892020160502\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.000286   0.00019313 0.00040092]\n",
      "Epoch 47, loss: 0.0002933473354487708, windowed_loss: 0.0006099803881211714\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00049805 0.00081597 0.00066867]\n",
      "Epoch 48, loss: 0.0006608987001307083, windowed_loss: 0.0005166299189582015\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00013727 0.00065032 0.00025123]\n",
      "Epoch 49, loss: 0.00034627442558606464, windowed_loss: 0.0004335068203885146\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00028091 0.00048654 0.0001277 ]\n",
      "Epoch 50, loss: 0.0002983825168374813, windowed_loss: 0.0004351852141847514\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.72412358e-04 1.76168640e-04 4.89216975e-05]\n",
      "Epoch 51, loss: 0.0003658342316295161, windowed_loss: 0.00033683039135102064\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.37219882e-04 3.53465703e-04 9.24056565e-05]\n",
      "Epoch 52, loss: 0.00022769708073500433, windowed_loss: 0.00029730460973400057\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.68875535e-05 6.28625381e-04 2.54346227e-04]\n",
      "Epoch 53, loss: 0.0003132863873333642, windowed_loss: 0.00030227256656596154\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00021501 0.00018901 0.00064772]\n",
      "Epoch 54, loss: 0.00035058007095799303, windowed_loss: 0.00029718784634212054\n",
      "LR: [0.01, 0.01, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00037535 0.00024955 0.00013555]\n",
      "Epoch 55, loss: 0.0002534826370802793, windowed_loss: 0.0003057830317905455\n",
      "Epoch 00056: reducing learning rate of group 0 to 8.0000e-03.\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0006026  0.00016235 0.00028768]\n",
      "Epoch 56, loss: 0.00035087781196290797, windowed_loss: 0.0003183135066670601\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00049516 0.00028292 0.00040344]\n",
      "Epoch 57, loss: 0.0003938417543064464, windowed_loss: 0.00033273406778321123\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.47317620e-04 5.10215844e-04 6.35370273e-05]\n",
      "Epoch 58, loss: 0.0003070234970161409, windowed_loss: 0.0003505810210951651\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00047771 0.00046462 0.        ]\n",
      "Epoch 59, loss: 0.0003141113415812001, windowed_loss: 0.0003383255309679291\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.26511366e-04 5.15717505e-04 7.79757446e-05]\n",
      "Epoch 60, loss: 0.00027340153853098553, windowed_loss: 0.00029817879237610886\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.82500617e-05 1.61075795e-04 1.18562444e-04]\n",
      "Epoch 61, loss: 0.0001026294335271373, windowed_loss: 0.00023004743787977434\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.68738547e-04 3.22028063e-04 6.76295974e-05]\n",
      "Epoch 62, loss: 0.0002527987358696533, windowed_loss: 0.00020960990264259202\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.13304535e-04 6.86224719e-04 4.52927568e-05]\n",
      "Epoch 63, loss: 0.0002816073370702339, windowed_loss: 0.00021234516882234148\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.28452155e-04 1.00726770e-05 3.42167914e-06]\n",
      "Epoch 64, loss: 0.00024731550365686417, windowed_loss: 0.0002605738588655838\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00045805 0.00011284 0.00025482]\n",
      "Epoch 65, loss: 0.00027523694955038303, windowed_loss: 0.000268053263425827\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.27054750e-05 1.18391080e-04 8.65833664e-05]\n",
      "Epoch 66, loss: 7.589330727403815e-05, windowed_loss: 0.00019948192016042848\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00023168 0.00022096 0.00055121]\n",
      "Epoch 67, loss: 0.00033461782291080016, windowed_loss: 0.0002285826932450738\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00052908 0.00012547 0.        ]\n",
      "Epoch 68, loss: 0.0002181852292833906, windowed_loss: 0.00020956545315607632\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.44912266e-04 2.89151445e-04 1.59645622e-06]\n",
      "Epoch 69, loss: 0.00027855338923858875, windowed_loss: 0.0002771188138109265\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.39090146e-05 3.75121409e-04 1.54671852e-04]\n",
      "Epoch 70, loss: 0.00019456742500716987, windowed_loss: 0.00023043534784304972\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.87417997e-05 4.08471054e-04 2.37128951e-04]\n",
      "Epoch 71, loss: 0.00024144726833610824, windowed_loss: 0.0002381893608606223\n",
      "LR: [0.01, 0.008, 0.01]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.27784566e-05 1.15755268e-04 4.54680147e-05]\n",
      "Epoch 72, loss: 7.800057981953476e-05, windowed_loss: 0.0001713384243876043\n",
      "Epoch 00073: reducing learning rate of group 0 to 8.0000e-03.\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.74265012e-05 3.84840014e-04 4.85590405e-04]\n",
      "Epoch 73, loss: 0.0003226189733003125, windowed_loss: 0.00021402227381865183\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0012816  0.00034809 0.00043467]\n",
      "Epoch 74, loss: 0.0006881191423445038, windowed_loss: 0.00036291289848811703\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.09327446e-05 8.72808424e-05 6.01744449e-05]\n",
      "Epoch 75, loss: 7.279601060982907e-05, windowed_loss: 0.0003611780420848818\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.89858400e-04 2.61881135e-05 1.53945928e-05]\n",
      "Epoch 76, loss: 0.00031048036885984016, windowed_loss: 0.00035713184060472434\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00015828 0.         0.        ]\n",
      "Epoch 77, loss: 5.2761173609531284e-05, windowed_loss: 0.00014534585102640016\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.95361843e-04 0.00000000e+00 4.33107330e-05]\n",
      "Epoch 78, loss: 7.955752538912225e-05, windowed_loss: 0.00014759968928616457\n",
      "LR: [0.01, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.94289973e-04 6.40563667e-06 9.06491821e-05]\n",
      "Epoch 79, loss: 0.0002304482640642108, windowed_loss: 0.00012092232102095477\n",
      "Epoch 00080: reducing learning rate of group 0 to 8.0000e-03.\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.44257888e-04 9.38238068e-05 8.60807063e-05]\n",
      "Epoch 80, loss: 0.00010805413352720665, windowed_loss: 0.0001393533076601799\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.01659445e-05 9.11932439e-05 9.85261392e-05]\n",
      "Epoch 81, loss: 7.996177583029777e-05, windowed_loss: 0.0001394880578072384\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.33056190e-05 8.79197297e-05 1.70693817e-04]\n",
      "Epoch 82, loss: 0.00011397305537353861, windowed_loss: 0.00010066298824368101\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.99753111e-04 1.37692402e-04 8.55390998e-05]\n",
      "Epoch 83, loss: 0.00034099487079815435, windowed_loss: 0.00017830990066733027\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00054176 0.         0.00045112]\n",
      "Epoch 84, loss: 0.0003309580638553157, windowed_loss: 0.0002619753300090029\n",
      "LR: [0.008, 0.008, 0.008]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.05194067e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 85, loss: 2.3506468895709876e-05, windowed_loss: 0.00023181980118305997\n",
      "Epoch 00086: reducing learning rate of group 0 to 6.4000e-03.\n",
      "LR: [0.008, 0.008, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00035535 0.00015079 0.        ]\n",
      "Epoch 86, loss: 0.0001687125274629304, windowed_loss: 0.000174392353404652\n",
      "LR: [0.008, 0.008, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.24132429e-05 7.75580040e-05 9.39975408e-06]\n",
      "Epoch 87, loss: 3.979033367200331e-05, windowed_loss: 7.733644334354786e-05\n",
      "LR: [0.008, 0.008, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.63343138e-06 2.83545052e-04 1.51071020e-04]\n",
      "Epoch 88, loss: 0.00014808316799727353, windowed_loss: 0.00011886200971073576\n",
      "LR: [0.008, 0.008, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.59011303e-05 0.00000000e+00 1.76719644e-04]\n",
      "Epoch 89, loss: 8.754025806080212e-05, windowed_loss: 9.180458657669298e-05\n",
      "LR: [0.008, 0.008, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00054487 0.00012877 0.        ]\n",
      "Epoch 90, loss: 0.00022454875888246477, windowed_loss: 0.00015339072831351347\n",
      "Epoch 00091: reducing learning rate of group 0 to 6.4000e-03.\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00027055 0.0004034  0.        ]\n",
      "Epoch 91, loss: 0.00022464956749569285, windowed_loss: 0.00017891286147965325\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.69701531e-05 9.75521451e-05 7.01721080e-05]\n",
      "Epoch 92, loss: 8.8231468742544e-05, windowed_loss: 0.00017914326504023386\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.77266581e-05 1.36624344e-04 0.00000000e+00]\n",
      "Epoch 93, loss: 7.145033415519829e-05, windowed_loss: 0.0001281104567978117\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.79360197e-04 0.00000000e+00 3.11419029e-05]\n",
      "Epoch 94, loss: 0.00010350069990663819, windowed_loss: 8.772750093479349e-05\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.23258003e-04 9.65532593e-05 2.23205848e-05]\n",
      "Epoch 95, loss: 8.071061562408101e-05, windowed_loss: 8.522054989530583e-05\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.09457326e-04 5.92961230e-05 6.18657267e-05]\n",
      "Epoch 96, loss: 7.687305862253362e-05, windowed_loss: 8.702812471775095e-05\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.90269537e-06 1.84069642e-04 3.39118256e-05]\n",
      "Epoch 97, loss: 7.529472085562621e-05, windowed_loss: 7.762613170074695e-05\n",
      "LR: [0.008, 0.0064, 0.0064]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00067842 0.00021116 0.00015144]\n",
      "Epoch 98, loss: 0.0003470053726976568, windowed_loss: 0.0001663910507252722\n",
      "Epoch 00099: reducing learning rate of group 0 to 5.1200e-03.\n",
      "LR: [0.008, 0.0064, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.35306605e-04 3.98501076e-05 4.94125892e-06]\n",
      "Epoch 99, loss: 0.00019336599066401973, windowed_loss: 0.00020522202807243426\n",
      "LR: [0.008, 0.0064, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.99268486e-05 2.62226571e-06 1.02176754e-04]\n",
      "Epoch 100, loss: 5.157528953118757e-05, windowed_loss: 0.00019731555096428805\n",
      "LR: [0.008, 0.0064, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.70221890e-04 1.39667145e-04 3.03880396e-05]\n",
      "Epoch 101, loss: 0.00014675902484944373, windowed_loss: 0.000130566768348217\n",
      "LR: [0.008, 0.0064, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 6.69460405e-04 1.54367563e-05]\n",
      "Epoch 102, loss: 0.00022829905378096032, windowed_loss: 0.00014221112272053054\n",
      "LR: [0.008, 0.0064, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00014197 0.00018198 0.00018964]\n",
      "Epoch 103, loss: 0.0001711966187664957, windowed_loss: 0.0001820848991322999\n",
      "Epoch 00104: reducing learning rate of group 0 to 5.1200e-03.\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.88544223e-04 0.00000000e+00 5.98498366e-05]\n",
      "Epoch 104, loss: 8.279801995465249e-05, windowed_loss: 0.0001607645641673695\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 5.42591919e-05 2.06939876e-06]\n",
      "Epoch 105, loss: 1.877619687354926e-05, windowed_loss: 9.092361186489916e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.02445483e-05 1.73684887e-05 4.38983129e-05]\n",
      "Epoch 106, loss: 2.383711663159457e-05, windowed_loss: 4.1803777819932106e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.38884576e-05 2.00180168e-05 4.22182070e-05]\n",
      "Epoch 107, loss: 4.870822709618193e-05, windowed_loss: 3.044051353377525e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.61421227e-05 5.77115200e-06 8.72835517e-06]\n",
      "Epoch 108, loss: 3.688054328615015e-05, windowed_loss: 3.647529567130889e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.42533670e-05 1.50972977e-04]\n",
      "Epoch 109, loss: 6.174211474982175e-05, windowed_loss: 4.911029504405128e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 4.51986085e-05 0.00000000e+00]\n",
      "Epoch 110, loss: 1.5066202842827998e-05, windowed_loss: 3.7896286959599974e-05\n",
      "LR: [0.008, 0.00512, 0.00512]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.52007760e-05 0.00000000e+00 1.44838948e-04]\n",
      "Epoch 111, loss: 6.0013241388581015e-05, windowed_loss: 4.560718632707692e-05\n",
      "Epoch 00112: reducing learning rate of group 0 to 4.0960e-03.\n",
      "LR: [0.008, 0.00512, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 112, loss: 0.0, windowed_loss: 2.5026481410469672e-05\n",
      "LR: [0.008, 0.00512, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 4.39516523e-06 0.00000000e+00]\n",
      "Epoch 113, loss: 1.465055075558749e-06, windowed_loss: 2.0492765488046587e-05\n",
      "LR: [0.008, 0.00512, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.48715282e-04 7.98319551e-05 4.21599570e-04]\n",
      "Epoch 114, loss: 0.0002167156022606474, windowed_loss: 7.272688577873538e-05\n",
      "LR: [0.008, 0.00512, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.49285590e-04 4.62184914e-05 0.00000000e+00]\n",
      "Epoch 115, loss: 6.516802717338909e-05, windowed_loss: 9.44495615031984e-05\n",
      "Epoch 00116: reducing learning rate of group 0 to 6.4000e-03.\n",
      "LR: [0.0064, 0.00512, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.67280093e-05 9.27732749e-05 0.00000000e+00]\n",
      "Epoch 116, loss: 6.316709473277582e-05, windowed_loss: 0.0001150169080556041\n",
      "Epoch 00117: reducing learning rate of group 0 to 4.0960e-03.\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00019894 0.00022971 0.        ]\n",
      "Epoch 117, loss: 0.0001428827191844131, windowed_loss: 9.040594703019267e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.23002312e-05 1.93122436e-05 8.08929855e-06]\n",
      "Epoch 118, loss: 1.3233924453908749e-05, windowed_loss: 7.309457945703256e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.86585225e-06 0.00000000e+00 2.81918117e-05]\n",
      "Epoch 119, loss: 1.2352554635568097e-05, windowed_loss: 5.6156399424629984e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.19212676e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 120, loss: 3.973755872610844e-06, windowed_loss: 9.85341165402923e-06\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00021815 0.        ]\n",
      "Epoch 121, loss: 7.271614264358173e-05, windowed_loss: 2.9680817717253556e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.89392404e-05 0.00000000e+00 1.31321563e-05]\n",
      "Epoch 122, loss: 1.4023798884767475e-05, windowed_loss: 3.0237899133653347e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0001199 0.        0.       ]\n",
      "Epoch 123, loss: 3.996581742257783e-05, windowed_loss: 4.223525298364234e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.004096000000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 124, loss: 0.0, windowed_loss: 1.79965387691151e-05\n",
      "Epoch 00125: reducing learning rate of group 0 to 3.2768e-03.\n",
      "LR: [0.0064, 0.004096000000000001, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.5218522e-06 0.0000000e+00 0.0000000e+00]\n",
      "Epoch 125, loss: 8.40617400227171e-07, windowed_loss: 1.3602144940935001e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00024413 0.        ]\n",
      "Epoch 126, loss: 8.13781199130145e-05, windowed_loss: 2.740624577108056e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 2.34948979e-05 3.78943302e-05]\n",
      "Epoch 127, loss: 2.0463076053243697e-05, windowed_loss: 3.422727112216179e-05\n",
      "LR: [0.0064, 0.004096000000000001, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [6.30251386e-05 8.70944085e-05 6.25271350e-05]\n",
      "Epoch 128, loss: 7.088222738468285e-05, windowed_loss: 5.757447445031369e-05\n",
      "Epoch 00129: reducing learning rate of group 0 to 5.1200e-03.\n",
      "LR: [0.00512, 0.004096000000000001, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.75191257e-05 0.00000000e+00 8.03533264e-05]\n",
      "Epoch 129, loss: 4.262415071328481e-05, windowed_loss: 4.465648471707045e-05\n",
      "Epoch 00130: reducing learning rate of group 0 to 3.2768e-03.\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.56334512e-05 1.68511983e-04 0.00000000e+00]\n",
      "Epoch 130, loss: 8.804847796758015e-05, windowed_loss: 6.718495202184928e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0002152 0.000192  0.       ]\n",
      "Epoch 131, loss: 0.0001357346208709659, windowed_loss: 8.880241651727696e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.43802979e-05 1.28034841e-05 0.00000000e+00]\n",
      "Epoch 132, loss: 9.061260656876998e-06, windowed_loss: 7.761478649847435e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.71602111e-05 4.71225516e-05 0.00000000e+00]\n",
      "Epoch 133, loss: 2.1427587577790927e-05, windowed_loss: 5.540782303521127e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.19292601e-04 7.47904520e-05]\n",
      "Epoch 134, loss: 6.469435086756042e-05, windowed_loss: 3.1727733034076117e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.33113427e-05 9.04933973e-05 0.00000000e+00]\n",
      "Epoch 135, loss: 3.793491332819968e-05, windowed_loss: 4.135228392451701e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.41311097e-05 5.09919429e-05 0.00000000e+00]\n",
      "Epoch 136, loss: 2.8374350883743982e-05, windowed_loss: 4.3667871693168026e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.0032768000000000007]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.66888433e-04 5.66989183e-06 1.29956921e-04]\n",
      "Epoch 137, loss: 0.00010083841555046313, windowed_loss: 5.571589325413559e-05\n",
      "Epoch 00138: reducing learning rate of group 0 to 2.6214e-03.\n",
      "LR: [0.00512, 0.0032768000000000007, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00017778 0.         0.        ]\n",
      "Epoch 138, loss: 5.92602247541601e-05, windowed_loss: 6.28243303961224e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 7.96924261e-06 0.00000000e+00]\n",
      "Epoch 139, loss: 2.656414201765349e-06, windowed_loss: 5.425168483546286e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.08897685e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 140, loss: 1.0296589497363927e-05, windowed_loss: 2.407107615109646e-05\n",
      "LR: [0.00512, 0.0032768000000000007, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.02348287e-04 1.28817152e-05]\n",
      "Epoch 141, loss: 3.8410000728838376e-05, windowed_loss: 1.7121001475989216e-05\n",
      "Epoch 00142: reducing learning rate of group 0 to 4.0960e-03.\n",
      "LR: [0.004096000000000001, 0.0032768000000000007, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 9.88373702e-05 0.00000000e+00]\n",
      "Epoch 142, loss: 3.294579007408836e-05, windowed_loss: 2.7217460100096887e-05\n",
      "Epoch 00143: reducing learning rate of group 0 to 2.6214e-03.\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 7.12072307e-05 7.59620558e-06]\n",
      "Epoch 143, loss: 2.626781210754857e-05, windowed_loss: 3.2541200970158435e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.32451003e-06 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 144, loss: 4.4150334416013776e-07, windowed_loss: 1.988503517526569e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.24762680e-05 7.85005025e-05 0.00000000e+00]\n",
      "Epoch 145, loss: 4.032559015534141e-05, windowed_loss: 2.2344968535683375e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.97486444e-04 5.19276681e-05 0.00000000e+00]\n",
      "Epoch 146, loss: 8.313803736007576e-05, windowed_loss: 4.1301710286525766e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.48496336e-04 5.11898913e-05 0.00000000e+00]\n",
      "Epoch 147, loss: 9.989540911082066e-05, windowed_loss: 7.445301220874594e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 8.39968297e-06 0.00000000e+00]\n",
      "Epoch 148, loss: 2.799894322048534e-06, windowed_loss: 6.194444693098166e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.43255019e-05 5.19779595e-06 0.00000000e+00]\n",
      "Epoch 149, loss: 2.9841099273074757e-05, windowed_loss: 4.4178800901981314e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002621440000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00025647 0.         0.        ]\n",
      "Epoch 150, loss: 8.548937286391403e-05, windowed_loss: 3.937678881967911e-05\n",
      "Epoch 00151: reducing learning rate of group 0 to 2.0972e-03.\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.00979412e-06 2.82952731e-06 0.00000000e+00]\n",
      "Epoch 151, loss: 1.6131071430264097e-06, windowed_loss: 3.89811930933384e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 152, loss: 0.0, windowed_loss: 2.903416000231348e-05\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.91534107e-05 2.00742348e-06]\n",
      "Epoch 153, loss: 7.05361140496803e-06, windowed_loss: 2.888906182664813e-06\n",
      "LR: [0.004096000000000001, 0.002621440000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.39290974e-05 1.95970589e-05 0.00000000e+00]\n",
      "Epoch 154, loss: 1.7842052109313737e-05, windowed_loss: 8.298554504760589e-06\n",
      "Epoch 00155: reducing learning rate of group 0 to 3.2768e-03.\n",
      "LR: [0.0032768000000000007, 0.002621440000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.98148867e-05 1.47132034e-05]\n",
      "Epoch 155, loss: 1.8176030028950084e-05, windowed_loss: 1.4357231181077284e-05\n",
      "Epoch 00156: reducing learning rate of group 0 to 2.0972e-03.\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 6.18486242e-05 0.00000000e+00]\n",
      "Epoch 156, loss: 2.061620806202744e-05, windowed_loss: 1.887809673343042e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.89182771e-05 2.25448642e-04 0.00000000e+00]\n",
      "Epoch 157, loss: 8.812230644804059e-05, windowed_loss: 4.2304848179672696e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.60179693e-05 4.88549810e-05 7.88928433e-05]\n",
      "Epoch 158, loss: 5.458859783230406e-05, windowed_loss: 5.44423707807907e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 5.53356314e-05 0.00000000e+00]\n",
      "Epoch 159, loss: 1.844521047491016e-05, windowed_loss: 5.371870491841828e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 160, loss: 0.0, windowed_loss: 2.4344602769071404e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.46470286e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 161, loss: 8.215676202918544e-06, windowed_loss: 8.8869622259429e-06\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.28100539e-05 7.26692379e-05 0.00000000e+00]\n",
      "Epoch 162, loss: 4.182643059528235e-05, windowed_loss: 1.6680702266066967e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002097152000000001]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 163, loss: 0.0, windowed_loss: 1.6680702266066967e-05\n",
      "Epoch 00164: reducing learning rate of group 0 to 2.0000e-03.\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 164, loss: 0.0, windowed_loss: 1.3942143531760785e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.19155777e-05 0.00000000e+00 1.56688758e-04]\n",
      "Epoch 165, loss: 7.953477854078467e-05, windowed_loss: 2.6511592846928224e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 166, loss: 0.0, windowed_loss: 2.6511592846928224e-05\n",
      "LR: [0.0032768000000000007, 0.002097152000000001, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.79864462e-05 1.89241361e-05 0.00000000e+00]\n",
      "Epoch 167, loss: 3.563686076438788e-05, windowed_loss: 3.839054643505752e-05\n",
      "Epoch 00168: reducing learning rate of group 0 to 2.6214e-03.\n",
      "LR: [0.002621440000000001, 0.002097152000000001, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.77975405e-04 7.70129263e-05 0.00000000e+00]\n",
      "Epoch 168, loss: 8.499611056212223e-05, windowed_loss: 4.0210990442170034e-05\n",
      "Epoch 00169: reducing learning rate of group 0 to 2.0000e-03.\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.77271664e-05 7.35309652e-05 0.00000000e+00]\n",
      "Epoch 169, loss: 3.3752710530252166e-05, windowed_loss: 5.146189395225409e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00026432 0.        ]\n",
      "Epoch 170, loss: 8.810802616856314e-05, windowed_loss: 6.89522824203125e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00012909 0.00012319]\n",
      "Epoch 171, loss: 8.409267122095281e-05, windowed_loss: 6.865113597325604e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.16884708e-05 7.99355859e-05 0.00000000e+00]\n",
      "Epoch 172, loss: 3.387468556563059e-05, windowed_loss: 6.869179431838217e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.67508355e-05 1.60888345e-04]\n",
      "Epoch 173, loss: 6.587972695177251e-05, windowed_loss: 6.128236124611863e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 174, loss: 0.0, windowed_loss: 3.325147083913437e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00012115 0.        ]\n",
      "Epoch 175, loss: 4.0383275711175166e-05, windowed_loss: 3.5421000887649226e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.41171228e-05 8.23024999e-05 0.00000000e+00]\n",
      "Epoch 176, loss: 4.547320757851457e-05, windowed_loss: 2.861882776322991e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 177, loss: 0.0, windowed_loss: 2.861882776322991e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 178, loss: 0.0, windowed_loss: 1.5157735859504857e-05\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.69410963e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 179, loss: 5.647032098336653e-06, windowed_loss: 1.8823440327788843e-06\n",
      "LR: [0.002621440000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 180, loss: 0.0, windowed_loss: 1.8823440327788843e-06\n",
      "Epoch 00181: reducing learning rate of group 0 to 2.0972e-03.\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 181, loss: 0.0, windowed_loss: 1.8823440327788843e-06\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.01322137e-05 5.72577119e-05 0.00000000e+00]\n",
      "Epoch 182, loss: 3.246330853664514e-05, windowed_loss: 1.0821102845548379e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.48259440e-05 1.38291242e-05 0.00000000e+00]\n",
      "Epoch 183, loss: 2.2885022741375547e-05, windowed_loss: 1.8449443759340227e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 0.00000000e+00 1.94109638e-05]\n",
      "Epoch 184, loss: 6.470321254296736e-06, windowed_loss: 2.060621751077247e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.95556066e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 185, loss: 9.851868857036937e-06, windowed_loss: 1.3069070950903072e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.35764480e-04 8.80743292e-06 0.00000000e+00]\n",
      "Epoch 186, loss: 4.8190637519865326e-05, windowed_loss: 2.1504275877066335e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.49091874e-05 6.24368814e-05]\n",
      "Epoch 187, loss: 3.2448689594413295e-05, windowed_loss: 3.016373199043852e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 188, loss: 0.0, windowed_loss: 2.687977570475954e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.27688385e-05 6.51451674e-06 2.05054371e-04]\n",
      "Epoch 189, loss: 9.811257548404463e-05, windowed_loss: 4.3520421692819305e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [9.18814066e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 190, loss: 3.062713552605022e-05, windowed_loss: 4.291323700336495e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.43543902e-05 0.00000000e+00]\n",
      "Epoch 191, loss: 4.7847967256199224e-06, windowed_loss: 4.4508169245238255e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 192, loss: 0.0, windowed_loss: 1.180397741722338e-05\n",
      "LR: [0.002097152000000001, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 193, loss: 0.0, windowed_loss: 1.5949322418733074e-06\n",
      "Epoch 00194: reducing learning rate of group 0 to 2.0000e-03.\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00017995 0.        ]\n",
      "Epoch 194, loss: 5.998389061653253e-05, windowed_loss: 1.9994630205510842e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 195, loss: 0.0, windowed_loss: 1.9994630205510842e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 196, loss: 0.0, windowed_loss: 1.9994630205510842e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.41907144e-05 6.17036765e-05]\n",
      "Epoch 197, loss: 3.196479696216005e-05, windowed_loss: 1.0654932320720018e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.39436937e-05 0.00000000e+00 4.70758162e-06]\n",
      "Epoch 198, loss: 1.6217091769883126e-05, windowed_loss: 1.6060629577347726e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.57202171e-04 0.00000000e+00 2.85106626e-05]\n",
      "Epoch 199, loss: 6.190427776538964e-05, windowed_loss: 3.66953888324776e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.58646567e-05 8.38215717e-05 0.00000000e+00]\n",
      "Epoch 200, loss: 3.322874280539426e-05, windowed_loss: 3.711670411355568e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00012988 0.00012576]\n",
      "Epoch 201, loss: 8.521268539356463e-05, windowed_loss: 6.011523532144951e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.48681075e-05 1.83116137e-04 8.76706432e-05]\n",
      "Epoch 202, loss: 0.00010855162911342853, windowed_loss: 7.566435243746247e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.30037184e-04 0.00000000e+00 2.47511674e-06]\n",
      "Epoch 203, loss: 4.4170767068862915e-05, windowed_loss: 7.93116938586187e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 204, loss: 0.0, windowed_loss: 5.090746539409715e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 205, loss: 0.0, windowed_loss: 1.4723589022954306e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 2.34044750e-05 1.59578059e-04]\n",
      "Epoch 206, loss: 6.099417805671692e-05, windowed_loss: 2.0331392685572307e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.11943954e-06 2.90195034e-05 0.00000000e+00]\n",
      "Epoch 207, loss: 1.2379647655920548e-05, windowed_loss: 2.445794190421249e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 8.29278407e-05 0.00000000e+00]\n",
      "Epoch 208, loss: 2.764261355905822e-05, windowed_loss: 3.3672146423898565e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.17072666e-04 0.00000000e+00 8.06804746e-05]\n",
      "Epoch 209, loss: 6.591771362405835e-05, windowed_loss: 3.531332494634571e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.92094932e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 210, loss: 9.73649774536942e-06, windowed_loss: 3.4432274976161996e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.98442828e-05 0.00000000e+00]\n",
      "Epoch 211, loss: 6.614760919050737e-06, windowed_loss: 2.742299076282617e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 3.15828418e-05 0.00000000e+00]\n",
      "Epoch 212, loss: 1.0527613939660968e-05, windowed_loss: 8.959624201360374e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.14135104e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 213, loss: 1.047117014726003e-05, windowed_loss: 9.204515001990579e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.44836238e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 214, loss: 8.161207943251638e-06, windowed_loss: 9.719997343390879e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 215, loss: 0.0, windowed_loss: 6.210792696837223e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 216, loss: 0.0, windowed_loss: 2.720402647750546e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00026544 0.        ]\n",
      "Epoch 217, loss: 8.847908765980691e-05, windowed_loss: 2.9493029219935635e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.45979561e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 218, loss: 2.819931868350867e-05, windowed_loss: 3.889280211443852e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 219, loss: 0.0, windowed_loss: 3.889280211443852e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 7.24535097e-06 8.66448337e-05]\n",
      "Epoch 220, loss: 3.129672823530255e-05, windowed_loss: 1.983201563960374e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.33630902e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 221, loss: 1.778769673723163e-05, windowed_loss: 1.6361474990844727e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.10607764e-04 1.85639682e-05 0.00000000e+00]\n",
      "Epoch 222, loss: 4.305724393237721e-05, windowed_loss: 3.0713889634970464e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.91474841e-05 0.00000000e+00 3.11413949e-05]\n",
      "Epoch 223, loss: 1.6762959686192598e-05, windowed_loss: 2.5869300118600482e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 0.00000000e+00 7.17822801e-05]\n",
      "Epoch 224, loss: 2.3927426699436072e-05, windowed_loss: 2.7915876772668624e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.87311829e-04 7.54301860e-05 4.11837616e-05]\n",
      "Epoch 225, loss: 0.00013464192549387616, windowed_loss: 5.844410395983494e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 226, loss: 0.0, windowed_loss: 5.2856450731104075e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [6.57390126e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 227, loss: 2.1913004192438994e-05, windowed_loss: 5.218497656210505e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 0.00000000e+00 3.31493264e-05]\n",
      "Epoch 228, loss: 1.1049775463162048e-05, windowed_loss: 1.098759321853368e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 229, loss: 0.0, windowed_loss: 1.098759321853368e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0000000e+00 0.0000000e+00 2.6888976e-05]\n",
      "Epoch 230, loss: 8.962992014306964e-06, windowed_loss: 6.67092249248967e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.30623918e-05 1.66136094e-05]\n",
      "Epoch 231, loss: 9.892000393434005e-06, windowed_loss: 6.28499746924699e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 232, loss: 0.0, windowed_loss: 6.28499746924699e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.8021295e-05 0.0000000e+00 0.0000000e+00]\n",
      "Epoch 233, loss: 9.340431654092038e-06, windowed_loss: 6.410810682508681e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.62148340e-05 3.86456536e-05 0.00000000e+00]\n",
      "Epoch 234, loss: 1.8286829193433125e-05, windowed_loss: 9.209086949175054e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.49552453e-06 0.00000000e+00 5.18245453e-05]\n",
      "Epoch 235, loss: 2.0106689948024172e-05, windowed_loss: 1.5911316931849777e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 236, loss: 0.0, windowed_loss: 1.27978397138191e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 237, loss: 0.0, windowed_loss: 6.702229982674724e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 238, loss: 0.0, windowed_loss: 0.0\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 239, loss: 0.0, windowed_loss: 0.0\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0000000e+00 6.0825524e-06 0.0000000e+00]\n",
      "Epoch 240, loss: 2.027517466834097e-06, windowed_loss: 6.758391556113657e-07\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.        0.0002017 0.       ]\n",
      "Epoch 241, loss: 6.72320073301142e-05, windowed_loss: 2.3086508265649433e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 242, loss: 0.0, windowed_loss: 2.3086508265649433e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.58348544e-05 0.00000000e+00]\n",
      "Epoch 243, loss: 5.278284802581325e-06, windowed_loss: 2.4170097377565176e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 244, loss: 0.0, windowed_loss: 1.7594282675271084e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.01847403e-05 0.00000000e+00 1.67272308e-05]\n",
      "Epoch 245, loss: 2.2303990342400294e-05, windowed_loss: 9.194091714993873e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 0.00000000e+00 1.19563192e-05]\n",
      "Epoch 246, loss: 3.9854397376378374e-06, windowed_loss: 8.76314336001271e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 4.19501554e-05 5.22250140e-05]\n",
      "Epoch 247, loss: 3.1391723137913324e-05, windowed_loss: 1.9227051072650484e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.71255996e-05 0.00000000e+00 7.49565661e-05]\n",
      "Epoch 248, loss: 4.069405523213473e-05, windowed_loss: 2.5357072702561966e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [6.89720566e-06 0.00000000e+00 5.88321550e-05]\n",
      "Epoch 249, loss: 2.1909786896272138e-05, windowed_loss: 3.13318550887734e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.31697309e-04 2.08059156e-05]\n",
      "Epoch 250, loss: 5.0834408312132865e-05, windowed_loss: 3.781275014684658e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 251, loss: 0.0, windowed_loss: 2.4248065069468333e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.42620367e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 252, loss: 1.475401222705841e-05, windowed_loss: 2.1862806846397093e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.6182898e-05 0.0000000e+00 0.0000000e+00]\n",
      "Epoch 253, loss: 1.2060966004024854e-05, windowed_loss: 8.938326077027755e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 0.00000000e+00 3.21785496e-05]\n",
      "Epoch 254, loss: 1.0726183201327467e-05, windowed_loss: 1.2513720477470245e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 255, loss: 0.0, windowed_loss: 7.595716401784107e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.66806646e-05 0.00000000e+00]\n",
      "Epoch 256, loss: 5.56022154562401e-06, windowed_loss: 5.428801582317158e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.17616555e-06 6.01719049e-06 1.27354129e-06]\n",
      "Epoch 257, loss: 5.1556324416940856e-06, windowed_loss: 3.571951329106032e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 258, loss: 0.0, windowed_loss: 3.571951329106032e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00014543 0.00033949 0.        ]\n",
      "Epoch 259, loss: 0.00016163933006199923, windowed_loss: 5.559832083456444e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.49666245e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 260, loss: 1.4988874847238714e-05, windowed_loss: 5.8876068303079315e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 261, loss: 0.0, windowed_loss: 5.8876068303079315e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.48026441e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 262, loss: 8.267548048135007e-06, windowed_loss: 7.752140965124574e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 263, loss: 0.0, windowed_loss: 2.7558493493783354e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 264, loss: 0.0, windowed_loss: 2.7558493493783354e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.29490412e-05 1.92702494e-04 0.00000000e+00]\n",
      "Epoch 265, loss: 7.85505116888971e-05, windowed_loss: 2.6183503896299036e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 266, loss: 0.0, windowed_loss: 2.6183503896299036e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.07930127e-05 0.00000000e+00]\n",
      "Epoch 267, loss: 3.5976708838433926e-06, windowed_loss: 2.7382727524246833e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.         0.00013012]\n",
      "Epoch 268, loss: 4.3374570933255285e-05, windowed_loss: 1.565741393903289e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 5.55075028e-05 0.00000000e+00]\n",
      "Epoch 269, loss: 1.850250092419711e-05, windowed_loss: 2.1824914247098596e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 270, loss: 0.0, windowed_loss: 2.06256906191508e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 271, loss: 0.0, windowed_loss: 6.167500308065704e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 272, loss: 0.0, windowed_loss: 0.0\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 273, loss: 0.0, windowed_loss: 0.0\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00019387 0.        ]\n",
      "Epoch 274, loss: 6.462272369500363e-05, windowed_loss: 2.1540907898334543e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [4.35869125e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 275, loss: 1.4528970826755872e-05, windowed_loss: 2.6383898173919833e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.14693895e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 276, loss: 2.715646317510894e-05, windowed_loss: 3.543605256562281e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0001339 0.        0.       ]\n",
      "Epoch 277, loss: 4.463456571102142e-05, windowed_loss: 2.877333323762875e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.         0.00012521 0.        ]\n",
      "Epoch 278, loss: 4.173787028500528e-05, windowed_loss: 3.784296639037854e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [6.11658801e-06 3.66470353e-05 0.00000000e+00]\n",
      "Epoch 279, loss: 1.425454110810251e-05, windowed_loss: 3.3542325701376403e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [8.5581602e-05 0.0000000e+00 0.0000000e+00]\n",
      "Epoch 280, loss: 2.852720067356572e-05, windowed_loss: 2.8173204022224502e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.67047097e-05 4.19002026e-05]\n",
      "Epoch 281, loss: 1.953497077479507e-05, windowed_loss: 2.07722375188211e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 282, loss: 0.0, windowed_loss: 1.6020723816120263e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.90733508e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 283, loss: 9.691116936279066e-06, windowed_loss: 9.742029237024711e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 7.99105249e-05 0.00000000e+00]\n",
      "Epoch 284, loss: 2.66368416222659e-05, windowed_loss: 1.2109319519514988e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [3.46147201e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 285, loss: 1.1538240042599766e-05, windowed_loss: 1.595539953371491e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 286, loss: 0.0, windowed_loss: 1.2725027221621888e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 287, loss: 0.0, windowed_loss: 3.846080014199922e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 288, loss: 0.0, windowed_loss: 0.0\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [1.07059763e-05 4.34001400e-05 0.00000000e+00]\n",
      "Epoch 289, loss: 1.8035372098286945e-05, windowed_loss: 6.0117906994289815e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [5.59199940e-05 0.00000000e+00 5.03396785e-05]\n",
      "Epoch 290, loss: 3.541989082639868e-05, windowed_loss: 1.781842097489521e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.0000000e+00 2.3229725e-05 0.0000000e+00]\n",
      "Epoch 291, loss: 7.743241660522692e-06, windowed_loss: 2.0399501528402774e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 292, loss: 0.0, windowed_loss: 1.438771082897379e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 1.31297857e-05 0.00000000e+00]\n",
      "Epoch 293, loss: 4.376595218976338e-06, windowed_loss: 4.039945626499677e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 294, loss: 0.0, windowed_loss: 1.4588650729921128e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 295, loss: 0.0, windowed_loss: 1.4588650729921128e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [7.66050071e-05 0.00000000e+00 0.00000000e+00]\n",
      "Epoch 296, loss: 2.553500235080719e-05, windowed_loss: 8.511667450269064e-06\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0.00000000e+00 8.91878524e-05 0.00000000e+00]\n",
      "Epoch 297, loss: 2.97292841203285e-05, windowed_loss: 1.8421428823711897e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [2.30404125e-05 5.77724793e-06 2.53150409e-06]\n",
      "Epoch 298, loss: 1.0449721506147673e-05, windowed_loss: 2.190466932576112e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Losses: [0. 0. 0.]\n",
      "Epoch 299, loss: 0.0, windowed_loss: 1.3393001875492058e-05\n",
      "LR: [0.002, 0.002, 0.002]\n",
      "Total Pre-training Time: 4885.781047582626\n"
     ]
    }
   ],
   "source": [
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "ensemble = Ensemble(size=3, output_size=5, lr=1e-2, weight_decay=0, new_model=True, dynamic_lr=True, manual_schedulers=True, init=\"Random\")\n",
    "if ENSEMBLE_PATH is not None:\n",
    "    ensemble.load_ensemble(ENSEMBLE_PATH, full=True)\n",
    "sampled_dataset = DATASET\n",
    "\n",
    "def pretraining(data, ensemble, data_cutoff=None, data_size=500):\n",
    "    if data_cutoff is None:\n",
    "        data_cutoff = len(data) - 1\n",
    "    # np.random.seed(0)\n",
    "    random.shuffle(triplets)\n",
    "    samples = triplets[:data_size]\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "\n",
    "    BATCH_SIZE = 4096\n",
    "    total_updates = 0\n",
    "    total_batches = max(len(samples), data_size) // BATCH_SIZE\n",
    "\n",
    "    # Batch the data\n",
    "    for i in range(0, len(samples), BATCH_SIZE):\n",
    "        # AUGMENT_SIZE = 1\n",
    "        if i + (BATCH_SIZE) >= len(samples):\n",
    "            continue\n",
    "\n",
    "        print(f\"Unsupervised Training.. {(total_updates * 100) / total_batches}\")\n",
    "\n",
    "        temp_losses = np.array([0.0 for _ in ensemble.ensemble])\n",
    "\n",
    "        anchors = np.array([data[samples[i + j][0]][0] for j in range(BATCH_SIZE)])\n",
    "\n",
    "        pretraining = random.random() < 0.6\n",
    "        if pretraining:\n",
    "            positives = np.array(\n",
    "                [\n",
    "                    getRandomTransformation(data[samples[i + j][0]][0]) for j in range(BATCH_SIZE)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            positives = np.array(\n",
    "                [\n",
    "                    getRandomFlip(data[samples[i + j][1]][0]) for j in range(BATCH_SIZE)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        negatives = np.array([data[samples[i + j][2]][0] for j in range(BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        temp_losses += losses\n",
    "\n",
    "        total_loss += temp_losses\n",
    "        total_updates += 1\n",
    "\n",
    "    return total_loss, max(total_updates, 1)\n",
    "\n",
    "t_1 = time.time()\n",
    "epochs = 0\n",
    "loss_history = []\n",
    "while epochs < 300:\n",
    "    losses, total_updates = pretraining(sampled_dataset, ensemble, data_cutoff=9999, data_size=(4096 * 12))\n",
    "    average_loss = losses / total_updates\n",
    "    locale_loss = sum(average_loss) / len(average_loss)\n",
    "    loss_history.append(locale_loss)\n",
    "    loss = (sum(loss_history[-3:]) / 3) if len(loss_history) > 3 else 50\n",
    "    print(f\"Losses: {average_loss}\")\n",
    "    print(f\"Epoch {epochs}, loss: {locale_loss}, windowed_loss: {loss}\")\n",
    "    epochs += 1\n",
    "    ensemble.step_schedulers(losses)\n",
    "    print(f\"LR: {ensemble.get_lr()}\")\n",
    "\n",
    "print(f\"Total Pre-training Time: {time.time() - t_1}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "ensemble.save_ensemble(f\"../checkpoints/ensembles/{int(time.time())}\", full=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
