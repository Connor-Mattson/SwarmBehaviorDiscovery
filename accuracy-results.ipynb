{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from src.networks.embedding import NoveltyEmbedding\n",
    "from src.networks.archive import DataAggregationArchive\n",
    "from src.networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 1000\n"
     ]
    }
   ],
   "source": [
    "# For single Sensor Baseline Model\n",
    "# TRUTH_FILE = \"validation-data-two-sensor.txt\"\n",
    "# TRUTH_FILE = \"validation-data-baseline.txt\"\n",
    "\n",
    "\"\"\"\n",
    "RANDOM - Only Random Weight Initialization\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = None\n",
    "\n",
    "\"\"\"\n",
    "BASELINE - Pretraining only. No HIL.\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-20-23-baseline\"\n",
    "\n",
    "\"\"\"\n",
    "BASELINE - Pretraining + HIL.\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-25-23-baseline-HIL-H\"\n",
    "\n",
    "\"\"\"\n",
    "BASELINE - Pretraining + HIL + Heuristic.\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-baseline.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-easy-model\", rank=0)\n",
    "# TESTING_FILE = \"heuristic-simple-model-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/filtered-full\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-27-23-BLH-HIL-G\"\n",
    "\n",
    "\"\"\"\n",
    "AUGMENTED MODEL - Only Random Weights\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-two-sensor.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = None\n",
    "\n",
    "\"\"\"\n",
    "AUGMENTED MODEL - Pretraining\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-two-sensor.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-28-23-2S-HIL-A\"\n",
    "\n",
    "\"\"\"\n",
    "AUGMENTED MODEL - Pretraining + HIL\n",
    "\"\"\"\n",
    "VALIDATION_FILE = \"validation-data-two-sensor.txt\"\n",
    "VALIDATION_DATA = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "ENSEMBLE_PATH = \"../checkpoints/ensembles/01-28-23-2S-HIL-A\"\n",
    "\n",
    "\"\"\"\n",
    "AUGMENTED MODEL - Pretraining + Heurisitc\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-two-sensor.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "# TESTING_FILE = \"original-hand-labeled-classes.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/full-mini\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-30-23-2S-Heur-Pre-C\"\n",
    "\n",
    "\"\"\"\n",
    "AUGMENTED MODEL - Pretraining + Heurisitc + HIL\n",
    "\"\"\"\n",
    "# VALIDATION_FILE = \"validation-data-two-sensor.txt\"\n",
    "# VALIDATION_DATA = SwarmDataset(\"../data/validation-two-sensor-model\", rank=0)\n",
    "# TESTING_FILE = \"heuristic-two-sensor.txt\"\n",
    "# TESTING_DATA = SwarmDataset(\"../data/gecco-filtered-two-sensor\", rank=0)\n",
    "# ENSEMBLE_PATH = \"../checkpoints/ensembles/01-31-23-2S-Heur-HIL-A\"\n",
    "\n",
    "OUT = \"../data/oracle\"\n",
    "validation_classes = []\n",
    "with open(os.path.join(OUT, VALIDATION_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    validation_classes = [-1 for i in range(len(lines))]\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        validation_classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "testing_classes = []\n",
    "with open(os.path.join(OUT, TESTING_FILE), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    testing_classes = [-1 for i in range(len(lines))]\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        testing_classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "validation_set = []\n",
    "testing_set = []\n",
    "for i, _class in enumerate(testing_classes):\n",
    "    testing_set.append((i, _class))\n",
    "\n",
    "for i, _class in enumerate(validation_classes):\n",
    "    validation_set.append((i, _class))\n",
    "\n",
    "print(len(validation_set), len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "Adjusting learning rate of group 0 to 1.5000e-03.\n",
      "====================\n",
      "VAL results\n",
      "Class Set of Size: 200\n",
      "{0: 0, 1: 591, 2: 30951, 3: 19425, 4: 44781, 5: 16926, 6: 198, 7: 0, 8: 1950, 9: 198}\n",
      "CLASS ACCURACY (Out of 115020 triplets):\n",
      "1: 59.56006768189509\n",
      "2: 71.26102549190657\n",
      "3: 82.61003861003861\n",
      "4: 75.4829056966124\n",
      "5: 95.22627909724685\n",
      "6: 82.82828282828282\n",
      "8: 83.28205128205128\n",
      "9: 85.35353535353535\n",
      "Ensemble 0 ~ Accuracy: 78.53590679881759\n",
      "{0: 0, 1: 591, 2: 30951, 3: 19425, 4: 44781, 5: 16926, 6: 198, 7: 0, 8: 1950, 9: 198}\n",
      "CLASS ACCURACY (Out of 115020 triplets):\n",
      "1: 68.52791878172589\n",
      "2: 66.123873218959\n",
      "3: 69.07078507078506\n",
      "4: 74.77278309997544\n",
      "5: 98.44026940801135\n",
      "6: 83.33333333333333\n",
      "8: 59.07692307692308\n",
      "9: 93.43434343434343\n",
      "Ensemble 1 ~ Accuracy: 74.71396278908016\n",
      "{0: 0, 1: 591, 2: 30951, 3: 19425, 4: 44781, 5: 16926, 6: 198, 7: 0, 8: 1950, 9: 198}\n",
      "CLASS ACCURACY (Out of 115020 triplets):\n",
      "1: 57.36040609137056\n",
      "2: 71.3256437594908\n",
      "3: 75.9124839124839\n",
      "4: 75.94738840133093\n",
      "5: 97.74902516838\n",
      "6: 82.82828282828282\n",
      "8: 73.58974358974359\n",
      "9: 90.4040404040404\n",
      "Ensemble 2 ~ Accuracy: 77.80733785428622\n",
      "Average: 77.01906914739466\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr=15e-4, learning_decay=0.7, decay_step=1, threshold=9.0, weight_decay=1e-4, new_model=True, init=\"Random\")\n",
    "if ENSEMBLE_PATH:\n",
    "    ensemble.load_ensemble(ENSEMBLE_PATH, full=True)\n",
    "ensemble.eval_mode()\n",
    "\n",
    "MARGIN = 0\n",
    "# for metric in [\"TRAIN\", \"VAL\"]:\n",
    "for metric in [\"VAL\"]:\n",
    "    a = []\n",
    "    sampled_dataset = TESTING_DATA if metric == \"TRAIN\" else VALIDATION_DATA\n",
    "    c_set = testing_set if metric == \"TRAIN\" else validation_set\n",
    "    classes = testing_classes if metric == \"TRAIN\" else validation_classes\n",
    "\n",
    "    # random.shuffle(c_set)\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"{metric} results\")\n",
    "    print(f\"Class Set of Size: {len(c_set)}\")\n",
    "    for i in range(len(ensemble.ensemble)):\n",
    "        embedded_positions = []\n",
    "        for j, c in enumerate(classes):\n",
    "            image, _ = sampled_dataset[j][0], sampled_dataset[j][1][0]\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            embed = ensemble.ensemble[i].forward(torch.tensor(image, device=device, dtype=torch.float))\n",
    "            embed = embed.detach().cpu().squeeze(dim=0).numpy()\n",
    "            embedded_positions.append(embed)\n",
    "\n",
    "        # Evaluate Accuracy\n",
    "        correct, total = 0, 0\n",
    "        class_counts = {i:0 for i in range(max(classes) + 1)}\n",
    "        class_accuracy = {i:0 for i in range(max(classes) + 1)}\n",
    "        for l in range(len(c_set)):\n",
    "            x, _classX = c_set[l]\n",
    "            break_class_X = False\n",
    "            if _classX == 0:\n",
    "                continue\n",
    "            for j in range(l, len(c_set)):\n",
    "                y, _classY = c_set[j]\n",
    "                if x == y or _classX != _classY:\n",
    "                    continue\n",
    "                for k in range(len(c_set)):\n",
    "                    z, _classZ = c_set[k]\n",
    "                    # if _classZ == 0:\n",
    "                    #     continue\n",
    "                    if _classZ == _classX or x == z or y == z:\n",
    "                        continue\n",
    "                    positive_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[y])\n",
    "                    negative_dist = np.linalg.norm(embedded_positions[x] - embedded_positions[z])\n",
    "                    if positive_dist + MARGIN < negative_dist:\n",
    "                        correct += 1\n",
    "                        class_accuracy[_classX] += 1\n",
    "                    total += 1\n",
    "                    class_counts[_classX] += 1\n",
    "\n",
    "        print(class_counts)\n",
    "        print(f\"CLASS ACCURACY (Out of {total} triplets):\")\n",
    "        for class_value in class_accuracy:\n",
    "            if class_value == 0 or class_counts[class_value] == 0:\n",
    "                continue\n",
    "            print(f\"{class_value}: {class_accuracy[class_value] * 100 / class_counts[class_value]}\")\n",
    "        acc = correct * 100 / total\n",
    "        a.append(acc)\n",
    "        print(f\"Ensemble {i} ~ Accuracy: {acc}\")\n",
    "\n",
    "    print(f\"Average: {sum(a) / 3}\")\n",
    "    print(\"=\" * 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
