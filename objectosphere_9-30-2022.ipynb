{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "All imports should be defined here to reduce clutter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "from NovelSwarmBehavior.novel_swarms.config.EvolutionaryConfig import GeneticEvolutionConfig\n",
    "from NovelSwarmBehavior.novel_swarms.config.WorldConfig import RectangularWorldConfig\n",
    "from NovelSwarmBehavior.novel_swarms.config.defaults import ConfigurationDefaults\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.GeneRule import GeneRule\n",
    "from NovelSwarmBehavior.novel_swarms.config.OutputTensorConfig import OutputTensorConfig\n",
    "from generation.HaltedEvolution import HaltedEvolution\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function Declarations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def initializeHaltedEvolution():\n",
    "    agent_config = ConfigurationDefaults.DIFF_DRIVE_AGENT\n",
    "\n",
    "    genotype = [\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "        GeneRule(_max=1.0, _min=-1.0, mutation_step=0.4, round_digits=4),\n",
    "    ]\n",
    "\n",
    "    phenotype = ConfigurationDefaults.BEHAVIOR_VECTOR\n",
    "\n",
    "    world_config = RectangularWorldConfig(\n",
    "        size=(500, 500),\n",
    "        n_agents=30,\n",
    "        behavior=phenotype,\n",
    "        agentConfig=agent_config,\n",
    "        padding=15\n",
    "    )\n",
    "\n",
    "    novelty_config = GeneticEvolutionConfig(\n",
    "        gene_rules=genotype,\n",
    "        phenotype_config=phenotype,\n",
    "        n_generations=100,\n",
    "        n_population=100,\n",
    "        crossover_rate=0.7,\n",
    "        mutation_rate=0.15,\n",
    "        world_config=world_config,\n",
    "        k_nn=15,\n",
    "        simulation_lifespan=300,\n",
    "        display_novelty=False,\n",
    "        save_archive=False,\n",
    "        show_gui=True\n",
    "    )\n",
    "\n",
    "    pygame.init()\n",
    "    pygame.display.set_caption(\"Evolutionary Novelty Search\")\n",
    "    screen = pygame.display.set_mode((world_config.w, world_config.h))\n",
    "\n",
    "    output_config = OutputTensorConfig(\n",
    "        timeless=True,\n",
    "        total_frames=80,\n",
    "        steps_between_frames=2,\n",
    "        screen=screen\n",
    "    )\n",
    "\n",
    "    halted_evolution = HaltedEvolution(\n",
    "        world=world_config,\n",
    "        evolution_config=novelty_config,\n",
    "        output_config=output_config\n",
    "    )\n",
    "\n",
    "    return halted_evolution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BehaviorIdentificationModel(torch.nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super(BehaviorIdentificationModel, self,).__init__()\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        activation_function = torch.nn.LeakyReLU\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 1, 5, stride=2, padding=2)\n",
    "        self.activation1 = activation_function()\n",
    "        self.conv2 = torch.nn.Conv2d(1, 1, 3, stride=2, padding=1)\n",
    "        self.activation2 = activation_function()\n",
    "        # self.conv3 = torch.nn.Conv2d(1, 1, 3, stride=2)\n",
    "        # self.activation3 = activation_function()\n",
    "\n",
    "        self.pooling = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(3844, 400)\n",
    "        # self.normalization1 = torch.nn.BatchNorm1d(400)\n",
    "        self.activation5 = activation_function()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.05)\n",
    "\n",
    "        FEATURE_LAYER_SIZE = 100\n",
    "        self.linear2 = torch.nn.Linear(400, FEATURE_LAYER_SIZE)\n",
    "        self.activation6 = activation_function()\n",
    "        self.classification_layer = torch.nn.Linear(FEATURE_LAYER_SIZE, self.n_classes)\n",
    "\n",
    "        self.curr_feature_layer = torch.zeros(FEATURE_LAYER_SIZE)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation2(x)\n",
    "        # print(x.size())\n",
    "        # x = self.conv3(x)\n",
    "        # x = self.activation3(x)\n",
    "        # print(x.size())\n",
    "\n",
    "        x = self.pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.size())\n",
    "        x = self.linear1(x)\n",
    "\n",
    "\n",
    "        # if self.training:\n",
    "        #     x = self.normalization1(x)\n",
    "        x = self.activation5(x)\n",
    "        x = self.linear2(x)\n",
    "        self.curr_feature_layer = x\n",
    "        if self.training:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.activation6(x)\n",
    "        x = self.classification_layer(x)\n",
    "        return x\n",
    "\n",
    "    def increaseClassCount(self):\n",
    "        self.n_classes += 1\n",
    "        self.classification_layer = torch.nn.Linear(100, self.n_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Weight Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def weights_init_uniform_rule(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.uniform_(m.weight)\n",
    "\n",
    "def weights_init_normal_rule(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight, mean=0, std=1)\n",
    "\n",
    "def weights_init_xavier_rule(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "def weights_init_xavier_uniform_rule(m):\n",
    "    if type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=torch.nn.init.calculate_gain('relu'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Halted Evolution + TensorBoard\n",
    "The following initializes a possible evolution, simulates the genome, and outputs the resulting frame to tensorboard"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testTensorBoardAndEvolutionNexting():\n",
    "    # Writer will output to ./runs/ directory by default\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    evolution = initializeHaltedEvolution()\n",
    "    evolution.evolve_config.lifespan = 1200\n",
    "    evolution.setup()\n",
    "\n",
    "    for i in range(60):\n",
    "        frame, behavior_vector = evolution.next()\n",
    "        frame = frame.astype(np.uint8)\n",
    "        reshaped = np.reshape(frame, (1, 500, 500))\n",
    "\n",
    "        # Tensorboard output\n",
    "        writer.add_image('images', reshaped.astype(np.uint8), i, dataformats=\"CWH\")\n",
    "\n",
    "    writer.close()\n",
    "    pygame.quit()\n",
    "\n",
    "# testTensorBoardAndEvolutionNexting()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Single Pass Through of the Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testInputAndBackpropOfAlteredNetwork():\n",
    "    evolution = initializeHaltedEvolution()\n",
    "    evolution.setup()\n",
    "\n",
    "    model = BehaviorIdentificationModel(n_classes=6)\n",
    "    frame, _ = evolution.next()\n",
    "    frame = frame.astype(np.uint8)\n",
    "    reshaped = np.reshape(frame, (1, 500, 500))\n",
    "\n",
    "    # Initialize a test loss function\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    tensor = torch.tensor(reshaped, dtype=torch.float32)\n",
    "    y_hat1 = model.forward(tensor)\n",
    "    print(y_hat1)\n",
    "\n",
    "    y_truth = torch.tensor([[1, 0, 0, 0, 0, 0]], dtype=torch.float32)\n",
    "    loss = loss_fn(y_hat1, y_truth)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.increaseClassCount()\n",
    "    y_hat2 = model.forward(tensor)\n",
    "    y_truth = torch.tensor([[1, 0, 0, 0, 0, 0, 0]], dtype=torch.float32)\n",
    "    loss = loss_fn(y_hat2, y_truth)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(y_hat1, y_hat2)\n",
    "    pygame.quit()\n",
    "# testInputAndBackpropOfAlteredNetwork()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get Number of trainable parameters in the network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def printModelInformation():\n",
    "    model_info = BehaviorIdentificationModel(n_classes=2)\n",
    "    print(sum(p.numel() for p in model_info.parameters() if p.requires_grad))\n",
    "    print(f\"Model structure: {model_info}\\n\\n\")\n",
    "printModelInformation()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_transform_training = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomApply(\n",
    "        transforms=[\n",
    "            transforms.RandomAffine(\n",
    "                degrees=(0, 180),\n",
    "                translate=(0.0, 0.3),\n",
    "                scale=(0.5, 1.0)\n",
    "            ),\n",
    "            transforms.RandomPerspective(\n",
    "                distortion_scale=0.6,\n",
    "                p = 0.3\n",
    "            )\n",
    "        ],\n",
    "        p=1.0\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.0, 1.0)\n",
    "])\n",
    "\n",
    "data_transform_testing = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_folder = torchvision.datasets.ImageFolder(root=\"./data/train\", transform=data_transform_training)\n",
    "test_folder = torchvision.datasets.ImageFolder(root=\"./data/test\", transform=data_transform_testing)\n",
    "\n",
    "train_folder = torch.utils.data.ConcatDataset([train_folder] * 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "OOD_CLASS = 2\n",
    "\n",
    "def custom_softmax(x, dim=0):\n",
    "    exp_x = torch.exp(x)\n",
    "    exp_x = torch.nan_to_num(exp_x, nan=0.0, neginf=1e-5)\n",
    "    # print(\"Exp X: \", exp_x)\n",
    "    sum_x = torch.sum(exp_x, dim=dim, keepdim=True)\n",
    "\n",
    "    # print(\"Sum X: \", sum_x)\n",
    "    softmax = exp_x / sum_x\n",
    "    softmax = torch.nan_to_num(softmax, nan=0.0, neginf=0.0, posinf=1.0)\n",
    "    # print(\"Custom Softmax: \", softmax)\n",
    "    if torch.isnan(softmax).any():\n",
    "        raise Exception(\"NAN element in Custom Softmax\")\n",
    "    return softmax\n",
    "\n",
    "def threshold_softmax(x, dim=0, a=0.2):\n",
    "    # print(\"THRESHOLDING SET\")\n",
    "    alpha = torch.tensor(a, device=device)\n",
    "\n",
    "    # limits = torch.full(x.shape, 1000, device=device)\n",
    "    log_exp_x = torch.exp(x)\n",
    "    log_exp_x = torch.nan_to_num(log_exp_x, nan=0.0, neginf=1e-5, posinf=1e5)\n",
    "    # log_exp_x = torch.minimum(log_exp_x, limits)\n",
    "    # print(\"Log Exp X: \", log_exp_x)\n",
    "    sum_x = torch.sum(log_exp_x, dim=dim, keepdim=True) + torch.exp(alpha)\n",
    "    # print(\"Sum X: \", sum_x)\n",
    "    softmax = log_exp_x / sum_x\n",
    "    softmax = torch.nan_to_num(softmax, nan=0.0, neginf=0.0, posinf=1.0)\n",
    "    # print(\"Threshold Softmax: \", softmax)\n",
    "    if torch.isnan(softmax).any():\n",
    "        raise Exception(\"NAN element in Threshold Softmax\")\n",
    "    return softmax\n",
    "\n",
    "def custom_log_softmax(x, a=None):\n",
    "    log_softmax = torch.log(custom_softmax(x))\n",
    "    if torch.isnan(log_softmax).any():\n",
    "        raise Exception(\"NAN element in Custom Log Softmax\")\n",
    "    return log_softmax\n",
    "\n",
    "def threshold_log_softmax(x, a=0.2):\n",
    "    log_softmax = torch.log(threshold_softmax(x, a=a))\n",
    "    if torch.isnan(log_softmax).any():\n",
    "        print(log_softmax)\n",
    "        raise Exception(\"NAN element in Threshold Log Softmax\")\n",
    "    return log_softmax\n",
    "\n",
    "def custom_softmax_loss(x, y_truth, dim=0):\n",
    "    log_prob = -1.0 * custom_log_softmax(x)\n",
    "    # print(\"Log Prob: \", log_prob)\n",
    "    loss = log_prob.gather(dim, y_truth)\n",
    "    # print(\"Gathering: \", loss)\n",
    "    loss = loss.mean()\n",
    "    # print(\"Loss: \", loss)\n",
    "    if torch.isnan(loss).any():\n",
    "        raise Exception(\"NAN element in Custom Softmax Loss\")\n",
    "    return loss\n",
    "\n",
    "def entropic_open_set_loss(x, y_truth=None, ret_mean=False, threshold_softmax=False):\n",
    "    entropic_loss = torch.zeros(len(x), device=device)\n",
    "    softmax = custom_log_softmax\n",
    "    if threshold_softmax:\n",
    "        # print(\"THRESHOLDING SET\")\n",
    "        softmax = threshold_log_softmax\n",
    "\n",
    "    for i, y_t in enumerate(y_truth):\n",
    "        if y_t == OOD_CLASS:\n",
    "            entropic_loss[i] = (-1/len(x[i])) * torch.sum(softmax(x[i], a=threshold_softmax))\n",
    "        else:\n",
    "            logsoft = (-1) * softmax(x[i], a=threshold_softmax)\n",
    "            entropic_loss[i] = logsoft[y_truth[i]]\n",
    "\n",
    "    if torch.isnan(entropic_loss).any():\n",
    "        raise Exception(\"NAN element in Entropic Open Set Loss\")\n",
    "    if ret_mean:\n",
    "        return entropic_loss.mean()\n",
    "    return entropic_loss\n",
    "\n",
    "def objectosphere_loss(x, y_truth=None, feature_layer=None, ret_mean=True, lamb=1e-2, zeta=2.0, threshold_softmax=0.0):\n",
    "    entropic_loss = entropic_open_set_loss(x, y_truth=y_truth, threshold_softmax=threshold_softmax)\n",
    "    objectosphere = torch.zeros(len(x), device=device)\n",
    "    LAMBDA = lamb\n",
    "\n",
    "    for i, y_t in enumerate(y_truth):\n",
    "        if y_t == OOD_CLASS:\n",
    "            o_loss = torch.log(torch.norm(feature_layer[i]) ** 2)\n",
    "            objectosphere[i] = torch.nan_to_num(o_loss, neginf=-3, nan=0)\n",
    "        else:\n",
    "            ZETA = zeta\n",
    "            dist_to_zero = ZETA - torch.norm(feature_layer[i])\n",
    "            o_loss = torch.log(torch.pow(torch.max(dist_to_zero, torch.tensor(0, device=device)), 2))\n",
    "            objectosphere[i] = torch.nan_to_num(o_loss, neginf=-3, nan=0)\n",
    "\n",
    "    total_loss = entropic_loss + (LAMBDA * objectosphere)\n",
    "    if torch.isnan(total_loss).any():\n",
    "        print(total_loss)\n",
    "        raise Exception(\"NAN element in Objectosphere Loss\")\n",
    "    if ret_mean:\n",
    "        return total_loss.mean()\n",
    "    return total_loss\n",
    "\n",
    "def binary_entropy_calculation(p1, p2):\n",
    "    entropy = -(p1 * np.log2(p1)) - (p2 * np.log2(p2))\n",
    "    return entropy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Softmax:  tensor([[0.4281, 0.5719],\n",
      "        [0.3589, 0.6411],\n",
      "        [0.6411, 0.3589]], device='cuda:0')\n",
      "Entropic:  tensor([0.5588, 0.4446, 0.7346], device='cuda:0')\n",
      "Entropic:  tensor([0.6192, 1.2849, 1.1232], device='cuda:0')\n",
      "Objectosphere:  tensor([0.5259, 0.1848, 0.9118], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([[2.4283, 2.7178], [-0.8, -0.22], [0.8, 0.22]], device=device)\n",
    "y_truth = torch.tensor([1, 1, 2], device=device)\n",
    "features = torch.rand((3,3), device=device)\n",
    "# softmax_a = torch.tensor([[0.3813, 0.6187]])\n",
    "# softmax_b = torch.tensor([[0.1939, 0.8061]])\n",
    "\n",
    "# print(\"Test: \", test)\n",
    "# print(\"Y Truth: \", y_truth)\n",
    "# print(\"Features: \", features)\n",
    "#\n",
    "print(\"Custom Softmax: \", custom_softmax(test, dim=1))\n",
    "print(\"Entropic: \", entropic_open_set_loss(test, y_truth=y_truth))\n",
    "print(\"Entropic: \", entropic_open_set_loss(test, y_truth=y_truth, threshold_softmax=0.5))\n",
    "print(\"Objectosphere: \", objectosphere_loss(test, y_truth=y_truth, feature_layer=features, ret_mean=False, lamb=0.3))\n",
    "# print(\"Binary Entropy Calculation A: \", binary_entropy_calculation(softmax_a[0][0], softmax_a[0][1]))\n",
    "# print(\"Binary Entropy Calculation B: \", binary_entropy_calculation(softmax_b[0][0], softmax_b[0][1]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Unit Test for Softmax"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TESTS = 100\n",
    "THRESHOLD = 1e-2\n",
    "for i in range(TESTS):\n",
    "    x = torch.rand(2, device=device)\n",
    "    softmax = custom_softmax(x, dim=0)\n",
    "    softsum = torch.sum(softmax)\n",
    "    if  softsum > (1 + THRESHOLD) or softsum < (1 - THRESHOLD):\n",
    "        print(\"Input: \", x)\n",
    "        print(\"Softmax: \", softmax)\n",
    "        print(\"Softsum: \", softsum)\n",
    "        assert False\n",
    "print(f\"{TESTS} tests passed.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n",
      "Epoch 0\n",
      "Training loss: 0.666521\n",
      "Max Loss: 0.9406033754348755\n",
      "Min Loss: 0.45234331488609314\n",
      "Predication:  tensor(0, device='cuda:0')\n",
      "HITL Loss:  tensor(21.6752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Softy:  tensor([[0.5262, 0.4738],\n",
      "        [0.5261, 0.4739],\n",
      "        [0.5261, 0.4739],\n",
      "        [0.5261, 0.4739]], device='cuda:0')\n",
      "Control:  tensor(0.9980)\n",
      "Sample-A:  tensor(0.9980)\n",
      "Sample-B:  tensor(0.9981)\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 0.696258 \n",
      "\n",
      "Epoch 1\n",
      "Training loss: 0.666591\n",
      "Max Loss: 0.8729397058486938\n",
      "Min Loss: 0.4914611876010895\n",
      "Predication:  tensor(1, device='cuda:0')\n",
      "HITL Loss:  tensor(inf, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Predication:  tensor(0, device='cuda:0')\n",
      "HITL Loss:  tensor(inf, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Softy:  tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "Control:  tensor(nan)\n",
      "Sample-A:  tensor(nan)\n",
      "Sample-B:  tensor(nan)\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss:      nan \n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1751866/3571595926.py:103: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = -(p1 * np.log2(p1)) - (p2 * np.log2(p2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:     inf\n",
      "Max Loss: inf\n",
      "Min Loss: 50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [218], line 103\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m INCLUDE_EVOLUTION:\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m--> 103\u001B[0m         frame, _ \u001B[38;5;241m=\u001B[39m \u001B[43mevolution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m         frame \u001B[38;5;241m=\u001B[39m frame\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[1;32m    105\u001B[0m         reshaped \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(frame, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m500\u001B[39m))\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/generation/HaltedEvolution.py:53\u001B[0m, in \u001B[0;36mHaltedEvolution.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mevolve()\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mcurr_genome \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 53\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbehavior_discovery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunSinglePopulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscreen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbehavior_discovery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurr_genome\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworld\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_configuration\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mcurr_genome \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     61\u001B[0m behavior \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mbehavior[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/novelty/BehaviorDiscovery.py:65\u001B[0m, in \u001B[0;36mBehaviorDiscovery.runSinglePopulation\u001B[0;34m(self, screen, i, seed, output_config)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld_config\u001B[38;5;241m.\u001B[39magentConfig\u001B[38;5;241m.\u001B[39mcontroller \u001B[38;5;241m=\u001B[39m genome\n\u001B[1;32m     64\u001B[0m world \u001B[38;5;241m=\u001B[39m WorldFactory\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld_config)\n\u001B[0;32m---> 65\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mworld\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlifespan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_capture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m screen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     67\u001B[0m     world\u001B[38;5;241m.\u001B[39mdraw(screen)\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/world/World.py:48\u001B[0m, in \u001B[0;36mWorld.evaluate\u001B[0;34m(self, steps, output_capture, screen)\u001B[0m\n\u001B[1;32m     45\u001B[0m     screen \u001B[38;5;241m=\u001B[39m output_capture\u001B[38;5;241m.\u001B[39mscreen\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_capture \u001B[38;5;129;01mand\u001B[39;00m output_capture\u001B[38;5;241m.\u001B[39mscreen:\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;66;03m# If start of recording, clear screen\u001B[39;00m\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m frame_markers \u001B[38;5;129;01mand\u001B[39;00m step \u001B[38;5;241m==\u001B[39m frame_markers[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/world/RectangularWorld.py:41\u001B[0m, in \u001B[0;36mRectangularWorld.step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mtype\u001B[39m(agent), DifferentialDriveAgent):\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAgents must be subtype of Agent, not \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(agent)))\n\u001B[0;32m---> 41\u001B[0m     \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_for_world_boundaries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithinWorldBoundaries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_for_agent_collisions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreventAgentCollisions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopulation\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m behavior \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior:\n\u001B[1;32m     48\u001B[0m     behavior\u001B[38;5;241m.\u001B[39mcalculate()\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/agent/DiffDriveAgent.py:83\u001B[0m, in \u001B[0;36mDifferentialDriveAgent.step\u001B[0;34m(self, check_for_world_boundaries, population, check_for_agent_collisions)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_pos \u001B[38;5;241m-\u001B[39m old_y_pos\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msensors:\n\u001B[0;32m---> 83\u001B[0m     \u001B[43msensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpopulation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/sensors/BinaryLOSSensor.py:46\u001B[0m, in \u001B[0;36mBinaryLOSSensor.step\u001B[0;34m(self, population)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, population):\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28msuper\u001B[39m(BinaryLOSSensor, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mstep(population\u001B[38;5;241m=\u001B[39mpopulation)\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckForLOSCollisions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpopulation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/sensors/BinaryLOSSensor.py:32\u001B[0m, in \u001B[0;36mBinaryLOSSensor.checkForLOSCollisions\u001B[0;34m(self, population)\u001B[0m\n\u001B[1;32m     29\u001B[0m a \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(e, d_hat)\n\u001B[1;32m     31\u001B[0m r_2 \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mradius \u001B[38;5;241m*\u001B[39m agent\u001B[38;5;241m.\u001B[39mradius\n\u001B[0;32m---> 32\u001B[0m e_2 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m a_2 \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m*\u001B[39m a\n\u001B[1;32m     35\u001B[0m has_intersection \u001B[38;5;241m=\u001B[39m (r_2 \u001B[38;5;241m-\u001B[39m e_2 \u001B[38;5;241m+\u001B[39m a_2) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# CUDA_LAUNCH_BLOCKING=1\n",
    "# with torch.no_grad():\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "eval_folder = torchvision.datasets.ImageFolder(root=\"./data/eval\", transform=data_transform_testing)\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    eval_folder,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_folder,\n",
    "    batch_size=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_folder,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "SEED = 2\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "CLIP_GRADIENT = False\n",
    "CLIP_VAL = 0.25\n",
    "OOD_CLASS = 2\n",
    "WEIGHT_INIT_FN = None\n",
    "OBJECTO_LAMBDA = 1e-2\n",
    "OBJECTO_ZETA = 1.6\n",
    "THRESHOLD_ALPHA = 0.0\n",
    "LEARNING_RATE = 15e-4 # 4e-4\n",
    "INCLUDE_EVOLUTION = True\n",
    "HITL = False\n",
    "\n",
    "epochs = 100\n",
    "model = BehaviorIdentificationModel(n_classes=2).to(device)\n",
    "\n",
    "if WEIGHT_INIT_FN:\n",
    "    model.apply(WEIGHT_INIT_FN) # Init Weights\n",
    "\n",
    "if INCLUDE_EVOLUTION:\n",
    "    evolution = initializeHaltedEvolution()\n",
    "    evolution.setup()\n",
    "\n",
    "loss_fn = custom_softmax_loss\n",
    "decay_rate = 0.0\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"experiments/latest\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
    "\n",
    "span_control = torch.zeros(10)\n",
    "span_A = torch.zeros(10)\n",
    "span_B = torch.zeros(10)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "\n",
    "    # Training\n",
    "    size = len(train_loader.dataset)\n",
    "    loss_sum = 0\n",
    "    loss_max = 0.0\n",
    "    loss_min = 50.0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "\n",
    "        # loss = torch.nn.CrossEntropyLoss()(pred, y)\n",
    "        loss = objectosphere_loss(\n",
    "            pred,\n",
    "            y_truth=y,\n",
    "            feature_layer=model.curr_feature_layer,\n",
    "            ret_mean=False,\n",
    "            lamb=OBJECTO_LAMBDA,\n",
    "            zeta=OBJECTO_ZETA,\n",
    "            threshold_softmax=THRESHOLD_ALPHA\n",
    "        )\n",
    "        loss_max = max(loss_max, max(loss))\n",
    "        loss_min = min(loss_min, min(loss))\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        if CLIP_GRADIENT:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_VAL)\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = loss_sum / len(train_loader)\n",
    "    writer.add_scalar('Loss/Train', epoch_loss, global_step=epoch)\n",
    "    print(f\"Training loss: {epoch_loss:>7f}\")\n",
    "    print(f\"Max Loss: {loss_max}\")\n",
    "    print(f\"Min Loss: {loss_min}\")\n",
    "\n",
    "    if INCLUDE_EVOLUTION:\n",
    "        for i in range(max(0, epoch + 1)):\n",
    "            frame, _ = evolution.next()\n",
    "            frame = frame.astype(np.uint8)\n",
    "            reshaped = np.reshape(frame, (1, 500, 500))\n",
    "\n",
    "            # plot.imshow(frame, cmap='Greys')\n",
    "\n",
    "            X = torch.tensor(reshaped, dtype=torch.float32, device=device)\n",
    "            out = model(X)\n",
    "            print(\"Predication: \", out.argmax())\n",
    "            if HITL:\n",
    "                i = input(\"Actual Class? Input 2 for OOD\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = objectosphere_loss(\n",
    "                out,\n",
    "                y_truth=torch.tensor([2]),\n",
    "                feature_layer=model.curr_feature_layer,\n",
    "                ret_mean=False,\n",
    "                lamb=OBJECTO_LAMBDA,\n",
    "                zeta=OBJECTO_ZETA,\n",
    "                threshold_softmax=THRESHOLD_ALPHA\n",
    "            )\n",
    "            print(\"HITL Loss: \", loss.mean())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Testing (Only test every few epochs)\n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        size = len(test_loader.dataset)\n",
    "        num_batches = len(test_loader)\n",
    "        test_loss, accuracy = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                pred = model(X)\n",
    "                loss = torch.nn.CrossEntropyLoss()(pred, y)\n",
    "                test_loss += loss.item()\n",
    "                softy = custom_softmax(pred, dim=1)\n",
    "\n",
    "                for i, row in enumerate(softy):\n",
    "                    if row.argmax() == y[i]:\n",
    "                        accuracy += 1\n",
    "\n",
    "            print(\"Softy: \", softy)\n",
    "\n",
    "            SampleControl, _ = train_loader.dataset[3]\n",
    "            SampleControl = SampleControl.to(device)\n",
    "            control_pred = model(SampleControl.unsqueeze(0))\n",
    "            control_pred = custom_softmax(control_pred.cpu(), dim=1)\n",
    "            control = binary_entropy_calculation(control_pred[0][0], control_pred[0][1])\n",
    "            writer.add_scalar(\"Control Entropy\", control, epoch)\n",
    "            print(\"Control: \", control)\n",
    "            span_control = torch.concat((span_control, control.unsqueeze(0)))\n",
    "\n",
    "            # ID SAMPLE\n",
    "            SampleA, _ = eval_loader.dataset[3]\n",
    "            SampleA = SampleA.to(device)\n",
    "            predA = model(SampleA.unsqueeze(0))\n",
    "            predA = custom_softmax(predA.cpu(), dim=1)\n",
    "            entropyA = binary_entropy_calculation(predA[0][0], predA[0][1])\n",
    "            writer.add_scalar(\"ID-Entropy (Sample A)\", entropyA, epoch)\n",
    "            print(\"Sample-A: \", entropyA)\n",
    "            span_A = torch.concat((span_A, entropyA.unsqueeze(0)))\n",
    "\n",
    "            # OOD Sample\n",
    "            SampleB, _ = eval_loader.dataset[2]\n",
    "            SampleB = SampleB.to(device)\n",
    "            predB = model(SampleB.unsqueeze(0))\n",
    "            predB = custom_softmax(predB.cpu(), dim=1)\n",
    "            entropyB = binary_entropy_calculation(predB[0][0], predB[0][1])\n",
    "            writer.add_scalar(\"OOD-Entropy (Sample B)\", entropyB, epoch)\n",
    "            print(\"Sample-B: \", entropyB)\n",
    "            span_B = torch.concat((span_B, entropyB.unsqueeze(0)))\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        accuracy /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "        writer.add_scalar('Loss/Test', test_loss, global_step=epoch)\n",
    "        writer.add_scalar('Accuracy/Test', accuracy, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "if INCLUDE_EVOLUTION:\n",
    "    pygame.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    ".# Checkpointing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pygame.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "import time\n",
    "file_name = f\"cp_{round(time.time())}\"\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "}, f\"checkpoints/{file_name}.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the model\n",
    "FILE_PATH = \"cp_E_B\"\n",
    "checkpoint = torch.load(f\"checkpoints/{FILE_PATH}.pt\")\n",
    "\n",
    "eval_model = BehaviorIdentificationModel(n_classes=2)\n",
    "\n",
    "if optimizer is None:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "eval_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "eval_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Starting\")\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "model.eval()\n",
    "eval_folder = torchvision.datasets.ImageFolder(root=\"./data/eval\", transform=data_transform_testing)\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    eval_folder,\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, _ = eval_loader.dataset[2]\n",
    "    # X, _ = eval_loader.dataset[3]\n",
    "    # X, _ = train_loader.dataset[28]\n",
    "\n",
    "    plot.imshow(torch.squeeze(X), cmap='Greys')\n",
    "    plot.show()\n",
    "\n",
    "    X = X.to(device)\n",
    "\n",
    "    pred = model(X.unsqueeze(0))\n",
    "    # target = torch.tensor([y])\n",
    "    print(\"Prediction: \", pred, \"Target: \", None)\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "    #\n",
    "    # test_loss = loss_fn(pred, target)\n",
    "    # print(\"Loss: \", test_loss.item())\n",
    "\n",
    "    softy = custom_softmax(pred, dim=1)\n",
    "    print(\"SoftMaxed: \", softy)\n",
    "\n",
    "print(\"Ending\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_model = eval_model.to(device)\n",
    "eval_model.eval()\n",
    "evolution = initializeHaltedEvolution()\n",
    "evolution.setup()\n",
    "\n",
    "for i in range(10):\n",
    "    frame, _ = evolution.next()\n",
    "    frame = frame.astype(np.uint8)\n",
    "    reshaped = np.reshape(frame, (1, 500, 500))\n",
    "\n",
    "    plot.imshow(frame, cmap='Greys')\n",
    "\n",
    "    X = torch.tensor(reshaped, dtype=torch.float32, device=device)\n",
    "    out = eval_model(X)\n",
    "    print(\"Out: \", out)\n",
    "    n_out = torch.nn.functional.normalize(out, dim=1)\n",
    "    softy = torch.nn.functional.softmax(n_out, dim=1).cpu().detach().numpy()\n",
    "    entro = binary_entropy_calculation(softy[0][0], softy[0][1])\n",
    "\n",
    "    print(\"Softmax: \", softy)\n",
    "    print(\"Entropy: \", entro)\n",
    "\n",
    "pygame.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
