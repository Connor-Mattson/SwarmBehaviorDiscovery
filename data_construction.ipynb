{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "#\n",
    "# from data.swarmset import SwarmDataset, DataBuilder\n",
    "#\n",
    "# baseline_data = DataBuilder(\"data/full\", steps=1200, agents=24)\n",
    "# baseline_data.create()\n",
    "# baseline_data.evolution.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embed into Latent Space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from generation.evolution import ModifiedHaltingEvolution\n",
    "from networks.archive import DataAggregationArchive\n",
    "from hil.HIL import HIL\n",
    "\n",
    "def update_network(network, loss_fn, optim, anchor_image, pos_image, neg_image):\n",
    "    optim.zero_grad()\n",
    "    anchor_out, pos_out, neg_out = network.network_with_transforms(anchor_image, pos_image, neg_image)\n",
    "    loss = loss_fn(anchor_out, pos_out, neg_out)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "def pretraining(data, network, loss_fn, optim, data_size=500):\n",
    "    samples = np.random.random_integers(0, len(data) - 1, (data_size, 2))\n",
    "    total_loss = 0\n",
    "    total_updates = 0\n",
    "    for i, s in enumerate(samples):\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Unsupervised Training.. {(i * 100) / data_size}\")\n",
    "        anchor_image = data[s[0]][0]\n",
    "        pos_image = data[s[0]][0]\n",
    "\n",
    "\n",
    "        if len(data) - 2 > s[1] > 2:\n",
    "            neg_images = [\n",
    "                # data[s[1] - 2][0],\n",
    "                # data[s[1] - 1][0],\n",
    "                data[s[1]][0],\n",
    "                # data[s[1] + 1][0],\n",
    "                # data[s[1] + 2][0],\n",
    "            ]\n",
    "        else:\n",
    "            neg_images = [\n",
    "                data[s[1]][0]\n",
    "            ]\n",
    "\n",
    "        for neg in neg_images:\n",
    "            loss = update_network(network, loss_fn, optim, anchor_image, pos_image, neg)\n",
    "            total_loss += loss.item()\n",
    "            total_updates += 1\n",
    "\n",
    "    return total_loss / total_updates\n",
    "\n",
    "\n",
    "def human_in_the_loop(anchor_dataset, network, optimizer, loss_fn, HIL_archive, random_archive, stop_at):\n",
    "    print(\"HIL TIME!\")\n",
    "    improvements, human_loss, triplet_helpfulness, embedded_archive = hil.humanInput(anchor_dataset, network, optimizer, loss_fn, HIL_archive, random_archive, stop_at)\n",
    "    print(f\"Improvement Count: {improvements}, loss: {human_loss}\")\n",
    "\n",
    "    HIL_archive.save_to_file(f\"data/queries/{trial_name}_hil.csv\")\n",
    "    random_archive.save_to_file(f\"data/queries/{trial_name}_rand.csv\")\n",
    "    return improvements, human_loss, triplet_helpfulness, embedded_archive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIL Init!\n",
      "Pretrained model loaded!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 84\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m gen \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EVOLUTIONS_PER_EPOCH):\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;66;03m# Simulate current population + Save Data\u001B[39;00m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(evolution\u001B[38;5;241m.\u001B[39mgetPopulation())):\n\u001B[1;32m     83\u001B[0m         \u001B[38;5;66;03m# The collection of the original behavior vector below is only used to collect data to compare with the baseline\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m         visual_behavior, genome, baseline_behavior \u001B[38;5;241m=\u001B[39m \u001B[43mevolution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m         dataset\u001B[38;5;241m.\u001B[39mnew_entry(visual_behavior, genome, baseline_behavior)\n\u001B[1;32m     86\u001B[0m     simulation_time \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time)\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/generation/evolution.py:64\u001B[0m, in \u001B[0;36mModifiedHaltingEvolution.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 64\u001B[0m     output, behavior \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbehavior_discovery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunSinglePopulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscreen\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbehavior_discovery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurr_genome\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworld\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_configuration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     genome \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mpopulation[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mcurr_genome]\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior_discovery\u001B[38;5;241m.\u001B[39mcurr_genome \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/novelty/BehaviorDiscovery.py:67\u001B[0m, in \u001B[0;36mBehaviorDiscovery.runSinglePopulation\u001B[0;34m(self, screen, i, save, genome, seed, output_config)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld_config\u001B[38;5;241m.\u001B[39magentConfig\u001B[38;5;241m.\u001B[39mcontroller \u001B[38;5;241m=\u001B[39m genome\n\u001B[1;32m     66\u001B[0m world \u001B[38;5;241m=\u001B[39m WorldFactory\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld_config)\n\u001B[0;32m---> 67\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mworld\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlifespan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_capture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m screen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m     world\u001B[38;5;241m.\u001B[39mdraw(screen)\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/world/World.py:48\u001B[0m, in \u001B[0;36mWorld.evaluate\u001B[0;34m(self, steps, output_capture, screen)\u001B[0m\n\u001B[1;32m     45\u001B[0m     screen \u001B[38;5;241m=\u001B[39m output_capture\u001B[38;5;241m.\u001B[39mscreen\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_capture \u001B[38;5;129;01mand\u001B[39;00m output_capture\u001B[38;5;241m.\u001B[39mscreen:\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;66;03m# If start of recording, clear screen\u001B[39;00m\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m frame_markers \u001B[38;5;129;01mand\u001B[39;00m step \u001B[38;5;241m==\u001B[39m frame_markers[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/world/RectangularWorld.py:52\u001B[0m, in \u001B[0;36mRectangularWorld.step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mtype\u001B[39m(agent), DifferentialDriveAgent):\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAgents must be subtype of Agent, not \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(agent)))\n\u001B[0;32m---> 52\u001B[0m     \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_for_world_boundaries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithinWorldBoundaries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_for_agent_collisions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreventAgentCollisions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopulation\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m behavior \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbehavior:\n\u001B[1;32m     59\u001B[0m     behavior\u001B[38;5;241m.\u001B[39mcalculate()\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/agent/DiffDriveAgent.py:79\u001B[0m, in \u001B[0;36mDifferentialDriveAgent.step\u001B[0;34m(self, check_for_world_boundaries, population, check_for_agent_collisions)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my_pos \u001B[38;5;241m-\u001B[39m old_y_pos\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sensor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msensors:\n\u001B[0;32m---> 79\u001B[0m     \u001B[43msensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpopulation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/sensors/BinaryLOSSensor.py:46\u001B[0m, in \u001B[0;36mBinaryLOSSensor.step\u001B[0;34m(self, population)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, population):\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28msuper\u001B[39m(BinaryLOSSensor, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mstep(population\u001B[38;5;241m=\u001B[39mpopulation)\n\u001B[0;32m---> 46\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckForLOSCollisions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpopulation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/NovelSwarmBehavior/novel_swarms/sensors/BinaryLOSSensor.py:32\u001B[0m, in \u001B[0;36mBinaryLOSSensor.checkForLOSCollisions\u001B[0;34m(self, population)\u001B[0m\n\u001B[1;32m     29\u001B[0m a \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(e, d_hat)\n\u001B[1;32m     31\u001B[0m r_2 \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mradius \u001B[38;5;241m*\u001B[39m agent\u001B[38;5;241m.\u001B[39mradius\n\u001B[0;32m---> 32\u001B[0m e_2 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m a_2 \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m*\u001B[39m a\n\u001B[1;32m     35\u001B[0m has_intersection \u001B[38;5;241m=\u001B[39m (r_2 \u001B[38;5;241m-\u001B[39m e_2 \u001B[38;5;241m+\u001B[39m a_2) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m<__array_function__ internals>:177\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from generation.evolution import ModifiedHaltingEvolution\n",
    "from networks.archive import DataAggregationArchive\n",
    "from hil.HIL import HIL\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import ndimage\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "trial_name = f\"{str(int(time.time()))}\"\n",
    "\n",
    "TRAIN = True\n",
    "CLUSTER_AND_DISPLAY = True\n",
    "WRITE_OUT = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "writer = SummaryWriter()\n",
    "network = NoveltyEmbedding().to(device)\n",
    "\n",
    "SAVE_CLUSTER_IMAGES = True\n",
    "SAVE_CLUSTER_MEDOIDS = True\n",
    "PRETRAINING = True\n",
    "HUMAN_IN_LOOP = True\n",
    "SYNTHETIC_HIL = True\n",
    "EVOLUTION = True\n",
    "EPOCHS = 20\n",
    "DATA_SIZE = 10000\n",
    "EVOLUTIONS_PER_EPOCH = 3\n",
    "\n",
    "anchor_dataset = ContinuingDataset(\"data\")\n",
    "sampled_dataset = SwarmDataset(\"data/full\", rank=0)\n",
    "evolution, _ = ModifiedHaltingEvolution.defaultEvolver(steps=800, n_agents=24, evolve_population=100, seed=None)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.8)\n",
    "\n",
    "# Margin was 10\n",
    "loss_fn = torch.nn.TripletMarginLoss(margin=15)\n",
    "hil = HIL(name=trial_name, synthetic=SYNTHETIC_HIL, data_limiter=DATA_SIZE)\n",
    "HIL_archive = DataAggregationArchive()\n",
    "random_archive = DataAggregationArchive(scalar=True)\n",
    "EPSILON = 0.5\n",
    "\n",
    "simulation_time = 0\n",
    "evolution_time = 0\n",
    "training_time = 0\n",
    "hil_time = 0\n",
    "\n",
    "# TODO: Add Randomly-sampled Contrastive/Triplet Loss\n",
    "if PRETRAINING:\n",
    "    network.load_model(\"unsupervised_decay_0.7_target_0.08\")\n",
    "    print(\"Pretrained model loaded!\")\n",
    "\n",
    "dataset = anchor_dataset if EVOLUTION else sampled_dataset\n",
    "\n",
    "if TRAIN:\n",
    "    STOP_FLAG = False\n",
    "    for epoch in range(EPOCHS):\n",
    "        if STOP_FLAG:\n",
    "            break\n",
    "\n",
    "\n",
    "        # Record the accuracy of the medoids with respect to the synthetic policy\n",
    "        medoid_acc, cluster_acc = 0, 0\n",
    "        if len(dataset) > 0 and SAVE_CLUSTER_MEDOIDS:\n",
    "            if EVOLUTION:\n",
    "                hil.synthetic_knowledge = hil.syntheticBehaviorSpace(dataset)\n",
    "                print(f\"Synthetic Human Knowledge Size: {len(hil.synthetic_knowledge.labels_)}\")\n",
    "            medoid_acc, cluster_acc = hil.record_medoids(network, dataset)\n",
    "\n",
    "        # Cluster current dataset, display clusters, and save for analysis\n",
    "        if len(dataset) > 0 and  SAVE_CLUSTER_IMAGES:\n",
    "            hil.embed_and_cluster(network, dataset, auto_quit=True)\n",
    "            evolution.restart_screen()\n",
    "        start_time = time.time()\n",
    "\n",
    "        if EVOLUTION:\n",
    "            for gen in range(EVOLUTIONS_PER_EPOCH):\n",
    "                # Simulate current population + Save Data\n",
    "                for i in range(len(evolution.getPopulation())):\n",
    "                    # The collection of the original behavior vector below is only used to collect data to compare with the baseline\n",
    "                    visual_behavior, genome, baseline_behavior = evolution.next()\n",
    "                    dataset.new_entry(visual_behavior, genome, baseline_behavior)\n",
    "                simulation_time += (time.time() - start_time)\n",
    "\n",
    "                # Then, evolve\n",
    "                start_time = time.time()\n",
    "                embedded_archive = hil.getEmbeddedArchive(dataset, network)\n",
    "                evolution.overwriteArchive(embedded_archive, random_archive)\n",
    "                embedded_behavior = embedded_archive.archive[-evolution.evolve_config.population:]\n",
    "                evolution.overwriteBehavior(embedded_behavior)\n",
    "                evolution.evolve()\n",
    "                evolution.restart_screen()\n",
    "                evolution_time += (time.time() - start_time)\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Human in the Loop determines behavior embedding\n",
    "        if HUMAN_IN_LOOP:\n",
    "            improvements, human_loss, triplet_helpfulness, _ =   human_in_the_loop(\n",
    "                                                                dataset,\n",
    "                                                                network,\n",
    "                                                                optimizer,\n",
    "                                                                loss_fn,\n",
    "                                                                HIL_archive,\n",
    "                                                                random_archive,\n",
    "                                                                len(dataset)\n",
    "                                                            )\n",
    "            hil_time += (time.time() - start_time)\n",
    "\n",
    "        # Train on past user information\n",
    "        start_time = time.time()\n",
    "        anchor_list, pos_list, neg_list = None, None, None\n",
    "        loss = None\n",
    "\n",
    "        average_loss = 50\n",
    "        loop = 0\n",
    "        TRANSFORMS = 10\n",
    "        network.train()\n",
    "        while (average_loss > 0.05) and loop < 20:\n",
    "\n",
    "            loss_sum = 0\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, (anchor, pos, neg) in enumerate(HIL_archive):\n",
    "                anchor_encoding = np.expand_dims(dataset[anchor][0], axis=0)\n",
    "                similar_encoding = np.expand_dims(dataset[pos][0], axis=0)\n",
    "                anti_encoding = np.expand_dims(dataset[neg][0], axis=0)\n",
    "\n",
    "                if anchor_list is None:\n",
    "                    anchor_list = np.array([anchor_encoding])\n",
    "                    pos_list = np.array([similar_encoding])\n",
    "                    neg_list = np.array([anti_encoding])\n",
    "\n",
    "                else:\n",
    "                    anchor_list = np.concatenate((anchor_list, np.array([anchor_encoding])))\n",
    "                    pos_list = np.concatenate((pos_list, np.array([similar_encoding])))\n",
    "                    neg_list = np.concatenate((neg_list, np.array([anti_encoding])))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                for i in range(TRANSFORMS):\n",
    "                    anchor_out, pos_out, neg_out = network.network_with_transforms(anchor_list, pos_list, neg_list)\n",
    "                    loss = loss_fn(anchor_out, pos_out, neg_out)\n",
    "                    loss_sum += loss.item()\n",
    "                    if loss.item() > 0:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    total_loss += 1\n",
    "\n",
    "                anchor_list, pos_list, neg_list = None, None, None\n",
    "\n",
    "                if loss is not None and i > 0 and i % 50 == 0:\n",
    "                    print(f\"Epoch Progress: {(i*100) / len(HIL_archive)}%, Immediate Loss: {loss.item()}\")\n",
    "\n",
    "            average_loss = loss_sum / (total_loss + 1)\n",
    "            print(f\"Loop: {loop}, Average Loss: {average_loss}\")\n",
    "            loop += 1\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        training_time += (time.time() - start_time)\n",
    "\n",
    "        writer.add_scalar(\"Loss/Average\", loss_sum / (total_loss + 1), epoch)\n",
    "\n",
    "        if SAVE_CLUSTER_MEDOIDS:\n",
    "            writer.add_scalar(\"Accuracy/MedoidClassification\", medoid_acc, epoch)\n",
    "            writer.add_scalar(\"Accuracy/RandomSampleClassification\", cluster_acc, epoch)\n",
    "\n",
    "        if HUMAN_IN_LOOP:\n",
    "            writer.add_scalar(\"Loss/TripletQuality\", triplet_helpfulness, epoch)\n",
    "            writer.add_scalar(\"Queries/Total_Human_Queries\", epoch*8*9, epoch)\n",
    "            writer.add_scalar(\"Queries/Total_Triplets_Generated\", len(HIL_archive), epoch)\n",
    "            writer.add_scalar(\"Queries/Total_Random_Classes\", len(random_archive), epoch)\n",
    "\n",
    "        if EVOLUTION:\n",
    "            writer.add_scalar(\"Novelty/Highest\", evolution.behavior_discovery.getBestScore(), epoch)\n",
    "            writer.add_scalar(\"Novelty/Average\", evolution.behavior_discovery.getAverageScore(), epoch)\n",
    "\n",
    "        writer.add_scalar(\"Time/Simulation\", simulation_time, epoch)\n",
    "        writer.add_scalar(\"Time/HIL\", hil_time, epoch)\n",
    "        writer.add_scalar(\"Time/Evolution\", evolution_time, epoch)\n",
    "        writer.add_scalar(\"Time/Training\", training_time, epoch)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "evolution.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pretraining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1086102/39441780.py:17: DeprecationWarning: This function is deprecated. Please call randint(0, 9999 + 1) instead\n",
      "  samples = np.random.random_integers(0, len(data) - 1, (data_size, 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 0, loss: 13.88220010439555\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 1, loss: 11.486022001902262\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 2, loss: 10.365315214792888\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 3, loss: 9.43260423183441\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 4, loss: 9.785397299130757\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 5, loss: 8.86410661538442\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 58.333333333333336\n",
      "Unsupervised Training.. 66.66666666666667\n",
      "Unsupervised Training.. 75.0\n",
      "Unsupervised Training.. 83.33333333333333\n",
      "Unsupervised Training.. 91.66666666666667\n",
      "Epoch 6, loss: 9.207166860898337\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 8.333333333333334\n",
      "Unsupervised Training.. 16.666666666666668\n",
      "Unsupervised Training.. 25.0\n",
      "Unsupervised Training.. 33.333333333333336\n",
      "Unsupervised Training.. 41.666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "target = 0.08\n",
    "loss = 50\n",
    "network = NoveltyEmbedding().to(device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "if PRETRAINING:\n",
    "    epochs = 0\n",
    "    while loss > target:\n",
    "        loss = pretraining(sampled_dataset, network, loss_fn, optimizer, data_size=600)\n",
    "        print(f\"Epoch {epochs}, loss: {loss}\")\n",
    "        epochs += 1\n",
    "        scheduler.step()\n",
    "\n",
    "network.save_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(optimizer.lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from data.swarmset import SwarmDataset, DataBuilder\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from NovelSwarmBehavior.novel_swarms.novelty.NoveltyArchive import NoveltyArchive\n",
    "from NovelSwarmBehavior.novel_swarms.config.ResultsConfig import ResultsConfig\n",
    "from NovelSwarmBehavior.novel_swarms.results.results import main as results\n",
    "from NovelSwarmBehavior.novel_swarms.config.defaults import ConfigurationDefaults\n",
    "from data.swarmset import SwarmDataset, DataBuilder\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "network = NoveltyEmbedding().to(device)\n",
    "network.load_model(\"trialA-10-18-2022\")\n",
    "# anchor_dataset = SwarmDataset(\"data/full\", rank=0)\n",
    "\n",
    "WRITE_OUT = True\n",
    "if WRITE_OUT:\n",
    "    network.eval()\n",
    "    test_archive = NoveltyArchive()\n",
    "    for i in range(len(anchor_dataset)):\n",
    "        anchor_encoding, genome, _ = anchor_dataset[i]\n",
    "        anchor_encoding = torch.from_numpy(anchor_encoding).to(device).float()\n",
    "        embedding = network(anchor_encoding.unsqueeze(0)).squeeze(0).cpu().detach().numpy()\n",
    "        test_archive.addToArchive(embedding, genome)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ui.clustering_gui import ClusteringGUI\n",
    "import pygame\n",
    "\n",
    "agent_config = ConfigurationDefaults.DIFF_DRIVE_AGENT\n",
    "world_config = ConfigurationDefaults.RECTANGULAR_WORLD\n",
    "world_config.addAgentConfig(agent_config)\n",
    "config = ResultsConfig(archive=test_archive, k_clusters=6, world_config=world_config, tsne_perplexity=16, tsne_early_exaggeration=12, skip_tsne=False)\n",
    "gui = ClusteringGUI(config)\n",
    "gui.displayGUI()\n",
    "# results(config)\n",
    "pygame.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering + Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ui.clustering_gui import ClusteringGUI\n",
    "\n",
    "# Cluster over saved behaviors\n",
    "archive = NoveltyArchive()\n",
    "for i, (_, genome, behavior, _, _, _, _) in enumerate(anchor_dataset):\n",
    "    archive.addToArchive(vec=behavior, genome=genome)\n",
    "\n",
    "agent_config = ConfigurationDefaults.DIFF_DRIVE_AGENT\n",
    "world_config = ConfigurationDefaults.RECTANGULAR_WORLD\n",
    "world_config.addAgentConfig(agent_config)\n",
    "config = ResultsConfig(archive=archive, k_clusters=7, world_config=world_config, tsne_perplexity=20, tsne_early_exaggeration=2, skip_tsne=False)\n",
    "\n",
    "gui = ClusteringGUI(config)\n",
    "gui.displayGUI()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(human_l_hist, \"b\", label='Human Loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Time (Epochs)\")\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
