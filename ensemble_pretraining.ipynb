{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pretraining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1577473/597914256.py:79: DeprecationWarning: This function is deprecated. Please call randint(0, 9999 + 1) instead\n",
      "  samples = np.random.random_integers(0, data_cutoff, (data_size, 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [0.0001], [0.0001]]\n",
      "Losses: [0.20592165 0.19463463 0.3588306 ]\n",
      "Epoch 0, loss: 0.25312895844917577, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [0.0001], [0.0001]]\n",
      "Losses: [0.19582958 0.12274272 0.34376012]\n",
      "Epoch 1, loss: 0.22077747098429645, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [0.0001], [0.0001]]\n",
      "Losses: [0.16025481 0.14388956 0.19509634]\n",
      "Epoch 2, loss: 0.16641357220564992, windowed_loss: 50\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [0.0001], [0.0001]]\n",
      "Losses: [0.18552794 0.19235476 0.20765159]\n",
      "Epoch 3, loss: 0.19517809735084954, windowed_loss: 0.19412304684693196\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [0.0001], [0.0001]]\n",
      "Losses: [0.10940551 0.09843888 0.32493112]\n",
      "Epoch 4, loss: 0.1775918361345927, windowed_loss: 0.17972783523036406\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [9.5e-05], [0.0001]]\n",
      "Losses: [0.16613134 0.11598242 0.15789795]\n",
      "Epoch 5, loss: 0.14667057037353515, windowed_loss: 0.1731468346196591\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[0.0001], [9.5e-05], [9.5e-05]]\n",
      "Losses: [0.05551357 0.10317333 0.23515059]\n",
      "Epoch 6, loss: 0.1312791624304925, windowed_loss: 0.1518471896462068\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.5e-05], [9.5e-05], [9.5e-05]]\n",
      "Losses: [0.08922101 0.11323562 0.27730878]\n",
      "Epoch 7, loss: 0.15992180585861207, windowed_loss: 0.14595717955421325\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.5e-05], [9.5e-05], [9.5e-05]]\n",
      "Losses: [0.15564483 0.13466615 0.09986565]\n",
      "Epoch 8, loss: 0.1300588731306145, windowed_loss: 0.14041994713990635\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.5e-05], [9.025e-05], [9.5e-05]]\n",
      "Losses: [0.16106352 0.36784654 0.15031406]\n",
      "Epoch 9, loss: 0.22640803948034824, windowed_loss: 0.1721295728231916\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.5e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.08836856 0.08719152 0.20179193]\n",
      "Epoch 10, loss: 0.125784004398195, windowed_loss: 0.16075030566971926\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.025e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.17054385 0.04780232 0.11361846]\n",
      "Epoch 11, loss: 0.11065487798055013, windowed_loss: 0.15428230728636447\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.025e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.25342717 0.12276443 0.21615011]\n",
      "Epoch 12, loss: 0.19744723338481976, windowed_loss: 0.14462870525452162\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.025e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.25643119 0.16390547 0.32769739]\n",
      "Epoch 13, loss: 0.2493446839650472, windowed_loss: 0.18581559844347237\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.025e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.1412766 0.1299748 0.2244928]\n",
      "Epoch 14, loss: 0.16524806531270345, windowed_loss: 0.20401332755419013\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.025e-05], [9.025e-05], [9.025e-05]]\n",
      "Losses: [0.07649772 0.09667105 0.09543857]\n",
      "Epoch 15, loss: 0.0895357794497279, windowed_loss: 0.16804284290915952\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.573749999999999e-05], [8.573749999999999e-05], [8.573749999999999e-05]]\n",
      "Losses: [0.14518714 0.19318601 0.13054985]\n",
      "Epoch 16, loss: 0.15630766474099522, windowed_loss: 0.13703050316780885\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.573749999999999e-05], [8.573749999999999e-05], [8.573749999999999e-05]]\n",
      "Losses: [0.07913757 0.05753926 0.14317347]\n",
      "Epoch 17, loss: 0.09328343363387952, windowed_loss: 0.11304229260820088\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.573749999999999e-05], [8.573749999999999e-05], [8.573749999999999e-05]]\n",
      "Losses: [0.08927966 0.17770879 0.13360095]\n",
      "Epoch 18, loss: 0.13352980041503906, windowed_loss: 0.1277069662633046\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.573749999999999e-05], [8.573749999999999e-05], [8.573749999999999e-05]]\n",
      "Losses: [0.16342409 0.08890664 0.1775913 ]\n",
      "Epoch 19, loss: 0.14330734279686083, windowed_loss: 0.12337352561525979\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.145062499999998e-05], [8.573749999999999e-05], [8.145062499999998e-05]]\n",
      "Losses: [0.17282109 0.241858   0.21710383]\n",
      "Epoch 20, loss: 0.21059430529454906, windowed_loss: 0.16247714950214964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.145062499999998e-05], [8.573749999999999e-05], [8.145062499999998e-05]]\n",
      "Losses: [0.07838492 0.10025493 0.09436211]\n",
      "Epoch 21, loss: 0.09100064934496899, windowed_loss: 0.14830076581212628\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.145062499999998e-05], [8.573749999999999e-05], [8.145062499999998e-05]]\n",
      "Losses: [0.06064319 0.10022318 0.09774089]\n",
      "Epoch 22, loss: 0.08620241832733155, windowed_loss: 0.12926579098894986\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.145062499999998e-05], [8.145062499999998e-05], [8.145062499999998e-05]]\n",
      "Losses: [0.07800858 0.12412881 0.18680879]\n",
      "Epoch 23, loss: 0.12964872948328654, windowed_loss: 0.10228393238519569\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.145062499999998e-05], [8.145062499999998e-05], [8.145062499999998e-05]]\n",
      "Losses: [0.10105735 0.19846372 0.09761786]\n",
      "Epoch 24, loss: 0.13237964372877456, windowed_loss: 0.11607693051313088\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.737809374999998e-05], [8.145062499999998e-05], [7.737809374999998e-05]]\n",
      "Losses: [0.11200917 0.0578608  0.18038105]\n",
      "Epoch 25, loss: 0.11675033887227376, windowed_loss: 0.12625957069477828\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.737809374999998e-05], [8.145062499999998e-05], [7.737809374999998e-05]]\n",
      "Losses: [0.08741167 0.14420773 0.14173667]\n",
      "Epoch 26, loss: 0.12445202287038166, windowed_loss: 0.12452733515714333\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.737809374999998e-05], [7.737809374999998e-05], [7.737809374999998e-05]]\n",
      "Losses: [0.0895525  0.21811711 0.28353501]\n",
      "Epoch 27, loss: 0.1970682089797288, windowed_loss: 0.14609019024079473\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.737809374999998e-05], [7.737809374999998e-05], [7.737809374999998e-05]]\n",
      "Losses: [0.07288124 0.0493931  0.12299973]\n",
      "Epoch 28, loss: 0.08175802502127856, windowed_loss: 0.13442608562379635\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.737809374999998e-05], [7.737809374999998e-05], [7.737809374999998e-05]]\n",
      "Losses: [0.17972746 0.09943004 0.24369935]\n",
      "Epoch 29, loss: 0.17428561498521958, windowed_loss: 0.15103728299540897\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.350918906249998e-05], [7.737809374999998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.21398084 0.2332446  0.29869026]\n",
      "Epoch 30, loss: 0.2486385654113097, windowed_loss: 0.16822740180593596\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.350918906249998e-05], [7.737809374999998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.07284418 0.0673566  0.20683143]\n",
      "Epoch 31, loss: 0.11567740233739217, windowed_loss: 0.17953386091130716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.350918906249998e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.12256644 0.07677597 0.13432453]\n",
      "Epoch 32, loss: 0.11122231356302896, windowed_loss: 0.1585127604372436\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.350918906249998e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.0751638  0.07830488 0.09928586]\n",
      "Epoch 33, loss: 0.08425151401945329, windowed_loss: 0.10371707663995815\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.350918906249998e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.14747552 0.04959935 0.14281318]\n",
      "Epoch 34, loss: 0.11329601570695103, windowed_loss: 0.10292328109647775\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.29768901 0.20407847 0.43563627]\n",
      "Epoch 35, loss: 0.3124679129918416, windowed_loss: 0.17000514757274865\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.15956259 0.05921686 0.15407712]\n",
      "Epoch 36, loss: 0.12428552449824576, windowed_loss: 0.18334981773234613\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [7.350918906249998e-05], [7.350918906249998e-05]]\n",
      "Losses: [0.11025231 0.03430121 0.14783888]\n",
      "Epoch 37, loss: 0.09746413601131006, windowed_loss: 0.17807252450046582\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [6.983372960937497e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.07554559 0.13077025 0.20825302]\n",
      "Epoch 38, loss: 0.1381896206276689, windowed_loss: 0.11997976037907492\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [6.983372960937497e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.09431407 0.10377146 0.08964296]\n",
      "Epoch 39, loss: 0.09590949674566825, windowed_loss: 0.11052108446154907\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [6.983372960937497e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.16160827 0.10616089 0.25617411]\n",
      "Epoch 40, loss: 0.17464775583627787, windowed_loss: 0.13624895773653833\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.983372960937497e-05], [6.983372960937497e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.07684957 0.14848164 0.1686304 ]\n",
      "Epoch 41, loss: 0.1313205362560754, windowed_loss: 0.13395926294600716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.12160023 0.19471404 0.05108039]\n",
      "Epoch 42, loss: 0.12246488441844422, windowed_loss: 0.1428110588369325\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.983372960937497e-05]]\n",
      "Losses: [0.17209497 0.12187339 0.12171872]\n",
      "Epoch 43, loss: 0.13856236267344665, windowed_loss: 0.13078259444932208\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.12633427 0.07763728 0.20485087]\n",
      "Epoch 44, loss: 0.13627414051691691, windowed_loss: 0.13243379586960258\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.0827232  0.07114075 0.12653465]\n",
      "Epoch 45, loss: 0.09346619860331218, windowed_loss: 0.12276756726455858\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.12407222 0.13357347 0.17884812]\n",
      "Epoch 46, loss: 0.14549793807697423, windowed_loss: 0.1250794257324011\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.634204312890622e-05], [6.634204312890622e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.04855643 0.22269888 0.11194723]\n",
      "Epoch 47, loss: 0.12773418140411377, windowed_loss: 0.12223277269480005\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.30249409724609e-05], [6.634204312890622e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.08158396 0.05883487 0.16673922]\n",
      "Epoch 48, loss: 0.10238601636886598, windowed_loss: 0.125206045283318\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.30249409724609e-05], [6.30249409724609e-05], [6.634204312890622e-05]]\n",
      "Losses: [0.10440545 0.24395018 0.08906673]\n",
      "Epoch 49, loss: 0.14580745506286621, windowed_loss: 0.12530921761194866\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.30249409724609e-05], [6.30249409724609e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.07466731 0.058202   0.22986309]\n",
      "Epoch 50, loss: 0.1209108034769694, windowed_loss: 0.12303475830290055\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.30249409724609e-05], [6.30249409724609e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.04818748 0.143667   0.23237081]\n",
      "Epoch 51, loss: 0.14140842845002652, windowed_loss: 0.1360422289966207\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.30249409724609e-05], [6.30249409724609e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.12941204 0.08469722 0.15257248]\n",
      "Epoch 52, loss: 0.12222724548975626, windowed_loss: 0.1281821591389174\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [6.30249409724609e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.23449392 0.11041874 0.11505105]\n",
      "Epoch 53, loss: 0.15332123671043055, windowed_loss: 0.13898563688340446\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [6.30249409724609e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.05716686 0.06659938 0.12509171]\n",
      "Epoch 54, loss: 0.08295264846098446, windowed_loss: 0.1195003768870571\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [6.30249409724609e-05]]\n",
      "Losses: [0.09373975 0.11834913 0.11657821]\n",
      "Epoch 55, loss: 0.10955569818964304, windowed_loss: 0.11527652778701936\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.07772596 0.06101805 0.17535324]\n",
      "Epoch 56, loss: 0.1046990836461385, windowed_loss: 0.09906914343225533\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.06584611 0.10502442 0.11275462]\n",
      "Epoch 57, loss: 0.09454171882124845, windowed_loss: 0.10293216688567668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.0593228  0.01376458 0.07647894]\n",
      "Epoch 58, loss: 0.04985544187442157, windowed_loss: 0.0830320814472695\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.15475961 0.15798293 0.15255952]\n",
      "Epoch 59, loss: 0.15510068643706276, windowed_loss: 0.09983261571091091\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.987369392383786e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.13266892 0.05224875 0.08288164]\n",
      "Epoch 60, loss: 0.08926643975575765, windowed_loss: 0.09807418935574734\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.688000922764596e-05], [5.987369392383786e-05]]\n",
      "Losses: [0.07201503 0.06477473 0.12144461]\n",
      "Epoch 61, loss: 0.08607812587149398, windowed_loss: 0.11014841735477147\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.987369392383786e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.0706104  0.06435221 0.12321713]\n",
      "Epoch 62, loss: 0.0860599149080989, windowed_loss: 0.08713482684511685\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.09993253 0.05273858 0.18968719]\n",
      "Epoch 63, loss: 0.11411943403879803, windowed_loss: 0.09541915827279697\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.04312279 0.07447584 0.0950428 ]\n",
      "Epoch 64, loss: 0.07088047819449732, windowed_loss: 0.09035327571379809\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.10163228 0.0944839  0.16435051]\n",
      "Epoch 65, loss: 0.12015556634828907, windowed_loss: 0.10171849286052814\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.0908673  0.08017503 0.11076518]\n",
      "Epoch 66, loss: 0.09393583563277362, windowed_loss: 0.09499062672518667\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.688000922764596e-05], [5.688000922764596e-05]]\n",
      "Losses: [0.08796212 0.0556778  0.07522287]\n",
      "Epoch 67, loss: 0.0729542636871338, windowed_loss: 0.0956818885560655\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.4036008766263664e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.17986431 0.13662547 0.1616873 ]\n",
      "Epoch 68, loss: 0.15939236276533575, windowed_loss: 0.10876082069508104\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.688000922764596e-05], [5.4036008766263664e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.06499446 0.04104724 0.05168296]\n",
      "Epoch 69, loss: 0.052574886004130045, windowed_loss: 0.09497383748553319\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.4036008766263664e-05], [5.4036008766263664e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.09519955 0.08852731 0.16886112]\n",
      "Epoch 70, loss: 0.11752932649380073, windowed_loss: 0.10983219175442217\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.4036008766263664e-05], [5.4036008766263664e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.08083174 0.09205728 0.11578316]\n",
      "Epoch 71, loss: 0.09622406002029356, windowed_loss: 0.08877609083940811\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.4036008766263664e-05], [5.4036008766263664e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.13635733 0.05151482 0.24820808]\n",
      "Epoch 72, loss: 0.14536007756050653, windowed_loss: 0.11970448802486694\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.4036008766263664e-05], [5.133420832795048e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.14237511 0.11560687 0.18927888]\n",
      "Epoch 73, loss: 0.14908695252800117, windowed_loss: 0.13022369670293377\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.4036008766263664e-05], [5.133420832795048e-05], [5.4036008766263664e-05]]\n",
      "Losses: [0.09934763 0.07392242 0.12409925]\n",
      "Epoch 74, loss: 0.09912309968320225, windowed_loss: 0.13119004325723665\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.133420832795048e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.13532993 0.06165122 0.29493571]\n",
      "Epoch 75, loss: 0.1639722863594213, windowed_loss: 0.1373941128568749\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.133420832795048e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.14959922 0.08335058 0.22906483]\n",
      "Epoch 76, loss: 0.15400487830839962, windowed_loss: 0.13903342145034106\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.133420832795048e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.11135451 0.04745205 0.11267339]\n",
      "Epoch 77, loss: 0.09049331544635292, windowed_loss: 0.1361568267047246\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.133420832795048e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.11490908 0.14357455 0.24651314]\n",
      "Epoch 78, loss: 0.16833225758615622, windowed_loss: 0.1376101504469696\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.14798628 0.09549625 0.23620756]\n",
      "Epoch 79, loss: 0.15989669752120972, windowed_loss: 0.13957409018457295\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [5.133420832795048e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.10491942 0.05454598 0.14396813]\n",
      "Epoch 80, loss: 0.10114451384815122, windowed_loss: 0.14312448965183905\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [4.876749791155295e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.09754454 0.05533569 0.13509958]\n",
      "Epoch 81, loss: 0.09599326764404215, windowed_loss: 0.11901149300446769\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [4.876749791155295e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.11062039 0.14708115 0.15581001]\n",
      "Epoch 82, loss: 0.13783718347549437, windowed_loss: 0.11165832165589591\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [4.876749791155295e-05], [5.133420832795048e-05]]\n",
      "Losses: [0.0983986  0.05955662 0.13857392]\n",
      "Epoch 83, loss: 0.09884304614111761, windowed_loss: 0.11089116575355136\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [4.876749791155295e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.03801427 0.09754715 0.15210954]\n",
      "Epoch 84, loss: 0.09589031764439175, windowed_loss: 0.11085684908700123\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.876749791155295e-05], [4.876749791155295e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.11326061 0.06112523 0.08409135]\n",
      "Epoch 85, loss: 0.08615906459933213, windowed_loss: 0.09363080946161384\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6329123015975305e-05], [4.6329123015975305e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.15975582 0.09720257 0.26843616]\n",
      "Epoch 86, loss: 0.17513151836395266, windowed_loss: 0.11906030020255885\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6329123015975305e-05], [4.6329123015975305e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.05052786 0.03329451 0.04974417]\n",
      "Epoch 87, loss: 0.04452217960421628, windowed_loss: 0.10193758752250036\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6329123015975305e-05], [4.6329123015975305e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.05313332 0.09825047 0.20596531]\n",
      "Epoch 88, loss: 0.11911636503186411, windowed_loss: 0.11292335433334434\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6329123015975305e-05], [4.6329123015975305e-05], [4.876749791155295e-05]]\n",
      "Losses: [0.0823984  0.06727397 0.09308323]\n",
      "Epoch 89, loss: 0.08091853373500717, windowed_loss: 0.08151902612369587\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.4012666865176535e-05], [4.6329123015975305e-05], [4.6329123015975305e-05]]\n",
      "Losses: [0.11897316 0.03625244 0.13865259]\n",
      "Epoch 90, loss: 0.09795939850663853, windowed_loss: 0.09933143242450326\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.4012666865176535e-05], [4.6329123015975305e-05], [4.6329123015975305e-05]]\n",
      "Losses: [0.04284982 0.11285429 0.08502108]\n",
      "Epoch 91, loss: 0.08024172935791628, windowed_loss: 0.08637322053318731\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.4012666865176535e-05], [4.6329123015975305e-05], [4.6329123015975305e-05]]\n",
      "Losses: [0.05505761 0.07616487 0.11082618]\n",
      "Epoch 92, loss: 0.0806828875541687, windowed_loss: 0.08629467180624117\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.4012666865176535e-05], [4.4012666865176535e-05], [4.6329123015975305e-05]]\n",
      "Losses: [0.06019885 0.08113946 0.21294127]\n",
      "Epoch 93, loss: 0.11809319173786002, windowed_loss: 0.09300593621664834\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.181203352191771e-05], [4.4012666865176535e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.09198505 0.09126534 0.24126703]\n",
      "Epoch 94, loss: 0.14150580755869546, windowed_loss: 0.11342729561690806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.181203352191771e-05], [4.4012666865176535e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.13857031 0.15828425 0.18943405]\n",
      "Epoch 95, loss: 0.16209620400596317, windowed_loss: 0.1405650677675062\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.181203352191771e-05], [4.4012666865176535e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.05623197 0.09742767 0.12047803]\n",
      "Epoch 96, loss: 0.09137922437634653, windowed_loss: 0.13166041198033504\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.181203352191771e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.15892667 0.30636768 0.09752292]\n",
      "Epoch 97, loss: 0.1876057554422097, windowed_loss: 0.1470270612748398\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.181203352191771e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.03757499 0.12342377 0.08378417]\n",
      "Epoch 98, loss: 0.081594311084123, windowed_loss: 0.12019309696755975\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.09635659 0.08575027 0.24860347]\n",
      "Epoch 99, loss: 0.14357010905712386, windowed_loss: 0.13759005852781886\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.04230996 0.0756456  0.08771179]\n",
      "Epoch 100, loss: 0.06855578524475504, windowed_loss: 0.09790673512866731\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.02855081 0.02363096 0.07612338]\n",
      "Epoch 101, loss: 0.04276838283500595, windowed_loss: 0.08496475904562828\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.4012666865176535e-05]]\n",
      "Losses: [0.14414857 0.06386573 0.09474275]\n",
      "Epoch 102, loss: 0.1009190165201823, windowed_loss: 0.0707477281999811\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.11636462 0.06348054 0.13926897]\n",
      "Epoch 103, loss: 0.10637137778600057, windowed_loss: 0.08335292571372961\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [4.181203352191771e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.116815   0.0953957  0.18666259]\n",
      "Epoch 104, loss: 0.13295776287714642, windowed_loss: 0.11341605239444309\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [3.972143184582182e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.11138863 0.10767294 0.16188041]\n",
      "Epoch 105, loss: 0.12698066178846135, windowed_loss: 0.12210326748386945\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [3.972143184582182e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.10044752 0.22765743 0.11435046]\n",
      "Epoch 106, loss: 0.1474851364261108, windowed_loss: 0.13580785369723955\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [3.972143184582182e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.08909943 0.04205357 0.05631267]\n",
      "Epoch 107, loss: 0.06248855750084561, windowed_loss: 0.11231811857180592\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [3.972143184582182e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.06025173 0.07644401 0.15173185]\n",
      "Epoch 108, loss: 0.09614253188043054, windowed_loss: 0.10203874193579565\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.972143184582182e-05], [3.972143184582182e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.01031434 0.01631943 0.06995391]\n",
      "Epoch 109, loss: 0.032195892040349706, windowed_loss: 0.06360899380720862\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.7735360253530726e-05], [4.181203352191771e-05]]\n",
      "Losses: [0.0931463  0.05070881 0.0487905 ]\n",
      "Epoch 110, loss: 0.06421520205123789, windowed_loss: 0.06418454199067271\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.7735360253530726e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.07339517 0.06002882 0.12033057]\n",
      "Epoch 111, loss: 0.08458485309697857, windowed_loss: 0.06033198239618872\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.7735360253530726e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.07154925 0.06783814 0.11574508]\n",
      "Epoch 112, loss: 0.0850441573696608, windowed_loss: 0.07794807083929241\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.584859224085419e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.10683621 0.09217021 0.14833323]\n",
      "Epoch 113, loss: 0.11577987972895304, windowed_loss: 0.09513629673186413\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.584859224085419e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.19266343 0.10057469 0.27577462]\n",
      "Epoch 114, loss: 0.189670911471049, windowed_loss: 0.13016498285655428\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7735360253530726e-05], [3.584859224085419e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.0447746  0.02573994 0.13113665]\n",
      "Epoch 115, loss: 0.06721706460457127, windowed_loss: 0.12422261860152445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.584859224085419e-05], [3.972143184582182e-05]]\n",
      "Losses: [0.06430868 0.05743277 0.0566539 ]\n",
      "Epoch 116, loss: 0.05946511676512569, windowed_loss: 0.10545103094691533\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.584859224085419e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.05902967 0.03624746 0.08822158]\n",
      "Epoch 117, loss: 0.06116623460368778, windowed_loss: 0.06261613865779492\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.405616262881148e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.10584412 0.07118324 0.11394643]\n",
      "Epoch 118, loss: 0.09699126068687185, windowed_loss: 0.07254087068522845\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.405616262881148e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.0847588  0.10115745 0.23944103]\n",
      "Epoch 119, loss: 0.14178576040267946, windowed_loss: 0.0999810852310797\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.405616262881148e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.14638996 0.14615065 0.19385922]\n",
      "Epoch 120, loss: 0.16213327550888063, windowed_loss: 0.13363676553281065\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.584859224085419e-05], [3.405616262881148e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.07706452 0.03824373 0.16161407]\n",
      "Epoch 121, loss: 0.0923074385325114, windowed_loss: 0.13207549148135717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.405616262881148e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.08159297 0.03234088 0.08885436]\n",
      "Epoch 122, loss: 0.06759606993980356, windowed_loss: 0.10734559466039852\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.7735360253530726e-05]]\n",
      "Losses: [0.06460747 0.06018064 0.07352046]\n",
      "Epoch 123, loss: 0.06610285758972169, windowed_loss: 0.07533545535401222\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.584859224085419e-05]]\n",
      "Losses: [0.08993585 0.07369423 0.11269374]\n",
      "Epoch 124, loss: 0.09210794212504396, windowed_loss: 0.07526895655152306\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.584859224085419e-05]]\n",
      "Losses: [0.06401776 0.04227613 0.13657541]\n",
      "Epoch 125, loss: 0.08095643234252929, windowed_loss: 0.07972241068576498\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.584859224085419e-05]]\n",
      "Losses: [0.18499693 0.24216831 0.24735645]\n",
      "Epoch 126, loss: 0.2248405623435974, windowed_loss: 0.1326349789370569\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.584859224085419e-05]]\n",
      "Losses: [0.11533898 0.10536565 0.11438345]\n",
      "Epoch 127, loss: 0.11169602923498363, windowed_loss: 0.13916434130703678\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.2353354497370904e-05], [3.405616262881148e-05]]\n",
      "Losses: [0.08439317 0.06912646 0.14648187]\n",
      "Epoch 128, loss: 0.10000049852894877, windowed_loss: 0.14551236336917658\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.0735686772502355e-05], [3.405616262881148e-05]]\n",
      "Losses: [0.06986817 0.49496935 0.04592479]\n",
      "Epoch 129, loss: 0.20358743985493977, windowed_loss: 0.1384279892062907\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.405616262881148e-05], [3.0735686772502355e-05], [3.405616262881148e-05]]\n",
      "Losses: [0.02555546 0.02294537 0.09803069]\n",
      "Epoch 130, loss: 0.04884383960333998, windowed_loss: 0.11747725932907617\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [3.0735686772502355e-05], [3.405616262881148e-05]]\n",
      "Losses: [0.05465704 0.0576107  0.079368  ]\n",
      "Epoch 131, loss: 0.0638785785039266, windowed_loss: 0.10543661932073545\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [3.0735686772502355e-05], [3.405616262881148e-05]]\n",
      "Losses: [0.0311842  0.06851886 0.09191447]\n",
      "Epoch 132, loss: 0.06387250823184659, windowed_loss: 0.05886497544637106\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [3.0735686772502355e-05], [3.2353354497370904e-05]]\n",
      "Losses: [0.07423538 0.0606727  0.09567433]\n",
      "Epoch 133, loss: 0.07686080144271952, windowed_loss: 0.06820396272616423\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [2.9198902433877236e-05], [3.2353354497370904e-05]]\n",
      "Losses: [0.06344533 0.07730222 0.06725854]\n",
      "Epoch 134, loss: 0.06933536491240842, windowed_loss: 0.07002289152899151\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [2.9198902433877236e-05], [3.2353354497370904e-05]]\n",
      "Losses: [0.04676623 0.12406944 0.07526655]\n",
      "Epoch 135, loss: 0.08203407232590285, windowed_loss: 0.07607674622701026\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2353354497370904e-05], [2.9198902433877236e-05], [3.2353354497370904e-05]]\n",
      "Losses: [0.04778871 0.08426106 0.10068317]\n",
      "Epoch 136, loss: 0.07757764514287313, windowed_loss: 0.07631569412706146\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.9198902433877236e-05], [3.0735686772502355e-05]]\n",
      "Losses: [0.1265602  0.10616004 0.1503353 ]\n",
      "Epoch 137, loss: 0.1276851803723955, windowed_loss: 0.09576563261372384\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.9198902433877236e-05], [3.0735686772502355e-05]]\n",
      "Losses: [0.0773708  0.09138264 0.10656825]\n",
      "Epoch 138, loss: 0.09177389667284193, windowed_loss: 0.09901224072937019\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.9198902433877236e-05], [3.0735686772502355e-05]]\n",
      "Losses: [0.02182174 0.06757166 0.05173072]\n",
      "Epoch 139, loss: 0.047041373644658706, windowed_loss: 0.08883348356329872\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.7738957312183373e-05], [3.0735686772502355e-05]]\n",
      "Losses: [0.09004594 0.12075474 0.08593532]\n",
      "Epoch 140, loss: 0.0989119989042212, windowed_loss: 0.07924242307390728\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.7738957312183373e-05], [3.0735686772502355e-05]]\n",
      "Losses: [0.17120588 0.10116382 0.13267905]\n",
      "Epoch 141, loss: 0.1350162493387858, windowed_loss: 0.09365654062922191\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0735686772502355e-05], [2.7738957312183373e-05], [2.9198902433877236e-05]]\n",
      "Losses: [0.06600917 0.06636314 0.14354229]\n",
      "Epoch 142, loss: 0.0919715321858724, windowed_loss: 0.1086332601429598\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.9198902433877236e-05], [2.7738957312183373e-05], [2.9198902433877236e-05]]\n",
      "Losses: [0.09597579 0.07470803 0.15999659]\n",
      "Epoch 143, loss: 0.11022680301067427, windowed_loss: 0.11240486151177749\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.9198902433877236e-05], [2.7738957312183373e-05], [2.9198902433877236e-05]]\n",
      "Losses: [0.0429134  0.03678013 0.03411512]\n",
      "Epoch 144, loss: 0.03793621638890963, windowed_loss: 0.08004485052848544\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.9198902433877236e-05], [2.7738957312183373e-05], [2.9198902433877236e-05]]\n",
      "Losses: [0.0803646  0.11691504 0.11355147]\n",
      "Epoch 145, loss: 0.10361037021340774, windowed_loss: 0.08392446320433056\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.9198902433877236e-05], [2.7738957312183373e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.17370972 0.08664785 0.17250885]\n",
      "Epoch 146, loss: 0.14428880808746805, windowed_loss: 0.09527846489659514\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.9198902433877236e-05], [2.7738957312183373e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.09610974 0.04608075 0.10412573]\n",
      "Epoch 147, loss: 0.08210540502646324, windowed_loss: 0.11000152777577969\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.12934915 0.10606452 0.14205696]\n",
      "Epoch 148, loss: 0.1258235451686813, windowed_loss: 0.11740591942753753\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.10060271 0.11668015 0.1402734 ]\n",
      "Epoch 149, loss: 0.11918541971842449, windowed_loss: 0.109038123304523\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.05735032 0.03604609 0.03207185]\n",
      "Epoch 150, loss: 0.041822755663253185, windowed_loss: 0.09561057351678631\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.05311227 0.01194811 0.15903505]\n",
      "Epoch 151, loss: 0.07469847594877803, windowed_loss: 0.07856888377681857\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.7738957312183373e-05]]\n",
      "Losses: [0.03221825 0.17905929 0.0799038 ]\n",
      "Epoch 152, loss: 0.09706044658948838, windowed_loss: 0.07119389273383986\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.6352009446574204e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.06368599 0.04577193 0.12181714]\n",
      "Epoch 153, loss: 0.07709168734833967, windowed_loss: 0.08295020329553536\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.02931307 0.07620559 0.11452944]\n",
      "Epoch 154, loss: 0.0733493664460574, windowed_loss: 0.08250050012796183\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7738957312183373e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.09969816 0.05435848 0.1724025 ]\n",
      "Epoch 155, loss: 0.10881971612164555, windowed_loss: 0.08642025663868087\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.11577558 0.12760709 0.14382763]\n",
      "Epoch 156, loss: 0.12907009887695312, windowed_loss: 0.10374639381488536\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.13983489 0.08496466 0.0924303 ]\n",
      "Epoch 157, loss: 0.10574328452548189, windowed_loss: 0.11454436650802685\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.05250459 0.07649669 0.15023633]\n",
      "Epoch 158, loss: 0.09307920106252034, windowed_loss: 0.10929752815498511\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.5034408974245492e-05], [2.6352009446574204e-05]]\n",
      "Losses: [0.04181068 0.04415068 0.08207109]\n",
      "Epoch 159, loss: 0.05601081771697692, windowed_loss: 0.08494443443499305\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.5034408974245492e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.12113445 0.07012503 0.37911265]\n",
      "Epoch 160, loss: 0.1901240415841221, windowed_loss: 0.11307135345453978\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6352009446574204e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.08489904 0.07260217 0.16584479]\n",
      "Epoch 161, loss: 0.10778200076911637, windowed_loss: 0.1179722866900718\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.12168434 0.0353941  0.11520701]\n",
      "Epoch 162, loss: 0.09076181760274742, windowed_loss: 0.12955595331866196\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.06751068 0.06707833 0.17149301]\n",
      "Epoch 163, loss: 0.10202733707555645, windowed_loss: 0.10019038514914008\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.04948977 0.04874083 0.05409992]\n",
      "Epoch 164, loss: 0.05077684061003273, windowed_loss: 0.08118866509611221\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.09307965 0.10329956 0.09777993]\n",
      "Epoch 165, loss: 0.09805304652145885, windowed_loss: 0.08361907473568268\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.5034408974245492e-05]]\n",
      "Losses: [0.0975909  0.06564836 0.09601701]\n",
      "Epoch 166, loss: 0.08641875546696827, windowed_loss: 0.07841621419948662\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5034408974245492e-05], [2.3782688525533216e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.04298617 0.04992252 0.16144768]\n",
      "Epoch 167, loss: 0.0847854580745161, windowed_loss: 0.08975242002098106\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3782688525533216e-05], [2.2593554099256555e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.07565917 0.07350644 0.10850986]\n",
      "Epoch 168, loss: 0.08589182249704996, windowed_loss: 0.08569867867951143\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3782688525533216e-05], [2.2593554099256555e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.09877916 0.07123271 0.18839836]\n",
      "Epoch 169, loss: 0.11947007567865019, windowed_loss: 0.09671578541673875\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3782688525533216e-05], [2.2593554099256555e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.12869364 0.09134527 0.12452446]\n",
      "Epoch 170, loss: 0.11485445467631021, windowed_loss: 0.10673878428400346\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3782688525533216e-05], [2.2593554099256555e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.07600369 0.03393989 0.11415832]\n",
      "Epoch 171, loss: 0.07470063392369047, windowed_loss: 0.10300838809288364\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3782688525533216e-05], [2.2593554099256555e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.04663615 0.0639806  0.09059385]\n",
      "Epoch 172, loss: 0.06707020171483358, windowed_loss: 0.08554176343827809\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.3782688525533216e-05]]\n",
      "Losses: [0.07222073 0.14855037 0.10501548]\n",
      "Epoch 173, loss: 0.10859552828088632, windowed_loss: 0.08345545463980346\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.13065022 0.04624903 0.18412614]\n",
      "Epoch 174, loss: 0.120341796875, windowed_loss: 0.0986691756235733\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.08887423 0.06396488 0.10453969]\n",
      "Epoch 175, loss: 0.08579293535735553, windowed_loss: 0.10491008683774729\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.05583135 0.06243049 0.09987501]\n",
      "Epoch 176, loss: 0.0727122816216036, windowed_loss: 0.09294900461798639\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.03693619 0.05321219 0.02187378]\n",
      "Epoch 177, loss: 0.037340716831510516, windowed_loss: 0.06528197793682322\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2593554099256555e-05], [2.1463876394293726e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.08134285 0.10205195 0.14713979]\n",
      "Epoch 178, loss: 0.11017819604000889, windowed_loss: 0.07341039816437434\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.12611571 0.15161502 0.15862167]\n",
      "Epoch 179, loss: 0.1454508023162883, windowed_loss: 0.09765657172926923\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.2593554099256555e-05]]\n",
      "Losses: [0.04893806 0.01811881 0.10289985]\n",
      "Epoch 180, loss: 0.056652239846736396, windowed_loss: 0.10409374606767785\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.1463876394293726e-05]]\n",
      "Losses: [0.12181566 0.15321469 0.11784697]\n",
      "Epoch 181, loss: 0.13095910994211832, windowed_loss: 0.111020717368381\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.1463876394293726e-05]]\n",
      "Losses: [0.07182427 0.02091705 0.12393276]\n",
      "Epoch 182, loss: 0.07222469567772848, windowed_loss: 0.08661201515552773\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.1463876394293726e-05]]\n",
      "Losses: [0.04723428 0.09956202 0.20113264]\n",
      "Epoch 183, loss: 0.11597631259528333, windowed_loss: 0.10638670607171004\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.1463876394293726e-05]]\n",
      "Losses: [0.09252318 0.09740123 0.12007595]\n",
      "Epoch 184, loss: 0.10333345381418864, windowed_loss: 0.09717815402906682\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [2.039068257457904e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.07623352 0.03151202 0.14210077]\n",
      "Epoch 185, loss: 0.08328210614726157, windowed_loss: 0.10086395751891118\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1463876394293726e-05], [1.9371148445850086e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.04876288 0.08277025 0.06698004]\n",
      "Epoch 186, loss: 0.06617105779603234, windowed_loss: 0.08426220591916085\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.08214909 0.04109256 0.17402495]\n",
      "Epoch 187, loss: 0.09908886408121009, windowed_loss: 0.08284734267483466\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.09444068 0.03437808 0.13488129]\n",
      "Epoch 188, loss: 0.08790001551310223, windowed_loss: 0.08438664579678155\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.08437236 0.07140068 0.15703899]\n",
      "Epoch 189, loss: 0.10427067605367146, windowed_loss: 0.09708651854932793\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [2.039068257457904e-05]]\n",
      "Losses: [0.06954008 0.0356021  0.03624935]\n",
      "Epoch 190, loss: 0.047130510510211006, windowed_loss: 0.0797670673589949\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [1.9371148445850086e-05]]\n",
      "Losses: [0.06034757 0.06314488 0.10193539]\n",
      "Epoch 191, loss: 0.07514261355301342, windowed_loss: 0.0755146000389653\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.9371148445850086e-05], [1.9371148445850086e-05]]\n",
      "Losses: [0.05956682 0.04032362 0.06610977]\n",
      "Epoch 192, loss: 0.05533340210257126, windowed_loss: 0.059202175388598566\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.840259102355758e-05], [1.9371148445850086e-05]]\n",
      "Losses: [0.0571191  0.09326766 0.11018125]\n",
      "Epoch 193, loss: 0.08685600574444992, windowed_loss: 0.07244400713334487\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.840259102355758e-05], [1.9371148445850086e-05]]\n",
      "Losses: [0.01851895 0.05529335 0.03878228]\n",
      "Epoch 194, loss: 0.037531526548988274, windowed_loss: 0.05990697813200315\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.840259102355758e-05], [1.9371148445850086e-05]]\n",
      "Losses: [0.05885008 0.07222822 0.06633115]\n",
      "Epoch 195, loss: 0.06580315069429223, windowed_loss: 0.06339689432924346\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.840259102355758e-05], [1.840259102355758e-05]]\n",
      "Losses: [0.0502926  0.04842306 0.09281641]\n",
      "Epoch 196, loss: 0.06384402477669572, windowed_loss: 0.055726234006658736\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.039068257457904e-05], [1.840259102355758e-05], [1.840259102355758e-05]]\n",
      "Losses: [0.03271442 0.04583137 0.05475644]\n",
      "Epoch 197, loss: 0.04443407853444417, windowed_loss: 0.05802708466847737\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.840259102355758e-05], [1.840259102355758e-05]]\n",
      "Losses: [0.08092749 0.07783063 0.10722098]\n",
      "Epoch 198, loss: 0.08865969915268974, windowed_loss: 0.06564593415460988\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.840259102355758e-05], [1.840259102355758e-05]]\n",
      "Losses: [0.04427477 0.00823056 0.05487655]\n",
      "Epoch 199, loss: 0.035793959337946726, windowed_loss: 0.056295912341693545\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.74824614723797e-05], [1.840259102355758e-05]]\n",
      "Losses: [0.10076114 0.08848173 0.09693839]\n",
      "Epoch 200, loss: 0.09539375241597493, windowed_loss: 0.0732824703022038\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.03844153 0.06237556 0.21126232]\n",
      "Epoch 201, loss: 0.10402646666777159, windowed_loss: 0.07840472614056442\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.04300072 0.05390436 0.12787051]\n",
      "Epoch 202, loss: 0.07492519667248927, windowed_loss: 0.09144847191874526\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9371148445850086e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.04137948 0.05570743 0.13367684]\n",
      "Epoch 203, loss: 0.07692124938964844, windowed_loss: 0.08529097090996977\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.13611796 0.160406   0.17522116]\n",
      "Epoch 204, loss: 0.15724837572539507, windowed_loss: 0.10303160726251093\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.07045468 0.04952935 0.11208503]\n",
      "Epoch 205, loss: 0.07735635725657146, windowed_loss: 0.10384199412387167\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.74824614723797e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.06500071 0.03548186 0.11176357]\n",
      "Epoch 206, loss: 0.07074871533353565, windowed_loss: 0.10178448277183406\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.6608338398760715e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.050759   0.11557175 0.1009681 ]\n",
      "Epoch 207, loss: 0.08909961678779516, windowed_loss: 0.07906822979263409\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.6608338398760715e-05], [1.74824614723797e-05]]\n",
      "Losses: [0.08121359 0.07706864 0.06557171]\n",
      "Epoch 208, loss: 0.0746179821505633, windowed_loss: 0.07815543809063137\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.6608338398760715e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.11865431 0.12649646 0.14665606]\n",
      "Epoch 209, loss: 0.13060227662843552, windowed_loss: 0.09810662518893132\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.840259102355758e-05], [1.6608338398760715e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.04924603 0.057987   0.06187729]\n",
      "Epoch 210, loss: 0.0563701099181271, windowed_loss: 0.08719678956570863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.6608338398760715e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.1538719  0.08450716 0.14251454]\n",
      "Epoch 211, loss: 0.1269645347812249, windowed_loss: 0.10464564044259583\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.6608338398760715e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.12052364 0.0273227  0.10637006]\n",
      "Epoch 212, loss: 0.08473879763820447, windowed_loss: 0.08935781411251882\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.5777921478822678e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.04546063 0.12954994 0.07038914]\n",
      "Epoch 213, loss: 0.08179990593879001, windowed_loss: 0.09783441278607313\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.5777921478822678e-05], [1.6608338398760715e-05]]\n",
      "Losses: [0.06739817 0.19470758 0.10672177]\n",
      "Epoch 214, loss: 0.12294250511261355, windowed_loss: 0.09649373622986934\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.07357578 0.15031634 0.12051832]\n",
      "Epoch 215, loss: 0.1148034832084993, windowed_loss: 0.10651529808663429\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.74824614723797e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.03204671 0.12535284 0.10055169]\n",
      "Epoch 216, loss: 0.08598374522514292, windowed_loss: 0.10790991118208526\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6608338398760715e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.03401872 0.04215013 0.07757988]\n",
      "Epoch 217, loss: 0.05124957830649499, windowed_loss: 0.08401226891337908\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6608338398760715e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.00637781 0.02137944 0.06363398]\n",
      "Epoch 218, loss: 0.030463744579511398, windowed_loss: 0.05589902270371644\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6608338398760715e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.05384151 0.18720325 0.1256933 ]\n",
      "Epoch 219, loss: 0.12224602110002068, windowed_loss: 0.06798644799534236\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6608338398760715e-05], [1.5777921478822678e-05], [1.5777921478822678e-05]]\n",
      "Losses: [0.08590963 0.04499356 0.13662137]\n",
      "Epoch 220, loss: 0.08917485055834096, windowed_loss: 0.08062820541262435\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.10082861 0.06829088 0.20925339]\n",
      "Epoch 221, loss: 0.1261242947422351, windowed_loss: 0.11251505546686558\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.07317826 0.03694563 0.10441676]\n",
      "Epoch 222, loss: 0.07151355023533802, windowed_loss: 0.0956042318453047\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.05165476 0.01902426 0.07584699]\n",
      "Epoch 223, loss: 0.04884200434448569, windowed_loss: 0.08215994977401961\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.13603005 0.08444619 0.13909585]\n",
      "Epoch 224, loss: 0.11985736311359739, windowed_loss: 0.08007097256447371\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.06718259 0.04777791 0.10538855]\n",
      "Epoch 225, loss: 0.07344968096415201, windowed_loss: 0.08071634947407837\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.03605819 0.03863326 0.09639827]\n",
      "Epoch 226, loss: 0.05702990812150988, windowed_loss: 0.08344565073308642\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4989025404881544e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.13064295 0.1226379  0.12057001]\n",
      "Epoch 227, loss: 0.12461695671081545, windowed_loss: 0.08503218193215911\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4239574134637466e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.12543945 0.13110429 0.08674377]\n",
      "Epoch 228, loss: 0.11442916936371116, windowed_loss: 0.09869201139867884\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5777921478822678e-05], [1.4239574134637466e-05], [1.4989025404881544e-05]]\n",
      "Losses: [0.03308543 0.06276658 0.07387231]\n",
      "Epoch 229, loss: 0.05657477060953776, windowed_loss: 0.09854029889468813\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4989025404881544e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.09022635 0.60177554 0.24641809]\n",
      "Epoch 230, loss: 0.3128066623067281, windowed_loss: 0.16127020075999235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4989025404881544e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.11347761 0.14974154 0.07862098]\n",
      "Epoch 231, loss: 0.11394670890344329, windowed_loss: 0.1611093806065697\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4989025404881544e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.13206825 0.09140893 0.10501673]\n",
      "Epoch 232, loss: 0.10949796803792318, windowed_loss: 0.17875044641603152\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4989025404881544e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.09975184 0.30936163 0.17342054]\n",
      "Epoch 233, loss: 0.19417800394694015, windowed_loss: 0.1392075602961022\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4239574134637466e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.11903275 0.09163552 0.11213399]\n",
      "Epoch 234, loss: 0.10760075489679972, windowed_loss: 0.1370922422938877\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4239574134637466e-05], [1.4239574134637466e-05], [1.4239574134637466e-05]]\n",
      "Losses: [0.03250198 0.04106395 0.03900605]\n",
      "Epoch 235, loss: 0.03752399317423503, windowed_loss: 0.11310091733932498\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4239574134637466e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.09377526 0.20696027 0.18060064]\n",
      "Epoch 236, loss: 0.16044539105677175, windowed_loss: 0.10185671304260217\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4239574134637466e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.08523267 0.06026569 0.15017698]\n",
      "Epoch 237, loss: 0.09855844601091131, windowed_loss: 0.09884261008063937\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4239574134637466e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.08706115 0.06712299 0.09491089]\n",
      "Epoch 238, loss: 0.08303167554005512, windowed_loss: 0.11401183753591272\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3527595427905592e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.09872635 0.07446167 0.07957431]\n",
      "Epoch 239, loss: 0.08425410906473796, windowed_loss: 0.08861474353856813\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3527595427905592e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.03704801 0.03962462 0.07939443]\n",
      "Epoch 240, loss: 0.05202235344177736, windowed_loss: 0.07310271268219015\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3527595427905592e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.07336307 0.03632858 0.06310991]\n",
      "Epoch 241, loss: 0.05760051862622201, windowed_loss: 0.06462566037757911\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3527595427905592e-05], [1.3527595427905592e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.02788437 0.0291882  0.03353628]\n",
      "Epoch 242, loss: 0.03020294953284458, windowed_loss: 0.046608607200281316\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3527595427905592e-05], [1.2851215656510312e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.07710497 0.05723249 0.11008738]\n",
      "Epoch 243, loss: 0.08147494923797159, windowed_loss: 0.056426139132346065\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2851215656510312e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.0798415  0.05784139 0.05651307]\n",
      "Epoch 244, loss: 0.06473198934819856, windowed_loss: 0.058803296039671576\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2851215656510312e-05], [1.3527595427905592e-05]]\n",
      "Losses: [0.06602341 0.07511335 0.07543504]\n",
      "Epoch 245, loss: 0.07219059832890828, windowed_loss: 0.07279917897169282\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2851215656510312e-05], [1.2851215656510312e-05]]\n",
      "Losses: [0.02129682 0.05814615 0.08478564]\n",
      "Epoch 246, loss: 0.05474286784768264, windowed_loss: 0.06388848517492983\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2208654873684796e-05], [1.2851215656510312e-05]]\n",
      "Losses: [0.09738387 0.08671557 0.19976073]\n",
      "Epoch 247, loss: 0.12795338777199378, windowed_loss: 0.08496228464952822\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2208654873684796e-05], [1.2851215656510312e-05]]\n",
      "Losses: [0.03461123 0.08042317 0.14182853]\n",
      "Epoch 248, loss: 0.08562097628911336, windowed_loss: 0.08943907730292992\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2208654873684796e-05], [1.2851215656510312e-05]]\n",
      "Losses: [0.07821317 0.10309085 0.14819958]\n",
      "Epoch 249, loss: 0.1098345343717831, windowed_loss: 0.10780296614429674\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2208654873684796e-05], [1.2851215656510312e-05]]\n",
      "Losses: [0.04712211 0.11031837 0.02557366]\n",
      "Epoch 250, loss: 0.061004713526071515, windowed_loss: 0.08548674139565599\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.2208654873684796e-05], [1.2208654873684796e-05]]\n",
      "Losses: [0.04370935 0.05402351 0.103915  ]\n",
      "Epoch 251, loss: 0.06721595644393442, windowed_loss: 0.07935173478059636\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2851215656510312e-05], [1.1598222130000555e-05], [1.2208654873684796e-05]]\n",
      "Losses: [0.032024   0.09448918 0.10359694]\n",
      "Epoch 252, loss: 0.07670337295532227, windowed_loss: 0.06830801430844274\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1598222130000555e-05], [1.2208654873684796e-05]]\n",
      "Losses: [0.06783312 0.0460673  0.11257983]\n",
      "Epoch 253, loss: 0.07549341376622519, windowed_loss: 0.07313758105516062\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1598222130000555e-05], [1.2208654873684796e-05]]\n",
      "Losses: [0.03999291 0.05298171 0.12894128]\n",
      "Epoch 254, loss: 0.07397196490761426, windowed_loss: 0.07538958387638724\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1598222130000555e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.07427429 0.1151346  0.17023496]\n",
      "Epoch 255, loss: 0.11988128248850505, windowed_loss: 0.08978222038744817\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1598222130000555e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.03537345 0.08668545 0.06470522]\n",
      "Epoch 256, loss: 0.06225470900933744, windowed_loss: 0.08536931880181892\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1598222130000555e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.01922009 0.03405087 0.10481704]\n",
      "Epoch 257, loss: 0.052696003278096516, windowed_loss: 0.07827733159197967\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2208654873684796e-05], [1.1018311023500527e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.04141683 0.03981653 0.09726234]\n",
      "Epoch 258, loss: 0.05949856618602195, windowed_loss: 0.05814975949115197\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.1018311023500527e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.11377737 0.06504418 0.14551133]\n",
      "Epoch 259, loss: 0.1081109587351481, windowed_loss: 0.07343517606642219\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.1018311023500527e-05], [1.1598222130000555e-05]]\n",
      "Losses: [0.08509375 0.08718466 0.09727743]\n",
      "Epoch 260, loss: 0.08985194719460116, windowed_loss: 0.08582049070525706\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.1524724  0.09994788 0.2545116 ]\n",
      "Epoch 261, loss: 0.16897729301452635, windowed_loss: 0.12231339964809186\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.08035913 0.05499909 0.26748369]\n",
      "Epoch 262, loss: 0.1342806386087605, windowed_loss: 0.13103662627262933\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.04334863 0.0413066  0.13926261]\n",
      "Epoch 263, loss: 0.07463928318023681, windowed_loss: 0.12596573826784122\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.1105543  0.06723241 0.10242961]\n",
      "Epoch 264, loss: 0.09340543775673371, windowed_loss: 0.10077511984857701\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.0435523  0.02338673 0.06544537]\n",
      "Epoch 265, loss: 0.04412813495618149, windowed_loss: 0.07072428529771733\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1598222130000555e-05], [1.04673954723255e-05], [1.1018311023500527e-05]]\n",
      "Losses: [0.04066286 0.03797877 0.06085549]\n",
      "Epoch 266, loss: 0.046499040603637694, windowed_loss: 0.06134420443885096\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1018311023500527e-05], [9.944025698709225e-06], [1.1018311023500527e-05]]\n",
      "Losses: [0.07318472 0.10250218 0.14466208]\n",
      "Epoch 267, loss: 0.10678299268086751, windowed_loss: 0.06580338941356223\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1018311023500527e-05], [9.944025698709225e-06], [1.1018311023500527e-05]]\n",
      "Losses: [0.08246435 0.03828743 0.11549154]\n",
      "Epoch 268, loss: 0.07874777285257976, windowed_loss: 0.07734326871236165\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1018311023500527e-05], [9.944025698709225e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.14203662 0.09029552 0.31252699]\n",
      "Epoch 269, loss: 0.1816197094917297, windowed_loss: 0.12238349167505898\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1018311023500527e-05], [9.944025698709225e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.10168559 0.08023318 0.16564012]\n",
      "Epoch 270, loss: 0.1158529658317566, windowed_loss: 0.12540681605868867\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1018311023500527e-05], [9.944025698709225e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.06856381 0.09293173 0.05226468]\n",
      "Epoch 271, loss: 0.0712534068979736, windowed_loss: 0.12290869407381998\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.944025698709225e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.10658685 0.08772111 0.14654362]\n",
      "Epoch 272, loss: 0.11361719021895926, windowed_loss: 0.10024118764956315\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.944025698709225e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.05007188 0.05946649 0.13215709]\n",
      "Epoch 273, loss: 0.08056515367474741, windowed_loss: 0.08847858359722677\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.04218323 0.10314557 0.06993221]\n",
      "Epoch 274, loss: 0.07175366945534825, windowed_loss: 0.08864533778301831\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.05551719 0.03212613 0.04680187]\n",
      "Epoch 275, loss: 0.04481506299972534, windowed_loss: 0.065711295376607\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.05150693 0.09071714 0.09133428]\n",
      "Epoch 276, loss: 0.07785278247542171, windowed_loss: 0.06480717164349843\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [1.04673954723255e-05]]\n",
      "Losses: [0.04206561 0.04184676 0.05614083]\n",
      "Epoch 277, loss: 0.046684401512146, windowed_loss: 0.056450748995764355\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.02242353 0.10257033 0.10484569]\n",
      "Epoch 278, loss: 0.07661318492316053, windowed_loss: 0.06705012297024275\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.04673954723255e-05], [9.446824413773763e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.0493618  0.03680818 0.07236014]\n",
      "Epoch 279, loss: 0.05284337330375171, windowed_loss: 0.05871365324635275\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.944025698709225e-06], [8.974483193085074e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.09344135 0.09285583 0.19120565]\n",
      "Epoch 280, loss: 0.1258342760403951, windowed_loss: 0.08509694475576912\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.944025698709225e-06], [8.974483193085074e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.0751634  0.03979535 0.13193841]\n",
      "Epoch 281, loss: 0.08229905589421589, windowed_loss: 0.08699223507945424\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.944025698709225e-06], [8.974483193085074e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.08324621 0.04929802 0.10745486]\n",
      "Epoch 282, loss: 0.07999969933087248, windowed_loss: 0.09604434375516115\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.944025698709225e-06], [8.974483193085074e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.10185907 0.01820975 0.14507901]\n",
      "Epoch 283, loss: 0.08838260873158772, windowed_loss: 0.08356045465222535\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.944025698709225e-06], [8.974483193085074e-06], [9.944025698709225e-06]]\n",
      "Losses: [0.04056137 0.06321051 0.11211148]\n",
      "Epoch 284, loss: 0.07196111755677496, windowed_loss: 0.08011447520641173\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.10232535 0.08194022 0.16145698]\n",
      "Epoch 285, loss: 0.11524084774653116, windowed_loss: 0.09186152467829795\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.04196937 0.19183473 0.01642568]\n",
      "Epoch 286, loss: 0.0834099258604139, windowed_loss: 0.09020396372124001\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.06343088 0.08790284 0.08387055]\n",
      "Epoch 287, loss: 0.07840142387579464, windowed_loss: 0.09235073249424657\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.07121986 0.08362233 0.10280089]\n",
      "Epoch 288, loss: 0.08588102569401702, windowed_loss: 0.08256412514340851\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.06597028 0.10191553 0.0847573 ]\n",
      "Epoch 289, loss: 0.0842143665834603, windowed_loss: 0.08283227205109066\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.446824413773763e-06], [8.52575903343082e-06], [9.446824413773763e-06]]\n",
      "Losses: [0.04841206 0.03812258 0.06067498]\n",
      "Epoch 290, loss: 0.04906987269719442, windowed_loss: 0.07305508832489059\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.974483193085074e-06], [8.52575903343082e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.10541565 0.03779154 0.2041307 ]\n",
      "Epoch 291, loss: 0.1157792985797645, windowed_loss: 0.08302117928680641\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.974483193085074e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.11134501 0.08185173 0.09698009]\n",
      "Epoch 292, loss: 0.09672560951402111, windowed_loss: 0.08719159359699334\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.974483193085074e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.0986797  0.11348846 0.13711979]\n",
      "Epoch 293, loss: 0.11642931694965286, windowed_loss: 0.10964474168114617\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.974483193085074e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.13401396 0.07331979 0.06823787]\n",
      "Epoch 294, loss: 0.09185720570882161, windowed_loss: 0.10167071072416518\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.974483193085074e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.02806024 0.08665919 0.09548424]\n",
      "Epoch 295, loss: 0.07006788874914748, windowed_loss: 0.09278480380254066\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.08944278 0.05762326 0.05233058]\n",
      "Epoch 296, loss: 0.06646554216832101, windowed_loss: 0.07613021220876337\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [8.09947108175928e-06], [8.974483193085074e-06]]\n",
      "Losses: [0.0241254  0.0285231  0.01097442]\n",
      "Epoch 297, loss: 0.021207640012105306, windowed_loss: 0.052580356976524606\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.09923527 0.04892972 0.11780692]\n",
      "Epoch 298, loss: 0.08865730461472261, windowed_loss: 0.05877682893171631\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.09321663 0.06237824 0.19544873]\n",
      "Epoch 299, loss: 0.1170145336786906, windowed_loss: 0.07562649276850618\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.07391186 0.06213651 0.06871909]\n",
      "Epoch 300, loss: 0.06825582075119019, windowed_loss: 0.09130921968153445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.52575903343082e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.12100764 0.13829679 0.20688226]\n",
      "Epoch 301, loss: 0.1553955626487732, windowed_loss: 0.11355530569288465\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.14589938 0.05398175 0.19866021]\n",
      "Epoch 302, loss: 0.13284711496943066, windowed_loss: 0.11883283278979802\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.694497527671315e-06], [8.52575903343082e-06]]\n",
      "Losses: [0.0639788  0.0488259  0.08572274]\n",
      "Epoch 303, loss: 0.06617581374500303, windowed_loss: 0.11813949712106897\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.309772651287749e-06], [8.09947108175928e-06]]\n",
      "Losses: [0.0405821  0.0558265  0.11952206]\n",
      "Epoch 304, loss: 0.07197688420613607, windowed_loss: 0.09033327097352324\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.309772651287749e-06], [8.09947108175928e-06]]\n",
      "Losses: [0.07701695 0.09206262 0.13421689]\n",
      "Epoch 305, loss: 0.10109882236880785, windowed_loss: 0.07975050677331565\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.309772651287749e-06], [8.09947108175928e-06]]\n",
      "Losses: [0.05811892 0.09620446 0.07265018]\n",
      "Epoch 306, loss: 0.07565785425857614, windowed_loss: 0.08291118694450668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.309772651287749e-06], [8.09947108175928e-06]]\n",
      "Losses: [0.04265405 0.05167134 0.06080436]\n",
      "Epoch 307, loss: 0.051709919192429454, windowed_loss: 0.0761555319399378\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.09947108175928e-06], [7.309772651287749e-06], [8.09947108175928e-06]]\n",
      "Losses: [0.05248688 0.03303293 0.12127741]\n",
      "Epoch 308, loss: 0.06893240769704183, windowed_loss: 0.06543339371601581\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.694497527671315e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.09662507 0.08005257 0.14094289]\n",
      "Epoch 309, loss: 0.10587350956598918, windowed_loss: 0.07550527881848683\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.694497527671315e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.00205145 0.0793982  0.09305705]\n",
      "Epoch 310, loss: 0.058168900244832435, windowed_loss: 0.07765827250262115\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.694497527671315e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.04669783 0.01606936 0.07925478]\n",
      "Epoch 311, loss: 0.04734065797593859, windowed_loss: 0.07046102259558673\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.694497527671315e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.10250499 0.06782632 0.19254486]\n",
      "Epoch 312, loss: 0.12095872529220071, windowed_loss: 0.07548942783765723\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.694497527671315e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.05788616 0.05110434 0.06171494]\n",
      "Epoch 313, loss: 0.05690181342935913, windowed_loss: 0.07506706556583281\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.309772651287749e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.07382796 0.1063043  0.16694184]\n",
      "Epoch 314, loss: 0.11569136524200441, windowed_loss: 0.09785063465452142\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.309772651287749e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.09590483 0.07916794 0.14533087]\n",
      "Epoch 315, loss: 0.10680121251082692, windowed_loss: 0.09313146372739682\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.309772651287749e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.0107758  0.06168833 0.08371814]\n",
      "Epoch 316, loss: 0.05206075794472246, windowed_loss: 0.09151777856585126\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.309772651287749e-06], [6.944284018723361e-06], [7.694497527671315e-06]]\n",
      "Losses: [0.05589379 0.03041195 0.0592241 ]\n",
      "Epoch 317, loss: 0.048509947141011554, windowed_loss: 0.06912397253218698\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.944284018723361e-06], [7.309772651287749e-06]]\n",
      "Losses: [0.11411804 0.02649578 0.12745192]\n",
      "Epoch 318, loss: 0.08935524485356995, windowed_loss: 0.06330864997976798\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [7.309772651287749e-06]]\n",
      "Losses: [0.09184289 0.06125273 0.15054346]\n",
      "Epoch 319, loss: 0.10121302895118274, windowed_loss: 0.07969274031525475\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [7.309772651287749e-06]]\n",
      "Losses: [0.08626922 0.05137233 0.06656398]\n",
      "Epoch 320, loss: 0.06806851006700902, windowed_loss: 0.08621226129058723\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [7.309772651287749e-06]]\n",
      "Losses: [0.07726946 0.14515286 0.18994662]\n",
      "Epoch 321, loss: 0.13745631431160843, windowed_loss: 0.1022459511099334\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [7.309772651287749e-06]]\n",
      "Losses: [0.0393374  0.07029623 0.09252745]\n",
      "Epoch 322, loss: 0.06738702854317032, windowed_loss: 0.09097061764059593\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [6.944284018723361e-06]]\n",
      "Losses: [0.06816332 0.05622746 0.11855302]\n",
      "Epoch 323, loss: 0.08098126763730505, windowed_loss: 0.09527487016402793\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [6.944284018723361e-06]]\n",
      "Losses: [0.05053006 0.05932566 0.06689925]\n",
      "Epoch 324, loss: 0.058918321927388516, windowed_loss: 0.06909553936928796\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.597069817787193e-06], [6.944284018723361e-06]]\n",
      "Losses: [0.13893836 0.0556867  0.13022512]\n",
      "Epoch 325, loss: 0.10828339271596477, windowed_loss: 0.08272766076021944\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.267216326897833e-06], [6.944284018723361e-06]]\n",
      "Losses: [0.0883126  0.11640303 0.05820598]\n",
      "Epoch 326, loss: 0.08764053948720296, windowed_loss: 0.08494741804351875\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.267216326897833e-06], [6.944284018723361e-06]]\n",
      "Losses: [0.08000348 0.06967092 0.11380356]\n",
      "Epoch 327, loss: 0.08782598935689778, windowed_loss: 0.0945833071866885\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.944284018723361e-06], [6.267216326897833e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.0423851  0.06497578 0.16615813]\n",
      "Epoch 328, loss: 0.0911730047861735, windowed_loss: 0.08887984454342475\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.597069817787193e-06], [6.267216326897833e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.13559351 0.10466798 0.11890224]\n",
      "Epoch 329, loss: 0.11972124176815341, windowed_loss: 0.09957341197040824\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.597069817787193e-06], [6.267216326897833e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.0184801  0.43363452 0.18914583]\n",
      "Epoch 330, loss: 0.21375348493108448, windowed_loss: 0.14154924382847048\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.597069817787193e-06], [6.267216326897833e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.03684621 0.01868565 0.09475864]\n",
      "Epoch 331, loss: 0.050096832911173506, windowed_loss: 0.1278571865368038\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.597069817787193e-06], [6.267216326897833e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.01199135 0.01733503 0.08594492]\n",
      "Epoch 332, loss: 0.03842376722999629, windowed_loss: 0.1007580283574181\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.597069817787193e-06], [5.953855510552941e-06], [6.597069817787193e-06]]\n",
      "Losses: [0.05747968 0.03952855 0.11035613]\n",
      "Epoch 333, loss: 0.06912145201365154, windowed_loss: 0.05254735071827379\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.267216326897833e-06], [5.953855510552941e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.11561862 0.07643646 0.20827731]\n",
      "Epoch 334, loss: 0.1334441318511963, windowed_loss: 0.08032978369828138\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.267216326897833e-06], [5.953855510552941e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.01180947 0.06159569 0.08424746]\n",
      "Epoch 335, loss: 0.052550872007687245, windowed_loss: 0.08503881862417838\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.267216326897833e-06], [5.953855510552941e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.04677806 0.03457687 0.13395094]\n",
      "Epoch 336, loss: 0.07176862380234368, windowed_loss: 0.08592120922040908\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.267216326897833e-06], [5.953855510552941e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.05862203 0.05151593 0.13227054]\n",
      "Epoch 337, loss: 0.08080283593717383, windowed_loss: 0.06837411058240159\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.953855510552941e-06], [5.953855510552941e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.07078292 0.01723605 0.20378219]\n",
      "Epoch 338, loss: 0.09726705611667874, windowed_loss: 0.08327950528539875\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.953855510552941e-06], [5.6561627350252934e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.04457211 0.04222133 0.11421375]\n",
      "Epoch 339, loss: 0.0670023978551229, windowed_loss: 0.08169076330299181\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.953855510552941e-06], [5.6561627350252934e-06], [6.267216326897833e-06]]\n",
      "Losses: [0.06042764 0.03952528 0.08971841]\n",
      "Epoch 340, loss: 0.06322377577045037, windowed_loss: 0.07583107658075067\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.953855510552941e-06], [5.6561627350252934e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.10041579 0.06955632 0.18443193]\n",
      "Epoch 341, loss: 0.11813467872405577, windowed_loss: 0.08278695078320968\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.953855510552941e-06], [5.6561627350252934e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.06299185 0.02502915 0.08791442]\n",
      "Epoch 342, loss: 0.058645136131791176, windowed_loss: 0.08000119687543243\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.6561627350252934e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.14938434 0.16487489 0.15051605]\n",
      "Epoch 343, loss: 0.15492509524027506, windowed_loss: 0.110568303365374\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.6561627350252934e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.03359099 0.02679812 0.14417416]\n",
      "Epoch 344, loss: 0.06818775590260824, windowed_loss: 0.09391932909155816\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.373354598274029e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.01947186 0.12447639 0.11258977]\n",
      "Epoch 345, loss: 0.08551267440428954, windowed_loss: 0.10287517518239096\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.373354598274029e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.05469096 0.05448196 0.04484706]\n",
      "Epoch 346, loss: 0.05133999463225624, windowed_loss: 0.06834680831305134\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.373354598274029e-06], [5.953855510552941e-06]]\n",
      "Losses: [0.050646   0.08074308 0.08025628]\n",
      "Epoch 347, loss: 0.07054845412572225, windowed_loss: 0.06913370772075601\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.373354598274029e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.16115097 0.07615668 0.26585131]\n",
      "Epoch 348, loss: 0.16771965482351217, windowed_loss: 0.09653603452716357\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.373354598274029e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.08589153 0.08850985 0.11858237]\n",
      "Epoch 349, loss: 0.09766125075022379, windowed_loss: 0.11197645323315274\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.6561627350252934e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.03969017 0.13665836 0.06232232]\n",
      "Epoch 350, loss: 0.07955694884819837, windowed_loss: 0.11497928480731144\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.373354598274029e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.05504408 0.0527371  0.08725767]\n",
      "Epoch 351, loss: 0.06501295045764748, windowed_loss: 0.08074371668535656\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.373354598274029e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.09179975 0.07205727 0.16006287]\n",
      "Epoch 352, loss: 0.10797329560549322, windowed_loss: 0.08418106497044636\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.373354598274029e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.0337693  0.06285826 0.12590004]\n",
      "Epoch 353, loss: 0.07417586268626936, windowed_loss: 0.08238736958313668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.373354598274029e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.0325422  0.0942514  0.07604323]\n",
      "Epoch 354, loss: 0.06761227533191383, windowed_loss: 0.08325381120789214\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.373354598274029e-06], [5.104686868360327e-06], [5.6561627350252934e-06]]\n",
      "Losses: [0.05790635 0.03999039 0.05911211]\n",
      "Epoch 355, loss: 0.05233628304799398, windowed_loss: 0.0647081403553924\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.104686868360327e-06], [4.84945252494231e-06], [5.373354598274029e-06]]\n",
      "Losses: [0.07656527 0.09315049 0.12364693]\n",
      "Epoch 356, loss: 0.09778756618499755, windowed_loss: 0.0725787081883018\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.104686868360327e-06], [4.84945252494231e-06], [5.373354598274029e-06]]\n",
      "Losses: [0.10441642 0.04863701 0.07054736]\n",
      "Epoch 357, loss: 0.07453359821755327, windowed_loss: 0.07488581581684828\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.104686868360327e-06], [4.84945252494231e-06], [5.373354598274029e-06]]\n",
      "Losses: [0.04674336 0.02430816 0.12406803]\n",
      "Epoch 358, loss: 0.06503984902597655, windowed_loss: 0.07912033780950913\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.104686868360327e-06], [4.84945252494231e-06], [5.373354598274029e-06]]\n",
      "Losses: [0.05317934 0.05187895 0.12997947]\n",
      "Epoch 359, loss: 0.07834592069397787, windowed_loss: 0.07263978931250258\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.84945252494231e-06], [4.84945252494231e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.07207984 0.06166181 0.14418607]\n",
      "Epoch 360, loss: 0.09264257277499538, windowed_loss: 0.07867611416498327\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.84945252494231e-06], [4.84945252494231e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.07070372 0.04498936 0.14920157]\n",
      "Epoch 361, loss: 0.08829821629291705, windowed_loss: 0.08642890325396345\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.84945252494231e-06], [4.6069798986951945e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.09760681 0.07402008 0.11840984]\n",
      "Epoch 362, loss: 0.0966789110867915, windowed_loss: 0.09253990005156798\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.84945252494231e-06], [4.6069798986951945e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.03371782 0.07641566 0.09433264]\n",
      "Epoch 363, loss: 0.06815537277857463, windowed_loss: 0.08437750005276107\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.84945252494231e-06], [4.6069798986951945e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.0427915  0.03742146 0.0269735 ]\n",
      "Epoch 364, loss: 0.03572881971816302, windowed_loss: 0.06685436786117639\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6069798986951945e-06], [4.6069798986951945e-06], [5.104686868360327e-06]]\n",
      "Losses: [0.04624064 0.04436078 0.07328055]\n",
      "Epoch 365, loss: 0.054627321402231845, windowed_loss: 0.05283717129965649\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6069798986951945e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.0749213  0.09352808 0.09793593]\n",
      "Epoch 366, loss: 0.0887951011657715, windowed_loss: 0.05971708076205545\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6069798986951945e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.04146509 0.04328379 0.06202631]\n",
      "Epoch 367, loss: 0.04892506106694539, windowed_loss: 0.06411582787831624\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.6069798986951945e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.06450701 0.03764853 0.06535341]\n",
      "Epoch 368, loss: 0.0558363136996227, windowed_loss: 0.06451882531077986\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3766309037604346e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.10381097 0.09956108 0.14453571]\n",
      "Epoch 369, loss: 0.1159692498629461, windowed_loss: 0.07357687487650473\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3766309037604346e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.05535722 0.05809053 0.11574602]\n",
      "Epoch 370, loss: 0.07639792166560529, windowed_loss: 0.08273449507605803\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3766309037604346e-06], [4.3766309037604346e-06], [4.84945252494231e-06]]\n",
      "Losses: [0.09243733 0.0186739  0.08912802]\n",
      "Epoch 371, loss: 0.06674641490461357, windowed_loss: 0.08637119547772165\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3766309037604346e-06], [4.3766309037604346e-06], [4.6069798986951945e-06]]\n",
      "Losses: [0.09916929 0.062294   0.11515816]\n",
      "Epoch 372, loss: 0.0922071481435874, windowed_loss: 0.07845049490460208\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3766309037604346e-06], [4.3766309037604346e-06], [4.6069798986951945e-06]]\n",
      "Losses: [0.01887795 0.0477153  0.12014318]\n",
      "Epoch 373, loss: 0.06224547719955444, windowed_loss: 0.07373301341591847\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.6069798986951945e-06]]\n",
      "Losses: [0.12786501 0.11390134 0.12148206]\n",
      "Epoch 374, loss: 0.12108280217559957, windowed_loss: 0.09184514250624713\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.6069798986951945e-06]]\n",
      "Losses: [0.07241071 0.03931785 0.06651798]\n",
      "Epoch 375, loss: 0.05941551621754964, windowed_loss: 0.08091459853090122\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.04113945 0.03367509 0.14854025]\n",
      "Epoch 376, loss: 0.0744515946706136, windowed_loss: 0.0849833043545876\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.12148767 0.06034655 0.12965288]\n",
      "Epoch 377, loss: 0.10382903242111206, windowed_loss: 0.07923204776975844\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.04906885 0.03002037 0.10866154]\n",
      "Epoch 378, loss: 0.06258358729228068, windowed_loss: 0.08028807146133544\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.10854338 0.08309049 0.09406027]\n",
      "Epoch 379, loss: 0.09523138284683229, windowed_loss: 0.087214667520075\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.157799358572413e-06], [4.157799358572413e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.03705411 0.04782733 0.13301014]\n",
      "Epoch 380, loss: 0.07263052749633789, windowed_loss: 0.07681516587848362\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.949909390643792e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.06226196 0.053263   0.10107544]\n",
      "Epoch 381, loss: 0.072200133005778, windowed_loss: 0.08002068111631605\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.949909390643792e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.05038541 0.01724668 0.02998766]\n",
      "Epoch 382, loss: 0.032539917774493485, windowed_loss: 0.05912352609220314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.949909390643792e-06], [4.3766309037604346e-06]]\n",
      "Losses: [0.0538138  0.05463856 0.06843139]\n",
      "Epoch 383, loss: 0.058961248461660766, windowed_loss: 0.05456709974731075\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.949909390643792e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.03243739 0.08673522 0.0845633 ]\n",
      "Epoch 384, loss: 0.06791197152501609, windowed_loss: 0.053137712587056775\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.949909390643792e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.05320633 0.01886898 0.06246107]\n",
      "Epoch 385, loss: 0.04484545794342387, windowed_loss: 0.05723955931003358\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.949909390643792e-06], [3.7524139211116024e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.0104122  0.04690928 0.14877429]\n",
      "Epoch 386, loss: 0.06869858996073404, windowed_loss: 0.06048533980972467\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.09829407 0.12656754 0.11531576]\n",
      "Epoch 387, loss: 0.11339245678749749, windowed_loss: 0.07564550156388512\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.0420339  0.05327299 0.03252899]\n",
      "Epoch 388, loss: 0.042611961703064284, windowed_loss: 0.07490100281709859\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.04487703 0.01299676 0.07854068]\n",
      "Epoch 389, loss: 0.04547148954892207, windowed_loss: 0.06715863601316129\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [4.157799358572413e-06]]\n",
      "Losses: [0.05546273 0.17989975 0.04841432]\n",
      "Epoch 390, loss: 0.09459226788925518, windowed_loss: 0.06089190638041384\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.04938817 0.06327365 0.07173799]\n",
      "Epoch 391, loss: 0.061466605964308994, windowed_loss: 0.06717678780082875\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7524139211116024e-06], [3.7524139211116024e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.0476283  0.03541228 0.09340934]\n",
      "Epoch 392, loss: 0.05881664127051711, windowed_loss: 0.0716251717080271\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.7524139211116024e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.06739421 0.01781136 0.04580366]\n",
      "Epoch 393, loss: 0.04366974091641331, windowed_loss: 0.054650996050413146\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.564793225056022e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.10025818 0.04802887 0.16595128]\n",
      "Epoch 394, loss: 0.10474611124995555, windowed_loss: 0.06907749781229533\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.564793225056022e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.12747328 0.05869286 0.13052259]\n",
      "Epoch 395, loss: 0.10556291052717008, windowed_loss: 0.08465958756451297\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.564793225056022e-06], [3.949909390643792e-06]]\n",
      "Losses: [0.10501499 0.06929663 0.08624333]\n",
      "Epoch 396, loss: 0.08685164907094871, windowed_loss: 0.09905355694935812\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.05033639 0.11140356 0.12200177]\n",
      "Epoch 397, loss: 0.09458057085673015, windowed_loss: 0.09566504348494964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.04181722 0.04293679 0.03392322]\n",
      "Epoch 398, loss: 0.03955907948811849, windowed_loss: 0.07366376647193244\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.564793225056022e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.02461525 0.03302247 0.1848908 ]\n",
      "Epoch 399, loss: 0.08084283796946208, windowed_loss: 0.07166082943810358\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.0730151  0.06572797 0.0823846 ]\n",
      "Epoch 400, loss: 0.07370922321785905, windowed_loss: 0.06470371355847987\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.04015991 0.02874244 0.06259474]\n",
      "Epoch 401, loss: 0.043832360384220594, windowed_loss: 0.06612814052384723\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.3865535638032207e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.03942474 0.06551004 0.04265952]\n",
      "Epoch 402, loss: 0.04919810068495622, windowed_loss: 0.05557989476234529\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.2172258856130596e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.16271165 0.06736631 0.094394  ]\n",
      "Epoch 403, loss: 0.10815732099285406, windowed_loss: 0.06706259402067695\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.2172258856130596e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.03195738 0.03628878 0.06781254]\n",
      "Epoch 404, loss: 0.04535290027508834, windowed_loss: 0.0675694406509662\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.2172258856130596e-06], [3.7524139211116024e-06]]\n",
      "Losses: [0.01699429 0.05659754 0.03455354]\n",
      "Epoch 405, loss: 0.036048456616724685, windowed_loss: 0.0631862259615557\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.2172258856130596e-06], [3.564793225056022e-06]]\n",
      "Losses: [0.10728733 0.0820915  0.11849601]\n",
      "Epoch 406, loss: 0.1026249459584554, windowed_loss: 0.06134210095008947\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.3865535638032207e-06], [3.2172258856130596e-06], [3.564793225056022e-06]]\n",
      "Losses: [0.05519771 0.0185603  0.03847001]\n",
      "Epoch 407, loss: 0.03740934220328678, windowed_loss: 0.058694248259488956\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [3.0563645913324067e-06], [3.564793225056022e-06]]\n",
      "Losses: [0.08437021 0.08191557 0.08442839]\n",
      "Epoch 408, loss: 0.08357139078776042, windowed_loss: 0.07453522631650088\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [3.0563645913324067e-06], [3.564793225056022e-06]]\n",
      "Losses: [0.11397138 0.03055079 0.09599532]\n",
      "Epoch 409, loss: 0.08017249375462053, windowed_loss: 0.06705107558188923\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [3.0563645913324067e-06], [3.564793225056022e-06]]\n",
      "Losses: [0.02523459 0.05314152 0.02274967]\n",
      "Epoch 410, loss: 0.03370859038455532, windowed_loss: 0.06581749164231208\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [3.0563645913324067e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.02301381 0.06919135 0.09901015]\n",
      "Epoch 411, loss: 0.06373843722234927, windowed_loss: 0.05920650712050838\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [2.903546361765786e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.06419407 0.08410218 0.09277426]\n",
      "Epoch 412, loss: 0.08035683647823398, windowed_loss: 0.0592679546950462\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.2172258856130596e-06], [2.903546361765786e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.06124185 0.05542003 0.03298592]\n",
      "Epoch 413, loss: 0.04988259983062745, windowed_loss: 0.06465929117707024\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.06446488 0.02095026 0.05805289]\n",
      "Epoch 414, loss: 0.04782267801747294, windowed_loss: 0.05935403810877812\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.1879811  0.01779873 0.25240464]\n",
      "Epoch 415, loss: 0.15272815687782224, windowed_loss: 0.08347781157530754\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.3865535638032207e-06]]\n",
      "Losses: [0.07695375 0.13401126 0.09176786]\n",
      "Epoch 416, loss: 0.10091095876693724, windowed_loss: 0.10048726455407747\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.08844978 0.05209339 0.1141845 ]\n",
      "Epoch 417, loss: 0.08490922498703003, windowed_loss: 0.11284944687726317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.06429593 0.06362334 0.10150275]\n",
      "Epoch 418, loss: 0.07647400612662296, windowed_loss: 0.0874313966268634\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.903546361765786e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.05974684 0.04811446 0.08562589]\n",
      "Epoch 419, loss: 0.0644957291418979, windowed_loss: 0.0752929867518503\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0563645913324067e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.02649568 0.12779136 0.05888816]\n",
      "Epoch 420, loss: 0.07105839801933579, windowed_loss: 0.07067604442928554\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.07573474 0.0586638  0.05591911]\n",
      "Epoch 421, loss: 0.06343921535239669, windowed_loss: 0.06633111417121013\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.01390831 0.03700597 0.02853859]\n",
      "Epoch 422, loss: 0.02648428701605889, windowed_loss: 0.05366063346259713\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.14009734 0.10934682 0.1500715 ]\n",
      "Epoch 423, loss: 0.13317188755671183, windowed_loss: 0.0743651299750558\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.07698352 0.04127496 0.07609339]\n",
      "Epoch 424, loss: 0.0647839542373596, windowed_loss: 0.07481337627004343\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.7583690436774965e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.06291745 0.04994123 0.05584769]\n",
      "Epoch 425, loss: 0.05623545837402344, windowed_loss: 0.08473043338936496\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.6204505914936218e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.05856657 0.10824251 0.07665595]\n",
      "Epoch 426, loss: 0.08115501091650668, windowed_loss: 0.06739147450929657\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.6204505914936218e-06], [3.2172258856130596e-06]]\n",
      "Losses: [0.03486397 0.03557114 0.06372116]\n",
      "Epoch 427, loss: 0.04471875383763132, windowed_loss: 0.060703074376053816\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.6204505914936218e-06], [3.0563645913324067e-06]]\n",
      "Losses: [0.02969227 0.06477255 0.08796283]\n",
      "Epoch 428, loss: 0.060809219227310474, windowed_loss: 0.06222766132714949\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.903546361765786e-06], [2.6204505914936218e-06], [3.0563645913324067e-06]]\n",
      "Losses: [0.06120302 0.03182261 0.1224155 ]\n",
      "Epoch 429, loss: 0.07181371317438547, windowed_loss: 0.059113895413109095\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.6204505914936218e-06], [3.0563645913324067e-06]]\n",
      "Losses: [0.08090528 0.04804285 0.12712941]\n",
      "Epoch 430, loss: 0.08535917679787959, windowed_loss: 0.07266070306652517\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.4894280619189404e-06], [3.0563645913324067e-06]]\n",
      "Losses: [0.07039588 0.0671089  0.07733734]\n",
      "Epoch 431, loss: 0.07161403783162434, windowed_loss: 0.07626230926796314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.4894280619189404e-06], [2.903546361765786e-06]]\n",
      "Losses: [0.07487937 0.02262227 0.07995502]\n",
      "Epoch 432, loss: 0.05915221713838123, windowed_loss: 0.07204181058929505\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.4894280619189404e-06], [2.903546361765786e-06]]\n",
      "Losses: [0.07334084 0.07011331 0.09052742]\n",
      "Epoch 433, loss: 0.07799385512918333, windowed_loss: 0.0695867033663963\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.4894280619189404e-06], [2.903546361765786e-06]]\n",
      "Losses: [0.10369931 0.09411488 0.1605258 ]\n",
      "Epoch 434, loss: 0.11944666155067407, windowed_loss: 0.08553091127274622\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7583690436774965e-06], [2.4894280619189404e-06], [2.903546361765786e-06]]\n",
      "Losses: [0.01570143 0.03160059 0.09475917]\n",
      "Epoch 435, loss: 0.04735373017305363, windowed_loss: 0.08159808228430368\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6204505914936218e-06], [2.3649566588229932e-06], [2.7583690436774965e-06]]\n",
      "Losses: [0.11185189 0.11843496 0.3066396 ]\n",
      "Epoch 436, loss: 0.1789754810333252, windowed_loss: 0.11525862425235096\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6204505914936218e-06], [2.3649566588229932e-06], [2.7583690436774965e-06]]\n",
      "Losses: [0.04747924 0.05716535 0.07043295]\n",
      "Epoch 437, loss: 0.05835918083777011, windowed_loss: 0.09489613068138297\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6204505914936218e-06], [2.3649566588229932e-06], [2.7583690436774965e-06]]\n",
      "Losses: [0.04972793 0.09173354 0.10503057]\n",
      "Epoch 438, loss: 0.08216401402155558, windowed_loss: 0.10649955863088363\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6204505914936218e-06], [2.3649566588229932e-06], [2.7583690436774965e-06]]\n",
      "Losses: [0.115942   0.08045933 0.1177739 ]\n",
      "Epoch 439, loss: 0.10472507905960082, windowed_loss: 0.08174942463964217\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.6204505914936218e-06], [2.3649566588229932e-06], [2.7583690436774965e-06]]\n",
      "Losses: [0.04188292 0.03787133 0.0446618 ]\n",
      "Epoch 440, loss: 0.04147201697031657, windowed_loss: 0.07612037001715767\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.4894280619189404e-06], [2.3649566588229932e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.04825951 0.05664642 0.06455934]\n",
      "Epoch 441, loss: 0.056488424917818636, windowed_loss: 0.06756184031591202\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.4894280619189404e-06], [2.3649566588229932e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.02884756 0.05535008 0.11643059]\n",
      "Epoch 442, loss: 0.06687607860565185, windowed_loss: 0.05494550683126235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.4894280619189404e-06], [2.3649566588229932e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.04654145 0.03652774 0.06699771]\n",
      "Epoch 443, loss: 0.050022298682906585, windowed_loss: 0.05779560073545903\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.4894280619189404e-06], [2.2467088258818436e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.08227314 0.06229779 0.15017229]\n",
      "Epoch 444, loss: 0.09824773772557577, windowed_loss: 0.07171537167137808\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.2467088258818436e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.09539051 0.11327265 0.120759  ]\n",
      "Epoch 445, loss: 0.10980738443617989, windowed_loss: 0.08602580694822075\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.2467088258818436e-06], [2.6204505914936218e-06]]\n",
      "Losses: [0.02213621 0.04074372 0.02515243]\n",
      "Epoch 446, loss: 0.029344118902163013, windowed_loss: 0.07913308035463955\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.2467088258818436e-06], [2.4894280619189404e-06]]\n",
      "Losses: [0.11353522 0.06732353 0.07525915]\n",
      "Epoch 447, loss: 0.08537263510302058, windowed_loss: 0.0748413794804545\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.2467088258818436e-06], [2.4894280619189404e-06]]\n",
      "Losses: [0.06665014 0.05113635 0.13848975]\n",
      "Epoch 448, loss: 0.08542541455392698, windowed_loss: 0.06671405618637019\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.2467088258818436e-06], [2.4894280619189404e-06]]\n",
      "Losses: [0.01510651 0.02409653 0.03149112]\n",
      "Epoch 449, loss: 0.02356472120706336, windowed_loss: 0.06478759028800364\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.1343733845877514e-06], [2.4894280619189404e-06]]\n",
      "Losses: [0.04898673 0.03882525 0.12139467]\n",
      "Epoch 450, loss: 0.0697355499267578, windowed_loss: 0.05957522856258272\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3649566588229932e-06], [2.1343733845877514e-06], [2.4894280619189404e-06]]\n",
      "Losses: [0.00510686 0.04179321 0.0719902 ]\n",
      "Epoch 451, loss: 0.03963008944193522, windowed_loss: 0.044310120191918795\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.1343733845877514e-06], [2.3649566588229932e-06]]\n",
      "Losses: [0.10240669 0.09413273 0.08563121]\n",
      "Epoch 452, loss: 0.09405687522888184, windowed_loss: 0.06780750486585829\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.1343733845877514e-06], [2.3649566588229932e-06]]\n",
      "Losses: [0.03482541 0.02945196 0.06648787]\n",
      "Epoch 453, loss: 0.04358841390233878, windowed_loss: 0.059091792857718616\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.1343733845877514e-06], [2.3649566588229932e-06]]\n",
      "Losses: [0.01225662 0.0257638  0.06861224]\n",
      "Epoch 454, loss: 0.0355442204153689, windowed_loss: 0.05772983651552984\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.027654715358364e-06], [2.3649566588229932e-06]]\n",
      "Losses: [0.01326134 0.03460081 0.12376918]\n",
      "Epoch 455, loss: 0.05721044301986694, windowed_loss: 0.0454476924458582\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.027654715358364e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.12615309 0.11374778 0.13107766]\n",
      "Epoch 456, loss: 0.12365950786358688, windowed_loss: 0.07213805709960758\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.2467088258818436e-06], [2.027654715358364e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.09013587 0.09994894 0.14616164]\n",
      "Epoch 457, loss: 0.11208214737484894, windowed_loss: 0.09765069941943426\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1343733845877514e-06], [2.027654715358364e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.09064202 0.11458319 0.08784262]\n",
      "Epoch 458, loss: 0.09768927607989536, windowed_loss: 0.11114364377277706\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1343733845877514e-06], [2.027654715358364e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.09915614 0.04840549 0.07776389]\n",
      "Epoch 459, loss: 0.07510850818920008, windowed_loss: 0.09495997721464812\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1343733845877514e-06], [1.9262719795904457e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.05929458 0.04927524 0.06108784]\n",
      "Epoch 460, loss: 0.05655255199595787, windowed_loss: 0.0764501120883511\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1343733845877514e-06], [1.9262719795904457e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.11051055 0.11990071 0.10903763]\n",
      "Epoch 461, loss: 0.11314962892908213, windowed_loss: 0.08160356303808003\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1343733845877514e-06], [1.9262719795904457e-06], [2.2467088258818436e-06]]\n",
      "Losses: [0.01248594 0.01892626 0.02556342]\n",
      "Epoch 462, loss: 0.018991869297053123, windowed_loss: 0.06289801674069771\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.027654715358364e-06], [1.9262719795904457e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.03675624 0.2629884  0.0790601 ]\n",
      "Epoch 463, loss: 0.126268248240153, windowed_loss: 0.08613658215542941\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.027654715358364e-06], [1.9262719795904457e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.06736506 0.07708087 0.03241544]\n",
      "Epoch 464, loss: 0.05895379061998932, windowed_loss: 0.06807130271906515\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.027654715358364e-06], [1.9262719795904457e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.04026653 0.07427493 0.08962062]\n",
      "Epoch 465, loss: 0.0680540253021913, windowed_loss: 0.08442535472077788\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.027654715358364e-06], [1.8299583806109232e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.08157766 0.09446763 0.08592326]\n",
      "Epoch 466, loss: 0.08732284895579019, windowed_loss: 0.0714435549593236\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.11786678 0.05370547 0.06544387]\n",
      "Epoch 467, loss: 0.0790053742726644, windowed_loss: 0.07812741617688196\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.05882606 0.09069799 0.04214332]\n",
      "Epoch 468, loss: 0.0638891210855447, windowed_loss: 0.07673911477133309\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.1343733845877514e-06]]\n",
      "Losses: [0.04893926 0.03402317 0.07588629]\n",
      "Epoch 469, loss: 0.05294957478841145, windowed_loss: 0.06528135671554018\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.09955539 0.02249781 0.12901768]\n",
      "Epoch 470, loss: 0.083690293438078, windowed_loss: 0.06684299643734472\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.02474525 0.01788568 0.08919614]\n",
      "Epoch 471, loss: 0.043942354996999104, windowed_loss: 0.06019407440782953\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.06403269 0.07420559 0.15215412]\n",
      "Epoch 472, loss: 0.09679746388911246, windowed_loss: 0.07481003744139653\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9262719795904457e-06], [1.8299583806109232e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.04230048 0.05343227 0.1493556 ]\n",
      "Epoch 473, loss: 0.08169611771901449, windowed_loss: 0.07414531220170868\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8299583806109232e-06], [1.738460461580377e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.09156752 0.11532596 0.17220546]\n",
      "Epoch 474, loss: 0.12636631224528852, windowed_loss: 0.10161996461780516\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8299583806109232e-06], [1.738460461580377e-06], [2.027654715358364e-06]]\n",
      "Losses: [0.06899891 0.07932327 0.06319403]\n",
      "Epoch 475, loss: 0.07050540276822362, windowed_loss: 0.09285594424417554\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8299583806109232e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.08541437 0.12602311 0.16592696]\n",
      "Epoch 476, loss: 0.12578814907239608, windowed_loss: 0.10755328802863606\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8299583806109232e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.08957023 0.0535613  0.12627255]\n",
      "Epoch 477, loss: 0.08980136006851554, windowed_loss: 0.0953649706363784\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.11542905 0.04619727 0.11136024]\n",
      "Epoch 478, loss: 0.09099551989543254, windowed_loss: 0.10219500967878138\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.09279227 0.03607646 0.05421461]\n",
      "Epoch 479, loss: 0.06102777976709441, windowed_loss: 0.0806082199103475\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.02252325 0.02705136 0.04637263]\n",
      "Epoch 480, loss: 0.03198241502663734, windowed_loss: 0.06133523822972143\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.738460461580377e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.0873219  0.05187167 0.04767666]\n",
      "Epoch 481, loss: 0.06229007538748966, windowed_loss: 0.05176675672707381\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.651537438501358e-06], [1.9262719795904457e-06]]\n",
      "Losses: [0.07360967 0.07837275 0.11041258]\n",
      "Epoch 482, loss: 0.08746500221888225, windowed_loss: 0.06057916421100309\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.08626015 0.0700135  0.1321684 ]\n",
      "Epoch 483, loss: 0.09614734888076783, windowed_loss: 0.08196747549571325\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.738460461580377e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.02048272 0.10139918 0.11182697]\n",
      "Epoch 484, loss: 0.07790295728047689, windowed_loss: 0.0871717694600423\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.651537438501358e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.19783292 0.08504445 0.22237129]\n",
      "Epoch 485, loss: 0.16841621883089095, windowed_loss: 0.1141555083307119\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.651537438501358e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.10181286 0.04997843 0.06907228]\n",
      "Epoch 486, loss: 0.07362118848164877, windowed_loss: 0.1066467881976722\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.651537438501358e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.02743453 0.02596666 0.04574072]\n",
      "Epoch 487, loss: 0.03304730090431101, windowed_loss: 0.09169490273895024\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.651537438501358e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.07626429 0.08578357 0.13788879]\n",
      "Epoch 488, loss: 0.09997888461860244, windowed_loss: 0.06888245800152074\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.651537438501358e-06], [1.651537438501358e-06], [1.8299583806109232e-06]]\n",
      "Losses: [0.11181483 0.04988901 0.11485597]\n",
      "Epoch 489, loss: 0.09218660687795066, windowed_loss: 0.07507093080028804\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5689605665762901e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.15734358 0.09802702 0.15204221]\n",
      "Epoch 490, loss: 0.13580427252617214, windowed_loss: 0.10932325467424175\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5689605665762901e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.05734945 0.18600992 0.03575526]\n",
      "Epoch 491, loss: 0.09303820889714405, windowed_loss: 0.10700969610042228\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5689605665762901e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.05993602 0.03248864 0.02547039]\n",
      "Epoch 492, loss: 0.0392983486911975, windowed_loss: 0.0893802767048379\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.5689605665762901e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.09713125 0.1108853  0.12546259]\n",
      "Epoch 493, loss: 0.11115971341002522, windowed_loss: 0.08116542366612227\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.11108471 0.10995466 0.06294069]\n",
      "Epoch 494, loss: 0.09466002003351848, windowed_loss: 0.08170602737824706\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.5689605665762901e-06], [1.738460461580377e-06]]\n",
      "Losses: [0.04582886 0.04625033 0.06440997]\n",
      "Epoch 495, loss: 0.05216305368967509, windowed_loss: 0.0859942623777396\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.4905125382474756e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.10807316 0.05461145 0.14889068]\n",
      "Epoch 496, loss: 0.10385842998583633, windowed_loss: 0.08356050123634329\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.4905125382474756e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.09173163 0.05586915 0.11594841]\n",
      "Epoch 497, loss: 0.08784972944495355, windowed_loss: 0.08129040437348832\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.4905125382474756e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.01281811 0.00897005 0.05797677]\n",
      "Epoch 498, loss: 0.026588308175404866, windowed_loss: 0.07276548920206492\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4905125382474756e-06], [1.4905125382474756e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.04130319 0.03100651 0.04453228]\n",
      "Epoch 499, loss: 0.03894732659121594, windowed_loss: 0.051128454737191444\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.4159869113351018e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.13751871 0.15083005 0.22017687]\n",
      "Epoch 500, loss: 0.1695085430529036, windowed_loss: 0.0783480592731748\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.4159869113351018e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.05075925 0.03889161 0.04116069]\n",
      "Epoch 501, loss: 0.04360385122662317, windowed_loss: 0.08401990695691425\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.4159869113351018e-06], [1.651537438501358e-06]]\n",
      "Losses: [0.06138656 0.03378136 0.08145998]\n",
      "Epoch 502, loss: 0.058875967979431156, windowed_loss: 0.09066278741965265\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.4159869113351018e-06], [1.5689605665762901e-06]]\n",
      "Losses: [0.03889103 0.0620382  0.08331671]\n",
      "Epoch 503, loss: 0.061415311813354495, windowed_loss: 0.05463171033980294\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.4159869113351018e-06], [1.5689605665762901e-06]]\n",
      "Losses: [0.06575125 0.07910825 0.1215745 ]\n",
      "Epoch 504, loss: 0.08881133352826258, windowed_loss: 0.06970087110701607\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4159869113351018e-06], [1.3451875657683467e-06], [1.5689605665762901e-06]]\n",
      "Losses: [0.02692107 0.08124725 0.07388613]\n",
      "Epoch 505, loss: 0.060684817949930824, windowed_loss: 0.07030382109718263\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.5689605665762901e-06]]\n",
      "Losses: [0.07075425 0.06542415 0.15035375]\n",
      "Epoch 506, loss: 0.09551071833990858, windowed_loss: 0.081668956606034\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.4905125382474756e-06]]\n",
      "Losses: [0.12517306 0.10510825 0.16792603]\n",
      "Epoch 507, loss: 0.13273578278223674, windowed_loss: 0.09631043969069204\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.4905125382474756e-06]]\n",
      "Losses: [0.06985899 0.08206178 0.10755087]\n",
      "Epoch 508, loss: 0.08649054447809855, windowed_loss: 0.10491234853341463\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.4905125382474756e-06]]\n",
      "Losses: [0.07705895 0.07243302 0.10887494]\n",
      "Epoch 509, loss: 0.08612230190248955, windowed_loss: 0.10178287638760829\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.4905125382474756e-06]]\n",
      "Losses: [0.05100524 0.08952868 0.16769998]\n",
      "Epoch 510, loss: 0.10274463501002096, windowed_loss: 0.09178582713020302\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3451875657683467e-06], [1.3451875657683467e-06], [1.4905125382474756e-06]]\n",
      "Losses: [0.02980587 0.06048007 0.12172417]\n",
      "Epoch 511, loss: 0.07067003915846626, windowed_loss: 0.08651232535699226\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.3451875657683467e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.09635836 0.04913592 0.16536547]\n",
      "Epoch 512, loss: 0.10361991871494251, windowed_loss: 0.09234486429447658\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.3451875657683467e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.03546613 0.04547982 0.0555587 ]\n",
      "Epoch 513, loss: 0.04550155147780196, windowed_loss: 0.07326383645040359\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.2779281874799292e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.06027651 0.0754154  0.10677674]\n",
      "Epoch 514, loss: 0.08082288396143483, windowed_loss: 0.0766481180513931\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.2779281874799292e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.04154228 0.01369634 0.05310446]\n",
      "Epoch 515, loss: 0.03611436046276717, windowed_loss: 0.05414626530066799\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.2779281874799292e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.08342406 0.0282179  0.12897536]\n",
      "Epoch 516, loss: 0.08020577478408814, windowed_loss: 0.06571433973609671\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2779281874799292e-06], [1.2779281874799292e-06], [1.4159869113351018e-06]]\n",
      "Losses: [0.04020618 0.02713999 0.03575099]\n",
      "Epoch 517, loss: 0.03436571753813413, windowed_loss: 0.05022861759499648\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2779281874799292e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.07128223 0.37144165 0.06795928]\n",
      "Epoch 518, loss: 0.17022772176152637, windowed_loss: 0.09493307136124955\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2779281874799292e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.02749507 0.04235742 0.1323883 ]\n",
      "Epoch 519, loss: 0.06741359754100223, windowed_loss: 0.09066901228022091\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.07103259 0.12979591 0.09796492]\n",
      "Epoch 520, loss: 0.09959780915578205, windowed_loss: 0.11241304281943688\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.08041319 0.06599895 0.09068048]\n",
      "Epoch 521, loss: 0.07903087258577825, windowed_loss: 0.0820140930941875\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.07700776 0.07046207 0.07844973]\n",
      "Epoch 522, loss: 0.07530652072375398, windowed_loss: 0.08464506748843809\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2140317781059327e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.02387807 0.03892887 0.06961437]\n",
      "Epoch 523, loss: 0.04414043787899311, windowed_loss: 0.06615927706284178\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.153330189200636e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.06715036 0.06871942 0.23534156]\n",
      "Epoch 524, loss: 0.12373711382777354, windowed_loss: 0.08106135747684022\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.153330189200636e-06], [1.2140317781059327e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.12413899 0.02028748 0.14653628]\n",
      "Epoch 525, loss: 0.09698758271828284, windowed_loss: 0.08828837814168317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.153330189200636e-06], [1.153330189200636e-06], [1.3451875657683467e-06]]\n",
      "Losses: [0.04186726 0.08040613 0.05358091]\n",
      "Epoch 526, loss: 0.058618099053700766, windowed_loss: 0.09311426519991904\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.153330189200636e-06], [1.153330189200636e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.07544094 0.12279091 0.13907277]\n",
      "Epoch 527, loss: 0.11243487375930857, windowed_loss: 0.08934685184376406\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.153330189200636e-06], [1.153330189200636e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.01839711 0.02459346 0.09338166]\n",
      "Epoch 528, loss: 0.04545741138572922, windowed_loss: 0.07217012806624619\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.153330189200636e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.05124045 0.03384729 0.08040863]\n",
      "Epoch 529, loss: 0.0551654585202535, windowed_loss: 0.07101924788843043\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.05000964 0.07919915 0.09946284]\n",
      "Epoch 530, loss: 0.07622387790679931, windowed_loss: 0.058948915937594014\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.07160511 0.07387841 0.11451571]\n",
      "Epoch 531, loss: 0.08666640933354697, windowed_loss: 0.07268524858686659\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.06459149 0.07203082 0.09805378]\n",
      "Epoch 532, loss: 0.07822536211771892, windowed_loss: 0.08037188311935506\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2779281874799292e-06]]\n",
      "Losses: [0.06289469 0.22423253 0.0453333 ]\n",
      "Epoch 533, loss: 0.11082017755508422, windowed_loss: 0.0919039830021167\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.09623776 0.0765753  0.10763813]\n",
      "Epoch 534, loss: 0.09348372865216925, windowed_loss: 0.09417642277499079\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0956636797406041e-06], [1.0956636797406041e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.05443567 0.04847111 0.14050292]\n",
      "Epoch 535, loss: 0.081136568069458, windowed_loss: 0.09514682475890383\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0408804957535738e-06], [1.0956636797406041e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.06019186 0.08386176 0.09772548]\n",
      "Epoch 536, loss: 0.08059303156917065, windowed_loss: 0.08507110943026597\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0408804957535738e-06], [1.0956636797406041e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.08428719 0.07877333 0.11854799]\n",
      "Epoch 537, loss: 0.09386950595631018, windowed_loss: 0.0851997018649796\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0408804957535738e-06], [1.0408804957535738e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.04816855 0.11620232 0.11565855]\n",
      "Epoch 538, loss: 0.09334313949268346, windowed_loss: 0.08926855900605475\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0408804957535738e-06], [1.0408804957535738e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.06585109 0.06295441 0.10493839]\n",
      "Epoch 539, loss: 0.0779146278399221, windowed_loss: 0.08837575776297191\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0408804957535738e-06], [1.0408804957535738e-06], [1.2140317781059327e-06]]\n",
      "Losses: [0.06044704 0.12163397 0.08934319]\n",
      "Epoch 540, loss: 0.09047473382949829, windowed_loss: 0.08724416705403461\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [1.0408804957535738e-06], [1.153330189200636e-06]]\n",
      "Losses: [0.07883566 0.04394245 0.09392186]\n",
      "Epoch 541, loss: 0.07223332254744881, windowed_loss: 0.08020756140562307\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [1.0408804957535738e-06], [1.153330189200636e-06]]\n",
      "Losses: [0.11059782 0.04407932 0.05895667]\n",
      "Epoch 542, loss: 0.07121127099296452, windowed_loss: 0.07797310912330387\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [9.88836470965895e-07], [1.153330189200636e-06]]\n",
      "Losses: [0.03887147 0.0781179  0.06966056]\n",
      "Epoch 543, loss: 0.062216644535561604, windowed_loss: 0.06855374602532498\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [9.88836470965895e-07], [1.153330189200636e-06]]\n",
      "Losses: [0.08974542 0.05954138 0.06197527]\n",
      "Epoch 544, loss: 0.07042069218520251, windowed_loss: 0.06794953590457621\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [9.88836470965895e-07], [1.153330189200636e-06]]\n",
      "Losses: [0.07887465 0.0902382  0.10024045]\n",
      "Epoch 545, loss: 0.08978443266792784, windowed_loss: 0.07414058979623066\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [9.88836470965895e-07], [1.153330189200636e-06]]\n",
      "Losses: [0.0561768  0.0651793  0.07980366]\n",
      "Epoch 546, loss: 0.06705325176975452, windowed_loss: 0.07575279220762829\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.88836470965895e-07], [9.88836470965895e-07], [1.0956636797406041e-06]]\n",
      "Losses: [0.03235147 0.05716513 0.08618693]\n",
      "Epoch 547, loss: 0.05856784408640974, windowed_loss: 0.07180184284136404\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.393946474176003e-07], [9.88836470965895e-07], [1.0956636797406041e-06]]\n",
      "Losses: [0.03800279 0.02519053 0.10851167]\n",
      "Epoch 548, loss: 0.05723499756064054, windowed_loss: 0.06095203113893494\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.393946474176003e-07], [9.88836470965895e-07], [1.0956636797406041e-06]]\n",
      "Losses: [0.07963405 0.13008782 0.10252151]\n",
      "Epoch 549, loss: 0.10408112610200322, windowed_loss: 0.07329465591635116\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.393946474176003e-07], [9.88836470965895e-07], [1.0956636797406041e-06]]\n",
      "Losses: [0.05152546 0.10340123 0.1317342 ]\n",
      "Epoch 550, loss: 0.09555363112504543, windowed_loss: 0.0856232515958964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.393946474176003e-07], [9.88836470965895e-07], [1.0956636797406041e-06]]\n",
      "Losses: [0.03058571 0.03686621 0.05222753]\n",
      "Epoch 551, loss: 0.03989315048885409, windowed_loss: 0.07984263590530091\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.393946474176003e-07], [9.393946474176003e-07], [1.0408804957535738e-06]]\n",
      "Losses: [0.03327541 0.04455752 0.17728257]\n",
      "Epoch 552, loss: 0.08503849919637045, windowed_loss: 0.07349509360342332\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.924249150467202e-07], [9.393946474176003e-07], [1.0408804957535738e-06]]\n",
      "Losses: [0.09002699 0.144686   0.12312493]\n",
      "Epoch 553, loss: 0.11927930641684986, windowed_loss: 0.0814036520340248\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.924249150467202e-07], [9.393946474176003e-07], [1.0408804957535738e-06]]\n",
      "Losses: [0.04289313 0.04585794 0.15126766]\n",
      "Epoch 554, loss: 0.08000624020894369, windowed_loss: 0.09477468194072135\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.924249150467202e-07], [9.393946474176003e-07], [1.0408804957535738e-06]]\n",
      "Losses: [0.05150814 0.08762358 0.07128991]\n",
      "Epoch 555, loss: 0.07014054227545558, windowed_loss: 0.08980869630041638\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.924249150467202e-07], [9.393946474176003e-07], [1.0408804957535738e-06]]\n",
      "Losses: [0.05751069 0.08158858 0.12805566]\n",
      "Epoch 556, loss: 0.08905164097526785, windowed_loss: 0.07973280781988905\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.478036692943841e-07], [8.924249150467202e-07], [9.88836470965895e-07]]\n",
      "Losses: [0.12326057 0.12046776 0.13578751]\n",
      "Epoch 557, loss: 0.12650528110180526, windowed_loss: 0.09523248811750956\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.478036692943841e-07], [8.924249150467202e-07], [9.88836470965895e-07]]\n",
      "Losses: [0.04528094 0.02214224 0.12267419]\n",
      "Epoch 558, loss: 0.06336579182662404, windowed_loss: 0.09297423796789905\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.478036692943841e-07], [8.924249150467202e-07], [9.88836470965895e-07]]\n",
      "Losses: [0.05351576 0.04708503 0.12716129]\n",
      "Epoch 559, loss: 0.07592069133122763, windowed_loss: 0.08859725475321899\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.478036692943841e-07], [8.924249150467202e-07], [9.88836470965895e-07]]\n",
      "Losses: [0.05581758 0.15746036 0.07848936]\n",
      "Epoch 560, loss: 0.09725576826310907, windowed_loss: 0.07884741714032024\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.478036692943841e-07], [8.924249150467202e-07], [9.88836470965895e-07]]\n",
      "Losses: [0.0379906  0.03733765 0.08655477]\n",
      "Epoch 561, loss: 0.05396100546251398, windowed_loss: 0.07571248835228356\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.04976135 0.03765724 0.08813698]\n",
      "Epoch 562, loss: 0.05851852255493123, windowed_loss: 0.06991176542685142\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.05283662 0.14449047 0.08036228]\n",
      "Epoch 563, loss: 0.09256312470519079, windowed_loss: 0.06834755090754534\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.06550449 0.09749795 0.07659076]\n",
      "Epoch 564, loss: 0.07986440189392213, windowed_loss: 0.07698201638468138\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.05490905 0.05981167 0.06342053]\n",
      "Epoch 565, loss: 0.05938041632224817, windowed_loss: 0.07726931430712036\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.04608142 0.04603094 0.10317147]\n",
      "Epoch 566, loss: 0.06509461085001628, windowed_loss: 0.06811314302206219\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.054134858296649e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.02758688 0.09845329 0.06807909]\n",
      "Epoch 567, loss: 0.06470642019485484, windowed_loss: 0.06306048245570643\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.651428115381816e-07], [8.478036692943841e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.03878702 0.04468595 0.01158344]\n",
      "Epoch 568, loss: 0.031685469945271806, windowed_loss: 0.053828833663380975\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.651428115381816e-07], [8.054134858296649e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.08617319 0.09608475 0.11483497]\n",
      "Epoch 569, loss: 0.0990309697786967, windowed_loss: 0.06514095330627445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.651428115381816e-07], [8.054134858296649e-07], [9.393946474176003e-07]]\n",
      "Losses: [0.10636008 0.04595163 0.09010757]\n",
      "Epoch 570, loss: 0.08080642625509975, windowed_loss: 0.07050762199302275\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.651428115381816e-07], [8.054134858296649e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.07089295 0.07954653 0.12620908]\n",
      "Epoch 571, loss: 0.09221618893788348, windowed_loss: 0.0906845283238933\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.268856709612725e-07], [8.054134858296649e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.0744747  0.03466119 0.09763914]\n",
      "Epoch 572, loss: 0.06892501280637447, windowed_loss: 0.08064920933311924\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.268856709612725e-07], [8.054134858296649e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.08101625 0.08011787 0.12395807]\n",
      "Epoch 573, loss: 0.09503073050793874, windowed_loss: 0.08539064408406556\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.268856709612725e-07], [7.651428115381816e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.10445418 0.1372742  0.10132963]\n",
      "Epoch 574, loss: 0.11435267012678312, windowed_loss: 0.09276947114703211\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.268856709612725e-07], [7.651428115381816e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.02384581 0.09577628 0.07460928]\n",
      "Epoch 575, loss: 0.06474379053415262, windowed_loss: 0.09137573038962482\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.08784393 0.06390202 0.09399633]\n",
      "Epoch 576, loss: 0.08191409476598104, windowed_loss: 0.08700351847563892\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.924249150467202e-07]]\n",
      "Losses: [0.02714482 0.04300799 0.06197879]\n",
      "Epoch 577, loss: 0.04404386585365555, windowed_loss: 0.0635672503845964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.07046974 0.0737918  0.0862275 ]\n",
      "Epoch 578, loss: 0.07682968077853909, windowed_loss: 0.06759588046605856\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.06374268 0.02564019 0.07894398]\n",
      "Epoch 579, loss: 0.056108950291931074, windowed_loss: 0.05899416564137524\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.11952241 0.08031114 0.10689905]\n",
      "Epoch 580, loss: 0.10224420114923653, windowed_loss: 0.0783942774065689\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.06863768 0.06570417 0.11974412]\n",
      "Epoch 581, loss: 0.08469532081378857, windowed_loss: 0.08101615741831873\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.905413874132088e-07], [7.651428115381816e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.04404939 0.05709802 0.09372431]\n",
      "Epoch 582, loss: 0.0649572406200544, windowed_loss: 0.08396558752769316\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.560143180425484e-07], [7.268856709612725e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.081051   0.06804166 0.07904183]\n",
      "Epoch 583, loss: 0.07604482815754597, windowed_loss: 0.07523246319712966\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.560143180425484e-07], [7.268856709612725e-07], [8.478036692943841e-07]]\n",
      "Losses: [0.03786196 0.0936699  0.02225688]\n",
      "Epoch 584, loss: 0.05126291159080041, windowed_loss: 0.06408832678946692\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.560143180425484e-07], [7.268856709612725e-07], [8.054134858296649e-07]]\n",
      "Losses: [0.05604961 0.09358421 0.07671778]\n",
      "Epoch 585, loss: 0.07545053425357591, windowed_loss: 0.0675860913339741\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.560143180425484e-07], [7.268856709612725e-07], [8.054134858296649e-07]]\n",
      "Losses: [0.10529781 0.13093784 0.09737307]\n",
      "Epoch 586, loss: 0.11120290673241878, windowed_loss: 0.0793054508589317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.560143180425484e-07], [7.268856709612725e-07], [8.054134858296649e-07]]\n",
      "Losses: [0.04305011 0.07335093 0.06688758]\n",
      "Epoch 587, loss: 0.06109620560923096, windowed_loss: 0.08258321553174187\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.232136021404209e-07], [7.268856709612725e-07], [8.054134858296649e-07]]\n",
      "Losses: [0.11327536 0.07142336 0.21237568]\n",
      "Epoch 588, loss: 0.13235813442866007, windowed_loss: 0.10155241559010326\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.232136021404209e-07], [7.268856709612725e-07], [8.054134858296649e-07]]\n",
      "Losses: [0.02594491 0.03708654 0.06315447]\n",
      "Epoch 589, loss: 0.04206197597857866, windowed_loss: 0.07850543867215656\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.232136021404209e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.04490212 0.0376459  0.0820746 ]\n",
      "Epoch 590, loss: 0.05487420675192344, windowed_loss: 0.07643143905305406\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.232136021404209e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.08623187 0.02404105 0.14025829]\n",
      "Epoch 591, loss: 0.08351040365226776, windowed_loss: 0.06014886212758996\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.232136021404209e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.06790624 0.08271279 0.12554047]\n",
      "Epoch 592, loss: 0.09205316700932177, windowed_loss: 0.07681259247117099\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.920529220333999e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.06820881 0.04614469 0.08797406]\n",
      "Epoch 593, loss: 0.06744252002947954, windowed_loss: 0.08100203023035636\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.920529220333999e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.07502111 0.00892222 0.0588816 ]\n",
      "Epoch 594, loss: 0.0476083058110841, windowed_loss: 0.06903466428329513\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.920529220333999e-07], [6.905413874132088e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.07673069 0.02431294 0.13165205]\n",
      "Epoch 595, loss: 0.07756522862116495, windowed_loss: 0.06420535148724286\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.920529220333999e-07], [6.560143180425484e-07], [7.651428115381816e-07]]\n",
      "Losses: [0.05110905 0.06026485 0.00938959]\n",
      "Epoch 596, loss: 0.04025449810257877, windowed_loss: 0.05514267751160928\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [7.268856709612725e-07]]\n",
      "Losses: [0.07147771 0.07367842 0.03574876]\n",
      "Epoch 597, loss: 0.06030163160959879, windowed_loss: 0.059373786111114164\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [7.268856709612725e-07]]\n",
      "Losses: [0.01709003 0.04673243 0.05049532]\n",
      "Epoch 598, loss: 0.038105923811594646, windowed_loss: 0.04622068450792407\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [7.268856709612725e-07]]\n",
      "Losses: [0.08229093 0.21236495 0.12502084]\n",
      "Epoch 599, loss: 0.139892238892152, windowed_loss: 0.07943326477111513\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [7.268856709612725e-07]]\n",
      "Losses: [0.04651644 0.07420429 0.11091637]\n",
      "Epoch 600, loss: 0.0772123638788859, windowed_loss: 0.08507017552754419\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [7.268856709612725e-07]]\n",
      "Losses: [0.03982581 0.06465279 0.05772787]\n",
      "Epoch 601, loss: 0.05406882102230945, windowed_loss: 0.0903911412644491\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.624502759317298e-07], [6.560143180425484e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.04156026 0.06133714 0.06887575]\n",
      "Epoch 602, loss: 0.05725771487356427, windowed_loss: 0.06284629992491987\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.343277621351433e-07], [6.232136021404209e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.06151443 0.0689208  0.10616014]\n",
      "Epoch 603, loss: 0.07886512406667073, windowed_loss: 0.06339721998751481\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.343277621351433e-07], [6.232136021404209e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.07398055 0.04872162 0.09259463]\n",
      "Epoch 604, loss: 0.07176559940973919, windowed_loss: 0.06929614611665806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.343277621351433e-07], [6.232136021404209e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.09761645 0.06436928 0.08144106]\n",
      "Epoch 605, loss: 0.0811422610171413, windowed_loss: 0.0772576614978504\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.343277621351433e-07], [6.232136021404209e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.04875157 0.06306661 0.04834143]\n",
      "Epoch 606, loss: 0.05338653836476461, windowed_loss: 0.06876479959721503\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.343277621351433e-07], [6.232136021404209e-07], [6.905413874132088e-07]]\n",
      "Losses: [0.04315828 0.05750987 0.05604326]\n",
      "Epoch 607, loss: 0.05223713338414907, windowed_loss: 0.062255310922018324\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [6.232136021404209e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.07631723 0.05236887 0.15458625]\n",
      "Epoch 608, loss: 0.0944241153931092, windowed_loss: 0.06668259571400763\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [6.232136021404209e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.06928947 0.06696976 0.12221355]\n",
      "Epoch 609, loss: 0.08615759682002351, windowed_loss: 0.07760628186576059\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [5.920529220333999e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.09582601 0.1189462  0.11539761]\n",
      "Epoch 610, loss: 0.11005660638700905, windowed_loss: 0.09687943953338059\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [5.920529220333999e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.09217942 0.53329808 0.05388109]\n",
      "Epoch 611, loss: 0.2264528613090515, windowed_loss: 0.14088902150536134\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [5.920529220333999e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.07575813 0.05732959 0.13505808]\n",
      "Epoch 612, loss: 0.08938193178176879, windowed_loss: 0.14196379982594312\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [5.920529220333999e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.051545   0.0402009  0.14576823]\n",
      "Epoch 613, loss: 0.07917137502748009, windowed_loss: 0.1316687227061001\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.076113740283861e-07], [5.920529220333999e-07], [6.560143180425484e-07]]\n",
      "Losses: [0.09511366 0.13683873 0.14089041]\n",
      "Epoch 614, loss: 0.12428093211877457, windowed_loss: 0.09761141297600782\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.920529220333999e-07], [6.232136021404209e-07]]\n",
      "Losses: [0.12087443 0.05322386 0.17385626]\n",
      "Epoch 615, loss: 0.11598485120137532, windowed_loss: 0.10647905278254333\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.920529220333999e-07], [6.232136021404209e-07]]\n",
      "Losses: [0.03906596 0.04442879 0.08833579]\n",
      "Epoch 616, loss: 0.05727684330605792, windowed_loss: 0.09918087554206927\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.624502759317298e-07], [6.232136021404209e-07]]\n",
      "Losses: [0.06538325 0.05405157 0.1662625 ]\n",
      "Epoch 617, loss: 0.09523243735293667, windowed_loss: 0.08949804395345663\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.624502759317298e-07], [6.232136021404209e-07]]\n",
      "Losses: [0.04070175 0.08300084 0.19707466]\n",
      "Epoch 618, loss: 0.10692575019366608, windowed_loss: 0.08647834361755356\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.624502759317298e-07], [6.232136021404209e-07]]\n",
      "Losses: [0.05288635 0.08563588 0.05049449]\n",
      "Epoch 619, loss: 0.06300557400277239, windowed_loss: 0.08838792051645838\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.624502759317298e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.05236777 0.01742961 0.08338483]\n",
      "Epoch 620, loss: 0.051060735899517797, windowed_loss: 0.07366402003198542\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.822308053269667e-07], [5.343277621351433e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.04596469 0.09108068 0.07738025]\n",
      "Epoch 621, loss: 0.07147520891825358, windowed_loss: 0.06184717294018125\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.581192650606184e-07], [5.343277621351433e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.04960848 0.09015019 0.04954341]\n",
      "Epoch 622, loss: 0.06310069568967851, windowed_loss: 0.06187888016914996\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.581192650606184e-07], [5.343277621351433e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.02838767 0.03941311 0.06633884]\n",
      "Epoch 623, loss: 0.044713207357220223, windowed_loss: 0.05976303732171744\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.581192650606184e-07], [5.343277621351433e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.05883784 0.02019529 0.07775678]\n",
      "Epoch 624, loss: 0.05226330265622222, windowed_loss: 0.05335906856770698\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.581192650606184e-07], [5.343277621351433e-07], [5.920529220333999e-07]]\n",
      "Losses: [0.06795237 0.02582778 0.06463276]\n",
      "Epoch 625, loss: 0.05280430348714193, windowed_loss: 0.04992693783352812\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.581192650606184e-07], [5.343277621351433e-07], [5.624502759317298e-07]]\n",
      "Losses: [0.03882015 0.05962287 0.09292635]\n",
      "Epoch 626, loss: 0.06378979137144893, windowed_loss: 0.05628579917160436\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3521330180758747e-07], [5.343277621351433e-07], [5.624502759317298e-07]]\n",
      "Losses: [0.05086536 0.02124573 0.13490503]\n",
      "Epoch 627, loss: 0.06900537300109863, windowed_loss: 0.06186648928656316\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3521330180758747e-07], [5.076113740283861e-07], [5.624502759317298e-07]]\n",
      "Losses: [0.05827451 0.03770437 0.08823397]\n",
      "Epoch 628, loss: 0.06140428304672241, windowed_loss: 0.06473314913975665\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3521330180758747e-07], [5.076113740283861e-07], [5.624502759317298e-07]]\n",
      "Losses: [0.04056615 0.08485632 0.14124697]\n",
      "Epoch 629, loss: 0.08888981533050537, windowed_loss: 0.07309982379277546\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3521330180758747e-07], [5.076113740283861e-07], [5.624502759317298e-07]]\n",
      "Losses: [0.02369899 0.04829873 0.03352186]\n",
      "Epoch 630, loss: 0.03517319307001064, windowed_loss: 0.061822430482412816\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.3521330180758747e-07], [5.076113740283861e-07], [5.343277621351433e-07]]\n",
      "Losses: [0.08228378 0.04523701 0.12882579]\n",
      "Epoch 631, loss: 0.08544886120176347, windowed_loss: 0.06983728986742649\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.1345263671720807e-07], [5.076113740283861e-07], [5.343277621351433e-07]]\n",
      "Losses: [0.09503886 0.04931162 0.09900725]\n",
      "Epoch 632, loss: 0.08111924164426056, windowed_loss: 0.06724709863867823\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.1345263671720807e-07], [4.822308053269667e-07], [5.343277621351433e-07]]\n",
      "Losses: [0.07845051 0.05802803 0.14904475]\n",
      "Epoch 633, loss: 0.09517442957560222, windowed_loss: 0.08724751080720876\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.1345263671720807e-07], [4.822308053269667e-07], [5.343277621351433e-07]]\n",
      "Losses: [0.13467939 0.13154773 0.1694421 ]\n",
      "Epoch 634, loss: 0.14522307459513348, windowed_loss: 0.10717224860499874\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.1345263671720807e-07], [4.822308053269667e-07], [5.343277621351433e-07]]\n",
      "Losses: [0.01225415 0.05514303 0.03736289]\n",
      "Epoch 635, loss: 0.034920024105822706, windowed_loss: 0.09177250942551947\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.1345263671720807e-07], [4.822308053269667e-07], [5.076113740283861e-07]]\n",
      "Losses: [0.03484948 0.04442845 0.13790893]\n",
      "Epoch 636, loss: 0.07239561945878199, windowed_loss: 0.08417957271991272\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.822308053269667e-07], [5.076113740283861e-07]]\n",
      "Losses: [0.11205433 0.07955986 0.16036397]\n",
      "Epoch 637, loss: 0.11732605368436459, windowed_loss: 0.07488056574965643\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.822308053269667e-07], [5.076113740283861e-07]]\n",
      "Losses: [0.03950344 0.03486995 0.07446442]\n",
      "Epoch 638, loss: 0.04961260255368932, windowed_loss: 0.0797780918989453\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.581192650606184e-07], [5.076113740283861e-07]]\n",
      "Losses: [0.05803136 0.04730351 0.14598325]\n",
      "Epoch 639, loss: 0.08377270590030206, windowed_loss: 0.08357045404611867\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.581192650606184e-07], [5.076113740283861e-07]]\n",
      "Losses: [0.0240139  0.00459265 0.04367021]\n",
      "Epoch 640, loss: 0.024092252315128026, windowed_loss: 0.05249252025637313\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.581192650606184e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.08994016 0.07422363 0.08894853]\n",
      "Epoch 641, loss: 0.08437077442804973, windowed_loss: 0.0640785775478266\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.9278000488134764e-07], [4.581192650606184e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.04330295 0.03691579 0.15735598]\n",
      "Epoch 642, loss: 0.07919157435277659, windowed_loss: 0.06255153369865145\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.581192650606184e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.07671264 0.07227064 0.10048592]\n",
      "Epoch 643, loss: 0.08315639790668282, windowed_loss: 0.08223958222916972\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.581192650606184e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.09285533 0.06256186 0.16705587]\n",
      "Epoch 644, loss: 0.10749101878170027, windowed_loss: 0.08994633034705322\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.581192650606184e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.05676829 0.04372608 0.11430954]\n",
      "Epoch 645, loss: 0.07160130437215169, windowed_loss: 0.08741624035351159\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.3521330180758747e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.05371902 0.0441014  0.07936132]\n",
      "Epoch 646, loss: 0.059060581684112545, windowed_loss: 0.07938430161265483\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.3521330180758747e-07], [4.822308053269667e-07]]\n",
      "Losses: [0.04578342 0.05682091 0.07801354]\n",
      "Epoch 647, loss: 0.060205959161122646, windowed_loss: 0.0636226150724623\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.3521330180758747e-07], [4.581192650606184e-07]]\n",
      "Losses: [0.0224957  0.05657709 0.0805343 ]\n",
      "Epoch 648, loss: 0.0532023655070252, windowed_loss: 0.05748963545075347\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.7314100463728023e-07], [4.3521330180758747e-07], [4.581192650606184e-07]]\n",
      "Losses: [0.04373953 0.03396521 0.09486205]\n",
      "Epoch 649, loss: 0.05752226457487525, windowed_loss: 0.056976863081007696\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.3521330180758747e-07], [4.581192650606184e-07]]\n",
      "Losses: [0.06548833 0.07720317 0.16763652]\n",
      "Epoch 650, loss: 0.10344267274481227, windowed_loss: 0.07138910094223756\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.3521330180758747e-07], [4.581192650606184e-07]]\n",
      "Losses: [0.1355426  0.02056623 0.11095795]\n",
      "Epoch 651, loss: 0.08902225832024972, windowed_loss: 0.08332906521331242\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.3521330180758747e-07], [4.581192650606184e-07]]\n",
      "Losses: [0.02778056 0.0037808  0.06213358]\n",
      "Epoch 652, loss: 0.031231645901997885, windowed_loss: 0.07456552565568662\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.1345263671720807e-07], [4.3521330180758747e-07]]\n",
      "Losses: [0.11110613 0.03900439 0.09523399]\n",
      "Epoch 653, loss: 0.08178150343273828, windowed_loss: 0.0673451358849953\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.1345263671720807e-07], [4.3521330180758747e-07]]\n",
      "Losses: [0.05373872 0.02835305 0.06388204]\n",
      "Epoch 654, loss: 0.04865793251720523, windowed_loss: 0.0538903606173138\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.544839544054162e-07], [4.1345263671720807e-07], [4.3521330180758747e-07]]\n",
      "Losses: [0.0231303  0.02668905 0.11936351]\n",
      "Epoch 655, loss: 0.05639428652837902, windowed_loss: 0.062277907492774176\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.367597566851454e-07], [4.1345263671720807e-07], [4.3521330180758747e-07]]\n",
      "Losses: [0.05924949 0.08502664 0.04218941]\n",
      "Epoch 656, loss: 0.06215518018806795, windowed_loss: 0.055735799744550736\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.367597566851454e-07], [4.1345263671720807e-07], [4.3521330180758747e-07]]\n",
      "Losses: [0.06178462 0.05031035 0.06651182]\n",
      "Epoch 657, loss: 0.05953559605280558, windowed_loss: 0.059361687589750856\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.367597566851454e-07], [4.1345263671720807e-07], [4.1345263671720807e-07]]\n",
      "Losses: [0.0857234  0.11300308 0.09857828]\n",
      "Epoch 658, loss: 0.09910158888498943, windowed_loss: 0.07359745504195432\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.367597566851454e-07], [3.9278000488134764e-07], [4.1345263671720807e-07]]\n",
      "Losses: [0.02285113 0.26068669 0.04919697]\n",
      "Epoch 659, loss: 0.1109115972308692, windowed_loss: 0.08984959405622141\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.199217688508881e-07], [3.9278000488134764e-07], [4.1345263671720807e-07]]\n",
      "Losses: [0.07166527 0.03595049 0.1432213 ]\n",
      "Epoch 660, loss: 0.08361235123598026, windowed_loss: 0.09787517911727962\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.199217688508881e-07], [3.9278000488134764e-07], [4.1345263671720807e-07]]\n",
      "Losses: [0.10859798 0.02664123 0.16813953]\n",
      "Epoch 661, loss: 0.10112624512406772, windowed_loss: 0.09855006453030572\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.199217688508881e-07], [3.9278000488134764e-07], [4.1345263671720807e-07]]\n",
      "Losses: [0.09238587 0.08779685 0.09937762]\n",
      "Epoch 662, loss: 0.09318678141755109, windowed_loss: 0.09264179259253302\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.199217688508881e-07], [3.9278000488134764e-07], [3.9278000488134764e-07]]\n",
      "Losses: [0.1075542  0.11630152 0.17566467]\n",
      "Epoch 663, loss: 0.13317346111009656, windowed_loss: 0.1091621625505718\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0392568040834367e-07], [3.9278000488134764e-07], [3.9278000488134764e-07]]\n",
      "Losses: [0.10857404 0.06537242 0.09139497]\n",
      "Epoch 664, loss: 0.08844714371363323, windowed_loss: 0.10493579541376029\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0392568040834367e-07], [3.9278000488134764e-07], [3.9278000488134764e-07]]\n",
      "Losses: [0.01914432 0.03277549 0.06255635]\n",
      "Epoch 665, loss: 0.03815871868108011, windowed_loss: 0.08659310783493664\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0392568040834367e-07], [3.7314100463728023e-07], [3.9278000488134764e-07]]\n",
      "Losses: [0.05639537 0.07473926 0.07571431]\n",
      "Epoch 666, loss: 0.06894964859656039, windowed_loss: 0.06518517033042458\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0392568040834367e-07], [3.7314100463728023e-07], [3.9278000488134764e-07]]\n",
      "Losses: [0.02140468 0.05488711 0.0840129 ]\n",
      "Epoch 667, loss: 0.05343489688320326, windowed_loss: 0.053514421386947925\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.0392568040834367e-07], [3.7314100463728023e-07], [3.7314100463728023e-07]]\n",
      "Losses: [0.08042122 0.0631569  0.17079418]\n",
      "Epoch 668, loss: 0.1047907671934789, windowed_loss: 0.07572510422441418\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.7314100463728023e-07], [3.7314100463728023e-07]]\n",
      "Losses: [0.10601256 0.09896065 0.25265289]\n",
      "Epoch 669, loss: 0.15254203462568855, windowed_loss: 0.10358923290079025\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.7314100463728023e-07], [3.7314100463728023e-07]]\n",
      "Losses: [0.05175487 0.08110508 0.06483975]\n",
      "Epoch 670, loss: 0.06589990250269571, windowed_loss: 0.1077442347739544\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.544839544054162e-07], [3.7314100463728023e-07]]\n",
      "Losses: [0.11700247 0.11259565 0.07702476]\n",
      "Epoch 671, loss: 0.10220762700281309, windowed_loss: 0.10688318804373247\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.544839544054162e-07], [3.7314100463728023e-07]]\n",
      "Losses: [0.04131608 0.0793844  0.0743803 ]\n",
      "Epoch 672, loss: 0.0650269271695144, windowed_loss: 0.07771148555834106\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.544839544054162e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.08206453 0.14934821 0.17616806]\n",
      "Epoch 673, loss: 0.1358602712691109, windowed_loss: 0.10103160848047947\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.887293963879265e-07], [3.544839544054162e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.02504351 0.0369293  0.08492829]\n",
      "Epoch 674, loss: 0.048967032728787656, windowed_loss: 0.08328474372247098\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.544839544054162e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.17330863 0.06216565 0.21515817]\n",
      "Epoch 675, loss: 0.15021081590652466, windowed_loss: 0.11167937330147441\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.367597566851454e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.03848914 0.07951215 0.13927354]\n",
      "Epoch 676, loss: 0.08575827678044638, windowed_loss: 0.09497870847191957\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.367597566851454e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.11027752 0.57629972 0.09399365]\n",
      "Epoch 677, loss: 0.26019029716251685, windowed_loss: 0.16538646328316262\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.367597566851454e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.07741999 0.02482952 0.03751869]\n",
      "Epoch 678, loss: 0.046589400024515996, windowed_loss: 0.13084599132249308\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.367597566851454e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.06581605 0.05889967 0.06989306]\n",
      "Epoch 679, loss: 0.06486959218978881, windowed_loss: 0.12388309645894056\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.544839544054162e-07]]\n",
      "Losses: [0.0433408  0.06645815 0.0610334 ]\n",
      "Epoch 680, loss: 0.05694411512845026, windowed_loss: 0.05613436911425169\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.367597566851454e-07]]\n",
      "Losses: [0.02889925 0.01632598 0.09955809]\n",
      "Epoch 681, loss: 0.04826110529612346, windowed_loss: 0.056691604204787506\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.367597566851454e-07]]\n",
      "Losses: [0.14089102 0.10684246 0.16215257]\n",
      "Epoch 682, loss: 0.1366286859085501, windowed_loss: 0.08061130211104127\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.367597566851454e-07]]\n",
      "Losses: [0.03505791 0.01694011 0.09408675]\n",
      "Epoch 683, loss: 0.048694925308227534, windowed_loss: 0.07786157217096702\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.367597566851454e-07]]\n",
      "Losses: [0.02391469 0.01096085 0.12639354]\n",
      "Epoch 684, loss: 0.05375635639826457, windowed_loss: 0.07969332253834739\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7429292656853013e-07], [3.199217688508881e-07], [3.367597566851454e-07]]\n",
      "Losses: [0.01543369 0.00626677 0.04978001]\n",
      "Epoch 685, loss: 0.023826822857939734, windowed_loss: 0.04209270152147728\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.199217688508881e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.09958836 0.0542117  0.13266296]\n",
      "Epoch 686, loss: 0.09548767089206693, windowed_loss: 0.05769028338275708\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.199217688508881e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.10103925 0.03269521 0.09618045]\n",
      "Epoch 687, loss: 0.07663830375671386, windowed_loss: 0.06531759916890684\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.07137359 0.05172024 0.04061372]\n",
      "Epoch 688, loss: 0.05456918334960938, windowed_loss: 0.07556505266613006\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.04781381 0.36403528 0.12018986]\n",
      "Epoch 689, loss: 0.1773463186011257, windowed_loss: 0.10285126856914965\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.01992072 0.06188182 0.05567822]\n",
      "Epoch 690, loss: 0.04582692070339259, windowed_loss: 0.09258080755137589\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.199217688508881e-07]]\n",
      "Losses: [0.06993454 0.0373003  0.06069401]\n",
      "Epoch 691, loss: 0.05597628168312901, windowed_loss: 0.09304984032921576\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.0392568040834367e-07]]\n",
      "Losses: [0.06012276 0.06829397 0.10044824]\n",
      "Epoch 692, loss: 0.07628832197189331, windowed_loss: 0.05936384145280497\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.605782802401036e-07], [3.0392568040834367e-07], [3.0392568040834367e-07]]\n",
      "Losses: [0.05860235 0.04917085 0.12159113]\n",
      "Epoch 693, loss: 0.07645477480942516, windowed_loss: 0.06957312615481583\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.475493662280984e-07], [2.887293963879265e-07], [3.0392568040834367e-07]]\n",
      "Losses: [0.10152742 0.29850854 0.14647226]\n",
      "Epoch 694, loss: 0.1821694025993347, windowed_loss: 0.11163749979355105\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.475493662280984e-07], [2.887293963879265e-07], [3.0392568040834367e-07]]\n",
      "Losses: [0.05621041 0.08545494 0.10032798]\n",
      "Epoch 695, loss: 0.08066444412867228, windowed_loss: 0.11309620717914405\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.475493662280984e-07], [2.887293963879265e-07], [3.0392568040834367e-07]]\n",
      "Losses: [0.06849293 0.15518519 0.07248606]\n",
      "Epoch 696, loss: 0.09872139601343606, windowed_loss: 0.12051841424714767\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.475493662280984e-07], [2.887293963879265e-07], [2.887293963879265e-07]]\n",
      "Losses: [0.09559552 0.09033517 0.1064429 ]\n",
      "Epoch 697, loss: 0.09745786301294963, windowed_loss: 0.09228123438501933\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3517189791669347e-07], [2.887293963879265e-07], [2.887293963879265e-07]]\n",
      "Losses: [0.14567956 0.07009606 0.10212007]\n",
      "Epoch 698, loss: 0.10596522921789624, windowed_loss: 0.10071482941476063\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3517189791669347e-07], [2.887293963879265e-07], [2.887293963879265e-07]]\n",
      "Losses: [0.02882697 0.03294775 0.07593649]\n",
      "Epoch 699, loss: 0.04590373600981481, windowed_loss: 0.08310894274688689\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3517189791669347e-07], [2.887293963879265e-07], [2.887293963879265e-07]]\n",
      "Losses: [0.03816736 0.06789451 0.10390384]\n",
      "Epoch 700, loss: 0.06998857117208863, windowed_loss: 0.07395251213326655\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.3517189791669347e-07], [2.887293963879265e-07], [2.887293963879265e-07]]\n",
      "Losses: [0.04772358 0.0471056  0.15099358]\n",
      "Epoch 701, loss: 0.08194091844558715, windowed_loss: 0.06594440854249686\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.234133030208588e-07], [2.7429292656853013e-07], [2.7429292656853013e-07]]\n",
      "Losses: [0.10370146 0.08344132 0.18829968]\n",
      "Epoch 702, loss: 0.12514748586044364, windowed_loss: 0.0923589918260398\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.234133030208588e-07], [2.7429292656853013e-07], [2.7429292656853013e-07]]\n",
      "Losses: [0.01323438 0.08692003 0.07995341]\n",
      "Epoch 703, loss: 0.06003594191455013, windowed_loss: 0.08904144874019364\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.234133030208588e-07], [2.7429292656853013e-07], [2.7429292656853013e-07]]\n",
      "Losses: [0.02896083 0.07537683 0.08617393]\n",
      "Epoch 704, loss: 0.0635038636525472, windowed_loss: 0.08289576380918033\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.234133030208588e-07], [2.7429292656853013e-07], [2.7429292656853013e-07]]\n",
      "Losses: [0.05205013 0.03340585 0.0907854 ]\n",
      "Epoch 705, loss: 0.05874712639544385, windowed_loss: 0.0607623106541804\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1224263786981584e-07], [2.7429292656853013e-07], [2.605782802401036e-07]]\n",
      "Losses: [0.06717526 0.05368693 0.11991229]\n",
      "Epoch 706, loss: 0.08025815911401547, windowed_loss: 0.06750304972066884\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1224263786981584e-07], [2.605782802401036e-07], [2.605782802401036e-07]]\n",
      "Losses: [0.11996582 0.09424688 0.12976865]\n",
      "Epoch 707, loss: 0.11466044934590658, windowed_loss: 0.08455524495178864\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1224263786981584e-07], [2.605782802401036e-07], [2.605782802401036e-07]]\n",
      "Losses: [0.05251129 0.0753309  0.05158423]\n",
      "Epoch 708, loss: 0.0598088075319926, windowed_loss: 0.08490913866397154\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1224263786981584e-07], [2.605782802401036e-07], [2.605782802401036e-07]]\n",
      "Losses: [0.06812557 0.07492869 0.12589402]\n",
      "Epoch 709, loss: 0.08964942593172372, windowed_loss: 0.08803956093654097\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.0163050597632503e-07], [2.605782802401036e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.08385124 0.04683804 0.17209114]\n",
      "Epoch 710, loss: 0.10092680774375289, windowed_loss: 0.08346168040248973\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.0163050597632503e-07], [2.605782802401036e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.14368744 0.15140053 0.16649601]\n",
      "Epoch 711, loss: 0.15386132478713987, windowed_loss: 0.11481251948753883\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.0163050597632503e-07], [2.605782802401036e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.06101125 0.05076015 0.12601702]\n",
      "Epoch 712, loss: 0.07926280783587643, windowed_loss: 0.11135031345558973\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.0163050597632503e-07], [2.605782802401036e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.02295035 0.02981981 0.06246857]\n",
      "Epoch 713, loss: 0.03841291189193726, windowed_loss: 0.09051234817165117\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.0163050597632503e-07], [2.605782802401036e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.10337374 0.03126966 0.10358913]\n",
      "Epoch 714, loss: 0.07941083997269034, windowed_loss: 0.06569551990016802\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.475493662280984e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.15824494 0.0547486  0.17635947]\n",
      "Epoch 715, loss: 0.12978433876471665, windowed_loss: 0.08253603020978141\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.475493662280984e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.15452614 0.06094198 0.10837315]\n",
      "Epoch 716, loss: 0.10794708783048862, windowed_loss: 0.10571408885596521\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.475493662280984e-07], [2.475493662280984e-07]]\n",
      "Losses: [0.05840132 0.04984542 0.07673893]\n",
      "Epoch 717, loss: 0.06166188907623291, windowed_loss: 0.09979777189047939\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.475493662280984e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.10365774 0.06733078 0.14492088]\n",
      "Epoch 718, loss: 0.10530313158640482, windowed_loss: 0.09163736949770879\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.475493662280984e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.04077508 0.00521699 0.07170703]\n",
      "Epoch 719, loss: 0.03923302980447182, windowed_loss: 0.06873268348903652\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.3517189791669347e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.04356136 0.0426302  0.07660254]\n",
      "Epoch 720, loss: 0.05426470215669376, windowed_loss: 0.0662669545158568\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.9154898067750878e-07], [2.3517189791669347e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.03376868 0.09939445 0.14197694]\n",
      "Epoch 721, loss: 0.0917133555542889, windowed_loss: 0.06173702917181816\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.3517189791669347e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.07152364 0.06717053 0.10107934]\n",
      "Epoch 722, loss: 0.07992450348344672, windowed_loss: 0.07530085373147645\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.3517189791669347e-07], [2.3517189791669347e-07]]\n",
      "Losses: [0.07042474 0.04465156 0.0597218 ]\n",
      "Epoch 723, loss: 0.058266032218933096, windowed_loss: 0.07663463041888957\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.3517189791669347e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.13839021 0.11205538 0.14594796]\n",
      "Epoch 724, loss: 0.1321311820348104, windowed_loss: 0.09010723924573007\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.3517189791669347e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.12954081 0.09060249 0.18636135]\n",
      "Epoch 725, loss: 0.13550155181961365, windowed_loss: 0.10863292202445236\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.3517189791669347e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.0154387  0.02957377 0.04648827]\n",
      "Epoch 726, loss: 0.030500249523671984, windowed_loss: 0.09937766112603201\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8197153164363334e-07], [2.234133030208588e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.07228165 0.04385362 0.2143009 ]\n",
      "Epoch 727, loss: 0.11014539282644291, windowed_loss: 0.09204906472324285\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.234133030208588e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.10925571 0.06357131 0.14329585]\n",
      "Epoch 728, loss: 0.10537429076121992, windowed_loss: 0.08200664437044493\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.234133030208588e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.07147251 0.14466137 0.07056127]\n",
      "Epoch 729, loss: 0.09556504894911487, windowed_loss: 0.10369491084559257\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.234133030208588e-07], [2.234133030208588e-07]]\n",
      "Losses: [0.05967425 0.03772209 0.04886596]\n",
      "Epoch 730, loss: 0.048754098021992064, windowed_loss: 0.08323114591077561\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.1224263786981584e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.09915062 0.04981699 0.11965328]\n",
      "Epoch 731, loss: 0.08954029809496923, windowed_loss: 0.07795314835535871\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.1224263786981584e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.08232946 0.05573661 0.06349511]\n",
      "Epoch 732, loss: 0.06718706063317804, windowed_loss: 0.06849381891671312\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.1224263786981584e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.12463729 0.14781751 0.18339862]\n",
      "Epoch 733, loss: 0.15195114322136363, windowed_loss: 0.1028928339831703\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.1224263786981584e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.08016606 0.10140445 0.19738305]\n",
      "Epoch 734, loss: 0.12631785367916007, windowed_loss: 0.11515201917790059\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7287295506145167e-07], [2.1224263786981584e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.02676774 0.01997629 0.08614851]\n",
      "Epoch 735, loss: 0.044297515669104726, windowed_loss: 0.10752217085654281\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6422930730837908e-07], [2.0163050597632503e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.04490062 0.03341959 0.07069867]\n",
      "Epoch 736, loss: 0.04967296067537836, windowed_loss: 0.07342944334121439\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6422930730837908e-07], [2.0163050597632503e-07], [2.1224263786981584e-07]]\n",
      "Losses: [0.04005198 0.09243524 0.02852448]\n",
      "Epoch 737, loss: 0.05367056289830841, windowed_loss: 0.04921367974759716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6422930730837908e-07], [2.0163050597632503e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.0571991  0.06416649 0.07544671]\n",
      "Epoch 738, loss: 0.06560409921125006, windowed_loss: 0.05631587426164561\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6422930730837908e-07], [2.0163050597632503e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.06280754 0.02427414 0.09942328]\n",
      "Epoch 739, loss: 0.06216832105525749, windowed_loss: 0.06048099438827199\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [2.0163050597632503e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.06756324 0.03740903 0.15855615]\n",
      "Epoch 740, loss: 0.0878428071339925, windowed_loss: 0.07187174246683335\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.04182356 0.04070375 0.11428217]\n",
      "Epoch 741, loss: 0.0656031603485087, windowed_loss: 0.07187142951258624\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.11460191 0.03322198 0.10376623]\n",
      "Epoch 742, loss: 0.08386337191722515, windowed_loss: 0.07910311313324213\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [2.0163050597632503e-07]]\n",
      "Losses: [0.08495744 0.02913879 0.08691116]\n",
      "Epoch 743, loss: 0.06700246063868205, windowed_loss: 0.07215633096813863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.02143762 0.08092058 0.12079608]\n",
      "Epoch 744, loss: 0.07438475956658801, windowed_loss: 0.0750835307074984\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.02321239 0.02771604 0.08541139]\n",
      "Epoch 745, loss: 0.04544660393397013, windowed_loss: 0.06227794137974673\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.02128886 0.08313238 0.16532491]\n",
      "Epoch 746, loss: 0.08991538153754342, windowed_loss: 0.06991558167936719\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.560178419429601e-07], [1.9154898067750878e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.01827795 0.00918838 0.02572618]\n",
      "Epoch 747, loss: 0.01773083656826811, windowed_loss: 0.051030940679927216\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.8197153164363334e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.10634048 0.08340127 0.14983376]\n",
      "Epoch 748, loss: 0.11319183618447426, windowed_loss: 0.0736126847634286\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.8197153164363334e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.11211807 0.10339252 0.11996949]\n",
      "Epoch 749, loss: 0.11182669417063394, windowed_loss: 0.08091645564112543\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.8197153164363334e-07], [1.9154898067750878e-07]]\n",
      "Losses: [0.06071887 0.02932581 0.02733105]\n",
      "Epoch 750, loss: 0.03912524477640788, windowed_loss: 0.0880479250438387\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.8197153164363334e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.03920294 0.0381762  0.07605103]\n",
      "Epoch 751, loss: 0.051143391417437734, windowed_loss: 0.06736511012149318\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.7287295506145167e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.07305271 0.08098375 0.15775949]\n",
      "Epoch 752, loss: 0.1039319815600643, windowed_loss: 0.0647335392513033\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.7287295506145167e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.05313532 0.04668255 0.153824  ]\n",
      "Epoch 753, loss: 0.08454729227655862, windowed_loss: 0.07987422175135354\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.482169498458121e-07], [1.7287295506145167e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.04468374 0.03256135 0.05066852]\n",
      "Epoch 754, loss: 0.04263787040251768, windowed_loss: 0.07703904807971353\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.7287295506145167e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.10224472 0.18689004 0.14704573]\n",
      "Epoch 755, loss: 0.14539349921544395, windowed_loss: 0.09085955396484009\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.7287295506145167e-07], [1.8197153164363334e-07]]\n",
      "Losses: [0.05923653 0.04328959 0.13826303]\n",
      "Epoch 756, loss: 0.08026305196116089, windowed_loss: 0.08943147385970751\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.7287295506145167e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.1655976  0.10820213 0.18602207]\n",
      "Epoch 757, loss: 0.15327393283984148, windowed_loss: 0.12631016133881542\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.7287295506145167e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.0414136  0.10352752 0.1105677 ]\n",
      "Epoch 758, loss: 0.08516960541407266, windowed_loss: 0.10623553007169168\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.7287295506145167e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.02693921 0.02402303 0.12012939]\n",
      "Epoch 759, loss: 0.05703054332733154, windowed_loss: 0.09849136052708189\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.6422930730837908e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.01831047 0.02496727 0.06929977]\n",
      "Epoch 760, loss: 0.037525837739308676, windowed_loss: 0.05990866216023762\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4080610235352148e-07], [1.6422930730837908e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.04378184 0.09516195 0.05990416]\n",
      "Epoch 761, loss: 0.06628264955511676, windowed_loss: 0.05361301020725232\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.6422930730837908e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.07536906 0.02798974 0.14591104]\n",
      "Epoch 762, loss: 0.0830899444355834, windowed_loss: 0.06229947724333628\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.6422930730837908e-07], [1.7287295506145167e-07]]\n",
      "Losses: [0.07402349 0.06692052 0.10846671]\n",
      "Epoch 763, loss: 0.08313690582911173, windowed_loss: 0.07750316660660396\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.6422930730837908e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.04635481 0.05472645 0.15242858]\n",
      "Epoch 764, loss: 0.08450327889124552, windowed_loss: 0.08357670971864689\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.0793239  0.07133545 0.19239645]\n",
      "Epoch 765, loss: 0.11435193326099809, windowed_loss: 0.09399737266045177\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.05794716 0.06331228 0.1487389 ]\n",
      "Epoch 766, loss: 0.08999944642844449, windowed_loss: 0.0962848861935627\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.10968749 0.06421513 0.09340526]\n",
      "Epoch 767, loss: 0.08910262855979173, windowed_loss: 0.09781800274974477\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.10149606 0.04181804 0.07433809]\n",
      "Epoch 768, loss: 0.07255073093778704, windowed_loss: 0.08388426864200775\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.337657972358454e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.07946437 0.04000178 0.13929523]\n",
      "Epoch 769, loss: 0.08625379481471691, windowed_loss: 0.08263571810409855\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.560178419429601e-07], [1.6422930730837908e-07]]\n",
      "Losses: [0.10585987 0.07780755 0.11311847]\n",
      "Epoch 770, loss: 0.09892862943625085, windowed_loss: 0.08591105172958492\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.482169498458121e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.10326835 0.0867547  0.14694203]\n",
      "Epoch 771, loss: 0.1123216932557194, windowed_loss: 0.09916803916889572\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.482169498458121e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.10080609 0.10212889 0.08719274]\n",
      "Epoch 772, loss: 0.09670924089236825, windowed_loss: 0.10265318786144617\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.482169498458121e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.05950203 0.08571783 0.17485367]\n",
      "Epoch 773, loss: 0.10669117838822535, windowed_loss: 0.105240704178771\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.482169498458121e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.07534893 0.06701142 0.10293316]\n",
      "Epoch 774, loss: 0.08176450300216674, windowed_loss: 0.09505497409425345\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2707750737405312e-07], [1.482169498458121e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.11670493 0.10332525 0.15678525]\n",
      "Epoch 775, loss: 0.12560514202895132, windowed_loss: 0.10468694113978112\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.560178419429601e-07]]\n",
      "Losses: [0.1228248  0.13009352 0.10984435]\n",
      "Epoch 776, loss: 0.12092088823178047, windowed_loss: 0.10943017775429952\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.07747895 0.09886971 0.2021315 ]\n",
      "Epoch 777, loss: 0.12616005243264442, windowed_loss: 0.12422869423112541\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.06371825 0.11329758 0.12655859]\n",
      "Epoch 778, loss: 0.10119147386722908, windowed_loss: 0.11609080484388466\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.09256873 0.04840776 0.02624485]\n",
      "Epoch 779, loss: 0.055740446249643964, windowed_loss: 0.09436399084983915\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.07191858 0.11188508 0.12479113]\n",
      "Epoch 780, loss: 0.10286493116645073, windowed_loss: 0.08659895042777459\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.06219588 0.05209669 0.07000246]\n",
      "Epoch 781, loss: 0.06143167549240327, windowed_loss: 0.07334568430283266\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.4080610235352148e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.14719859 0.05120012 0.13139119]\n",
      "Epoch 782, loss: 0.10992996584140313, windowed_loss: 0.09140885750008572\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2072363200535045e-07], [1.337657972358454e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.0414467  0.07876862 0.11267642]\n",
      "Epoch 783, loss: 0.07763058318938289, windowed_loss: 0.08299740817439644\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1468745040508292e-07], [1.337657972358454e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.1313981  0.13246263 0.10294323]\n",
      "Epoch 784, loss: 0.12226798623760382, windowed_loss: 0.10327617842279661\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1468745040508292e-07], [1.337657972358454e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.14529261 0.08024155 0.06859472]\n",
      "Epoch 785, loss: 0.09804296093767399, windowed_loss: 0.0993138434548869\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1468745040508292e-07], [1.337657972358454e-07], [1.482169498458121e-07]]\n",
      "Losses: [0.06952089 0.0741201  0.06133654]\n",
      "Epoch 786, loss: 0.0683258435052478, windowed_loss: 0.0962122635601752\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1468745040508292e-07], [1.337657972358454e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.09159055 0.04680058 0.10055497]\n",
      "Epoch 787, loss: 0.07964870208250975, windowed_loss: 0.08200583550847718\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.337657972358454e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.11798127 0.12130058 0.15102053]\n",
      "Epoch 788, loss: 0.13010079081853232, windowed_loss: 0.09269177880209663\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.09823784 0.14051375 0.11587015]\n",
      "Epoch 789, loss: 0.11820724477111776, windowed_loss: 0.10931891255738661\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.05900476 0.07262665 0.05928047]\n",
      "Epoch 790, loss: 0.06363729540506997, windowed_loss: 0.10398177699824002\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.11638495 0.12331846 0.11681988]\n",
      "Epoch 791, loss: 0.1188410943400167, windowed_loss: 0.10022854483873482\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.4080610235352148e-07]]\n",
      "Losses: [0.07239704 0.0819345  0.05861419]\n",
      "Epoch 792, loss: 0.07098190851479651, windowed_loss: 0.08448676608662774\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.0784315  0.09627292 0.11929433]\n",
      "Epoch 793, loss: 0.09799958216936554, windowed_loss: 0.09594086167472625\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0895307788482877e-07], [1.2707750737405312e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.02830595 0.05215835 0.08718857]\n",
      "Epoch 794, loss: 0.05588429103155652, windowed_loss: 0.07495526057190618\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0350542399058734e-07], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.09344445 0.09054025 0.18251556]\n",
      "Epoch 795, loss: 0.12216675281524658, windowed_loss: 0.09201687533872288\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0350542399058734e-07], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.07854763 0.15612813 0.1261514 ]\n",
      "Epoch 796, loss: 0.12027572215837723, windowed_loss: 0.09944225533506011\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0350542399058734e-07], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.08355248 0.06780301 0.09569818]\n",
      "Epoch 797, loss: 0.08235122385114392, windowed_loss: 0.10826456627492258\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0350542399058734e-07], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.09093181 0.18293798 0.07462997]\n",
      "Epoch 798, loss: 0.11616658527371719, windowed_loss: 0.10626451042774611\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0350542399058734e-07], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.02227519 0.1047699  0.03943913]\n",
      "Epoch 799, loss: 0.05549473839112554, windowed_loss: 0.08467084917199556\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.833015279105797e-08], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.09454768 0.04298102 0.10051791]\n",
      "Epoch 800, loss: 0.0793488686611912, windowed_loss: 0.08367006410867799\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.833015279105797e-08], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.04785607 0.03867773 0.07777527]\n",
      "Epoch 801, loss: 0.05476969051361084, windowed_loss: 0.06320443252197586\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.833015279105797e-08], [1.2072363200535045e-07], [1.337657972358454e-07]]\n",
      "Losses: [0.0491209  0.02038433 0.04786442]\n",
      "Epoch 802, loss: 0.039123212805412255, windowed_loss: 0.0577472573267381\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.833015279105797e-08], [1.1468745040508292e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.06878605 0.05182615 0.21130299]\n",
      "Epoch 803, loss: 0.11063839308420816, windowed_loss: 0.06817709880107709\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.833015279105797e-08], [1.1468745040508292e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.05820779 0.05487257 0.15998252]\n",
      "Epoch 804, loss: 0.09102095985412599, windowed_loss: 0.08026085524791547\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.1468745040508292e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.07414525 0.04727843 0.13551063]\n",
      "Epoch 805, loss: 0.08564477141698201, windowed_loss: 0.09576804145177205\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.1468745040508292e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.15495541 0.07206215 0.17568416]\n",
      "Epoch 806, loss: 0.13423390585976436, windowed_loss: 0.10363321237695745\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.0895307788482877e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.08841761 0.09237674 0.0873026 ]\n",
      "Epoch 807, loss: 0.08936564604441326, windowed_loss: 0.10308144110705321\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.0895307788482877e-07], [1.2707750737405312e-07]]\n",
      "Losses: [0.07664256 0.03839723 0.09488048]\n",
      "Epoch 808, loss: 0.0699734245936076, windowed_loss: 0.09785765883259508\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.0895307788482877e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.04250729 0.04834825 0.10225491]\n",
      "Epoch 809, loss: 0.06437015167139495, windowed_loss: 0.07456974076980527\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.0895307788482877e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.07330414 0.06289334 0.0913665 ]\n",
      "Epoch 810, loss: 0.07585466035207113, windowed_loss: 0.07006607887235788\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.341364515150507e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.03586132 0.42011146 0.08401529]\n",
      "Epoch 811, loss: 0.1799960231972123, windowed_loss: 0.1067402784068928\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.874296289392981e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.08838881 0.04012267 0.07897986]\n",
      "Epoch 812, loss: 0.0691637820853499, windowed_loss: 0.10833815521154444\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.874296289392981e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.04495967 0.04591298 0.07229372]\n",
      "Epoch 813, loss: 0.0543887872134187, windowed_loss: 0.10118286416532697\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.874296289392981e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.07669714 0.04471708 0.15309007]\n",
      "Epoch 814, loss: 0.09150142908096315, windowed_loss: 0.07168466612657724\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.874296289392981e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.08173367 0.06868862 0.11310964]\n",
      "Epoch 815, loss: 0.08784397490914854, windowed_loss: 0.07791139706784346\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.874296289392981e-08], [1.0350542399058734e-07], [1.2072363200535045e-07]]\n",
      "Losses: [0.0001778  0.03762178 0.02456742]\n",
      "Epoch 816, loss: 0.020788997192739564, windowed_loss: 0.06671146706095042\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.2072363200535045e-07]]\n",
      "Losses: [0.09363176 0.07982461 0.14967587]\n",
      "Epoch 817, loss: 0.10771074674092855, windowed_loss: 0.07211457294760555\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.2072363200535045e-07]]\n",
      "Losses: [0.08691864 0.04755472 0.13208076]\n",
      "Epoch 818, loss: 0.08885137399676017, windowed_loss: 0.07245037264347609\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.2072363200535045e-07]]\n",
      "Losses: [0.04831551 0.06554105 0.10450426]\n",
      "Epoch 819, loss: 0.07278693803151448, windowed_loss: 0.0897830195897344\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.1468745040508292e-07]]\n",
      "Losses: [0.00872348 0.031368   0.11129399]\n",
      "Epoch 820, loss: 0.05046182473500569, windowed_loss: 0.07070004558776012\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.1468745040508292e-07]]\n",
      "Losses: [0.08346231 0.1190216  0.12435374]\n",
      "Epoch 821, loss: 0.10894588334765846, windowed_loss: 0.07739821537139287\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.833015279105797e-08], [1.1468745040508292e-07]]\n",
      "Losses: [0.04425617 0.03037448 0.06488399]\n",
      "Epoch 822, loss: 0.04650487963358561, windowed_loss: 0.06863752923874993\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.341364515150507e-08], [1.1468745040508292e-07]]\n",
      "Losses: [0.06858867 0.07145897 0.08912563]\n",
      "Epoch 823, loss: 0.07639109230041503, windowed_loss: 0.07728061842721971\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.430581474923332e-08], [9.341364515150507e-08], [1.1468745040508292e-07]]\n",
      "Losses: [0.03048297 0.11641843 0.08824056]\n",
      "Epoch 824, loss: 0.07838065351895197, windowed_loss: 0.06709220848431753\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [9.341364515150507e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.05026533 0.03458789 0.08905843]\n",
      "Epoch 825, loss: 0.05797055101394653, windowed_loss: 0.07091409894443784\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [9.341364515150507e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.02663278 0.04326646 0.03907785]\n",
      "Epoch 826, loss: 0.036325695837985374, windowed_loss: 0.057558966790294624\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [8.874296289392981e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.06643618 0.09172072 0.14498155]\n",
      "Epoch 827, loss: 0.10104614954115791, windowed_loss: 0.06511413213102994\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [8.874296289392981e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.01306387 0.03166233 0.02507932]\n",
      "Epoch 828, loss: 0.023268508399436335, windowed_loss: 0.05354678459285988\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [8.874296289392981e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.08062686 0.07272081 0.11187265]\n",
      "Epoch 829, loss: 0.08840677150090537, windowed_loss: 0.07090714314716655\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [8.874296289392981e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.04720431 0.04607739 0.07237774]\n",
      "Epoch 830, loss: 0.05521981366475423, windowed_loss: 0.05563169785503198\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[8.009052401177165e-08], [8.874296289392981e-08], [1.0895307788482877e-07]]\n",
      "Losses: [0.01308848 0.02121143 0.05008004]\n",
      "Epoch 831, loss: 0.028126649907634277, windowed_loss: 0.05725107835776463\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.608599781118306e-08], [8.874296289392981e-08], [1.0350542399058734e-07]]\n",
      "Losses: [0.09320726 0.11199203 0.08231669]\n",
      "Epoch 832, loss: 0.09583866253803791, windowed_loss: 0.05972837537014214\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.608599781118306e-08], [8.874296289392981e-08], [1.0350542399058734e-07]]\n",
      "Losses: [0.01809794 0.01661993 0.01954358]\n",
      "Epoch 833, loss: 0.018087148985549948, windowed_loss: 0.04735082047707404\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.608599781118306e-08], [8.430581474923332e-08], [1.0350542399058734e-07]]\n",
      "Losses: [0.04983501 0.03994043 0.06759352]\n",
      "Epoch 834, loss: 0.052456319173177085, windowed_loss: 0.05546071023225498\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.608599781118306e-08], [8.430581474923332e-08], [1.0350542399058734e-07]]\n",
      "Losses: [0.03327744 0.06027882 0.04704011]\n",
      "Epoch 835, loss: 0.04686545815014615, windowed_loss: 0.039136308769624394\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.608599781118306e-08], [8.430581474923332e-08], [1.0350542399058734e-07]]\n",
      "Losses: [0.0437886  0.06967561 0.06449681]\n",
      "Epoch 836, loss: 0.05932033882192078, windowed_loss: 0.052880705381748\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.09485237 0.08841161 0.14156621]\n",
      "Epoch 837, loss: 0.10827672767639158, windowed_loss: 0.07148750821615284\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.08212461 0.07769509 0.15910422]\n",
      "Epoch 838, loss: 0.10630797432037538, windowed_loss: 0.09130168027289591\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.07952137 0.08343279 0.21362682]\n",
      "Epoch 839, loss: 0.12552699554397398, windowed_loss: 0.11337056584691364\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.09517725 0.0404129  0.12095955]\n",
      "Epoch 840, loss: 0.085516566435496, windowed_loss: 0.10578384543328179\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.05203823 0.03046108 0.06348695]\n",
      "Epoch 841, loss: 0.048662085692087804, windowed_loss: 0.0865685492238526\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [8.009052401177165e-08], [9.833015279105797e-08]]\n",
      "Losses: [0.02402535 0.05798782 0.05081633]\n",
      "Epoch 842, loss: 0.044276501070123236, windowed_loss: 0.05948505106590235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [7.608599781118306e-08], [9.341364515150507e-08]]\n",
      "Losses: [0.0893051  0.07268777 0.10251541]\n",
      "Epoch 843, loss: 0.08816942469278971, windowed_loss: 0.06036933715166692\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [7.608599781118306e-08], [9.341364515150507e-08]]\n",
      "Losses: [0.08537415 0.08058774 0.0480519 ]\n",
      "Epoch 844, loss: 0.0713379275004069, windowed_loss: 0.06792795108777329\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[7.22816979206239e-08], [7.608599781118306e-08], [9.341364515150507e-08]]\n",
      "Losses: [0.04471804 0.09478808 0.10291007]\n",
      "Epoch 845, loss: 0.08080539515437328, windowed_loss: 0.08010424911585663\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.86676130245927e-08], [7.22816979206239e-08], [9.341364515150507e-08]]\n",
      "Losses: [0.1153196  0.10502227 0.11283773]\n",
      "Epoch 846, loss: 0.1110598669154258, windowed_loss: 0.087734396523402\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.86676130245927e-08], [7.22816979206239e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.11592281 0.0940012  0.16929566]\n",
      "Epoch 847, loss: 0.12640655663118783, windowed_loss: 0.1060906062336623\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.86676130245927e-08], [7.22816979206239e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.12421671 0.11821688 0.14656376]\n",
      "Epoch 848, loss: 0.12966578263159823, windowed_loss: 0.12237740205940395\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.86676130245927e-08], [7.22816979206239e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.00978948 0.03173387 0.04986555]\n",
      "Epoch 849, loss: 0.030462964152396122, windowed_loss: 0.09551176780506072\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.523423237336307e-08], [7.22816979206239e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.01979034 0.04846047 0.10082994]\n",
      "Epoch 850, loss: 0.05636025016596099, windowed_loss: 0.07216299898331845\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.523423237336307e-08], [7.22816979206239e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.05777886 0.03622775 0.07575024]\n",
      "Epoch 851, loss: 0.056585618154797145, windowed_loss: 0.04780294415771808\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.523423237336307e-08], [6.86676130245927e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.07927802 0.07612151 0.14572449]\n",
      "Epoch 852, loss: 0.10037467161814373, windowed_loss: 0.07110684664630063\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.523423237336307e-08], [6.86676130245927e-08], [8.874296289392981e-08]]\n",
      "Losses: [0.03445247 0.03654301 0.06517071]\n",
      "Epoch 853, loss: 0.04538873027146619, windowed_loss: 0.06744967334813569\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.86676130245927e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.0577686  0.11655061 0.11938849]\n",
      "Epoch 854, loss: 0.09790256516138714, windowed_loss: 0.08122198901699902\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.86676130245927e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.04684487 0.12307218 0.11572152]\n",
      "Epoch 855, loss: 0.09521285915820694, windowed_loss: 0.07950138486368676\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.86676130245927e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.09598441 0.08242163 0.06315731]\n",
      "Epoch 856, loss: 0.08052111821002271, windowed_loss: 0.09121218084320559\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.86676130245927e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.08356853 0.04241443 0.10078221]\n",
      "Epoch 857, loss: 0.07558838958151783, windowed_loss: 0.08377412231658249\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.523423237336307e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.08588224 0.05992484 0.12328317]\n",
      "Epoch 858, loss: 0.08969675355859015, windowed_loss: 0.08193542045004355\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[6.197252075469491e-08], [6.523423237336307e-08], [8.430581474923332e-08]]\n",
      "Losses: [0.03262363 0.06595523 0.08472643]\n",
      "Epoch 859, loss: 0.0611017621664637, windowed_loss: 0.07546230176885722\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.523423237336307e-08], [8.009052401177165e-08]]\n",
      "Losses: [0.1248225  0.10411144 0.11010804]\n",
      "Epoch 860, loss: 0.11301399615102396, windowed_loss: 0.0879375039586926\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [8.009052401177165e-08]]\n",
      "Losses: [0.08931647 0.25117674 0.1370945 ]\n",
      "Epoch 861, loss: 0.1591959025218613, windowed_loss: 0.11110388694644964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [8.009052401177165e-08]]\n",
      "Losses: [0.06870609 0.08688053 0.10442478]\n",
      "Epoch 862, loss: 0.08667046560314233, windowed_loss: 0.1196267880920092\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [8.009052401177165e-08]]\n",
      "Losses: [0.06533696 0.1587567  0.03473317]\n",
      "Epoch 863, loss: 0.08627560923875134, windowed_loss: 0.11071399245458498\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [8.009052401177165e-08]]\n",
      "Losses: [0.05203645 0.04904389 0.14599921]\n",
      "Epoch 864, loss: 0.08235985100388765, windowed_loss: 0.0851019752819271\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.05674249 0.04752808 0.1611117 ]\n",
      "Epoch 865, loss: 0.08846075820922851, windowed_loss: 0.08569873948395583\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [6.197252075469491e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.19303997 0.05220218 0.28379857]\n",
      "Epoch 866, loss: 0.17634690507253012, windowed_loss: 0.1157225047618821\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.887389471696016e-08], [5.887389471696016e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.05621252 0.06186794 0.08910632]\n",
      "Epoch 867, loss: 0.06906225802588813, windowed_loss: 0.11128997376921558\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.593019998111215e-08], [5.887389471696016e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.08971497 0.09250944 0.08011302]\n",
      "Epoch 868, loss: 0.08744580967074327, windowed_loss: 0.11095165758972052\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.593019998111215e-08], [5.887389471696016e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.10067982 0.02781685 0.07167123]\n",
      "Epoch 869, loss: 0.06672263432122423, windowed_loss: 0.07441023400595187\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.593019998111215e-08], [5.887389471696016e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.0349843  0.03477337 0.06704797]\n",
      "Epoch 870, loss: 0.045601883329545644, windowed_loss: 0.06659010910717104\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.593019998111215e-08], [5.593019998111215e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.04504289 0.041296   0.06276925]\n",
      "Epoch 871, loss: 0.04970271253585815, windowed_loss: 0.054009076728876004\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.593019998111215e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.0530963  0.03553026 0.0222035 ]\n",
      "Epoch 872, loss: 0.03694335285153641, windowed_loss: 0.0440826495723134\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.593019998111215e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.04601475 0.09490817 0.08240232]\n",
      "Epoch 873, loss: 0.07444174686271347, windowed_loss: 0.05369593741670268\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.593019998111215e-08], [7.608599781118306e-08]]\n",
      "Losses: [0.03431025 0.05696078 0.01648166]\n",
      "Epoch 874, loss: 0.03591756209103999, windowed_loss: 0.049100887268429955\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.593019998111215e-08], [7.22816979206239e-08]]\n",
      "Losses: [0.09311547 0.07071614 0.10674496]\n",
      "Epoch 875, loss: 0.09019219023271967, windowed_loss: 0.06685049972882438\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.313368998205654e-08], [7.22816979206239e-08]]\n",
      "Losses: [0.0530031  0.0975066  0.19853956]\n",
      "Epoch 876, loss: 0.11634975476669485, windowed_loss: 0.08081983569681817\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.313368998205654e-08], [7.22816979206239e-08]]\n",
      "Losses: [0.04525568 0.03064508 0.08116791]\n",
      "Epoch 877, loss: 0.05235622206844959, windowed_loss: 0.08629938902262137\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.313368998205654e-08], [7.22816979206239e-08]]\n",
      "Losses: [0.03233832 0.03577346 0.0981785 ]\n",
      "Epoch 878, loss: 0.05543009344736736, windowed_loss: 0.07471202342750392\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.313368998205654e-08], [5.313368998205654e-08], [7.22816979206239e-08]]\n",
      "Losses: [0.04620443 0.04631117 0.0949286 ]\n",
      "Epoch 879, loss: 0.06248140112113062, windowed_loss: 0.05675590554564919\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.07259052 0.05510141 0.11373041]\n",
      "Epoch 880, loss: 0.08047411261834378, windowed_loss: 0.06612853572894725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.03318181 0.02085568 0.10034635]\n",
      "Epoch 881, loss: 0.051461279193162124, windowed_loss: 0.06480559764421218\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.0767648  0.07134395 0.12300275]\n",
      "Epoch 882, loss: 0.09037049961790851, windowed_loss: 0.07410196380980481\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.05828239 0.09263633 0.09812156]\n",
      "Epoch 883, loss: 0.0830134273610596, windowed_loss: 0.07494840205737674\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.04258687 0.06985134 0.087946  ]\n",
      "Epoch 884, loss: 0.0667947364315321, windowed_loss: 0.08005955447016673\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[5.047700548295371e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.04865499 0.06641655 0.05564721]\n",
      "Epoch 885, loss: 0.05690624984105428, windowed_loss: 0.06890480454454866\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.795315520880602e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.08009419 0.05580998 0.15314551]\n",
      "Epoch 886, loss: 0.09634989312910285, windowed_loss: 0.0733502931338964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.795315520880602e-08], [5.047700548295371e-08], [6.86676130245927e-08]]\n",
      "Losses: [0.03740112 0.05245177 0.03244848]\n",
      "Epoch 887, loss: 0.04076712481180827, windowed_loss: 0.06467442259398846\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.795315520880602e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.09013857 0.05447049 0.08649891]\n",
      "Epoch 888, loss: 0.07703598896662393, windowed_loss: 0.07138433563584501\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.795315520880602e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.09093229 0.11370971 0.0820607 ]\n",
      "Epoch 889, loss: 0.09556756540883075, windowed_loss: 0.07112355972908764\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.16474631 0.09299543 0.20127798]\n",
      "Epoch 890, loss: 0.15300657335917153, windowed_loss: 0.1085367092448754\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.06403602 0.08004003 0.16282674]\n",
      "Epoch 891, loss: 0.10230092986424764, windowed_loss: 0.11695835621074997\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.08225013 0.0337204  0.06719262]\n",
      "Epoch 892, loss: 0.06105438341577369, windowed_loss: 0.10545396221306429\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.795315520880602e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.04357293 0.04486789 0.16629399]\n",
      "Epoch 893, loss: 0.0849116045633952, windowed_loss: 0.08275563928113884\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.5555497448365717e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.09739865 0.08139495 0.16462095]\n",
      "Epoch 894, loss: 0.11447151757307959, windowed_loss: 0.0868125018507495\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.5555497448365717e-08], [4.5555497448365717e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.08427224 0.03806066 0.11220317]\n",
      "Epoch 895, loss: 0.07817869020766549, windowed_loss: 0.09252060411471343\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.5555497448365717e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.08623935 0.05256664 0.09029444]\n",
      "Epoch 896, loss: 0.07636680520209935, windowed_loss: 0.08967233766094813\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.5555497448365717e-08], [6.523423237336307e-08]]\n",
      "Losses: [0.05655259 0.02961528 0.05969361]\n",
      "Epoch 897, loss: 0.0486204922000169, windowed_loss: 0.06772199586992725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.5555497448365717e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.05186468 0.02274462 0.09436216]\n",
      "Epoch 898, loss: 0.05632381910631159, windowed_loss: 0.06043703883614262\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.5555497448365717e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.06513955 0.03299519 0.06606173]\n",
      "Epoch 899, loss: 0.054732158491431517, windowed_loss: 0.05322548993258667\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.5555497448365717e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.01692503 0.02270483 0.02872878]\n",
      "Epoch 900, loss: 0.02278621418124131, windowed_loss: 0.044614063926328135\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.327772257594743e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.11625818 0.11864537 0.14215101]\n",
      "Epoch 901, loss: 0.1256848554611206, windowed_loss: 0.06773440937793114\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.327772257594743e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.02699227 0.03503368 0.0896788 ]\n",
      "Epoch 902, loss: 0.05056824824295605, windowed_loss: 0.06634643929510599\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.327772257594743e-08], [4.327772257594743e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.02669438 0.03897765 0.0787034 ]\n",
      "Epoch 903, loss: 0.04812514177958171, windowed_loss: 0.0747927484945528\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [4.327772257594743e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.06027907 0.04808193 0.11153107]\n",
      "Epoch 904, loss: 0.07329735602719717, windowed_loss: 0.05733024868324497\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [4.111383644715006e-08], [6.197252075469491e-08]]\n",
      "Losses: [0.05431046 0.05823249 0.10446348]\n",
      "Epoch 905, loss: 0.0723354738397286, windowed_loss: 0.06458599054883583\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [4.111383644715006e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.17857553 0.11094414 0.22539102]\n",
      "Epoch 906, loss: 0.1716368958085238, windowed_loss: 0.10575657522514985\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [4.111383644715006e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.05882066 0.03174388 0.0557584 ]\n",
      "Epoch 907, loss: 0.04877431297302246, windowed_loss: 0.09758222754042495\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [4.111383644715006e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.09774654 0.04837737 0.16486053]\n",
      "Epoch 908, loss: 0.10366147931416829, windowed_loss: 0.10802422936523819\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[4.111383644715006e-08], [3.905814462479255e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.08041838 0.07460564 0.03118058]\n",
      "Epoch 909, loss: 0.062068200653974955, windowed_loss: 0.07150133098038856\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.905814462479255e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.08558939 0.02469105 0.09239335]\n",
      "Epoch 910, loss: 0.06755793174427038, windowed_loss: 0.07776253723747122\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.905814462479255e-08], [5.887389471696016e-08]]\n",
      "Losses: [0.020188   0.02077523 0.0189814 ]\n",
      "Epoch 911, loss: 0.01998154194894917, windowed_loss: 0.049869224782398164\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.905814462479255e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.09960917 0.06094002 0.09083564]\n",
      "Epoch 912, loss: 0.08379494387385204, windowed_loss: 0.0571114725223572\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.905814462479255e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.06571489 0.09279517 0.04283205]\n",
      "Epoch 913, loss: 0.06711403624216715, windowed_loss: 0.05696350735498945\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.905814462479255e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.0404615  0.0453063  0.13247533]\n",
      "Epoch 914, loss: 0.07274770960561545, windowed_loss: 0.07455222990721155\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.710523739355292e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.07440386 0.05772449 0.07920473]\n",
      "Epoch 915, loss: 0.07044436120986938, windowed_loss: 0.070102035685884\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.905814462479255e-08], [3.710523739355292e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.04073133 0.0440843  0.06931997]\n",
      "Epoch 916, loss: 0.05137853130917632, windowed_loss: 0.06485686737488706\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.710523739355292e-08], [3.710523739355292e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.08367011 0.13135797 0.15329676]\n",
      "Epoch 917, loss: 0.1227749458948771, windowed_loss: 0.08153261280464093\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.710523739355292e-08], [3.710523739355292e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.05575675 0.02861262 0.07077351]\n",
      "Epoch 918, loss: 0.05171429552387202, windowed_loss: 0.07528925757597514\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.710523739355292e-08], [3.710523739355292e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.0610281  0.03937193 0.04984372]\n",
      "Epoch 919, loss: 0.0500812497072086, windowed_loss: 0.07485683037531923\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.710523739355292e-08], [3.5249975523875276e-08], [5.593019998111215e-08]]\n",
      "Losses: [0.02171868 0.05175238 0.04960575]\n",
      "Epoch 920, loss: 0.04102560347183003, windowed_loss: 0.047607049567636874\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.710523739355292e-08], [3.5249975523875276e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.0345639  0.11822757 0.12315303]\n",
      "Epoch 921, loss: 0.09198149857556094, windowed_loss: 0.06102945058486653\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.5249975523875276e-08], [3.5249975523875276e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.13293299 0.05372514 0.23229318]\n",
      "Epoch 922, loss: 0.13965043913306757, windowed_loss: 0.09088584706015285\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.5249975523875276e-08], [3.5249975523875276e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.06487964 0.07969574 0.09113259]\n",
      "Epoch 923, loss: 0.07856932129155976, windowed_loss: 0.10340041966672942\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.5249975523875276e-08], [3.5249975523875276e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.06807368 0.07416686 0.02278103]\n",
      "Epoch 924, loss: 0.05500719058944518, windowed_loss: 0.09107565033802417\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.5249975523875276e-08], [3.5249975523875276e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.07495206 0.05381866 0.14818771]\n",
      "Epoch 925, loss: 0.09231947803497315, windowed_loss: 0.07529866330532603\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.348747674768151e-08], [5.313368998205654e-08]]\n",
      "Losses: [0.12254314 0.0636092  0.13544509]\n",
      "Epoch 926, loss: 0.10719914129938946, windowed_loss: 0.08484193664126927\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.348747674768151e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.10629262 0.09814354 0.17577338]\n",
      "Epoch 927, loss: 0.12673651202519734, windowed_loss: 0.10875171045318666\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.348747674768151e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.09901776 0.10968918 0.17439738]\n",
      "Epoch 928, loss: 0.1277014417654686, windowed_loss: 0.12054569836335179\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.348747674768151e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.04288982 0.02537715 0.07314953]\n",
      "Epoch 929, loss: 0.047138830941760225, windowed_loss: 0.10052559491080872\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.181310291029743e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.03708864 0.16828547 0.11518073]\n",
      "Epoch 930, loss: 0.10685161613602513, windowed_loss: 0.09389729628108466\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.181310291029743e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.06252525 0.03891091 0.12400252]\n",
      "Epoch 931, loss: 0.07514622492324237, windowed_loss: 0.07637889066700924\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.181310291029743e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.04155714 0.04393368 0.11410932]\n",
      "Epoch 932, loss: 0.06653338061544843, windowed_loss: 0.08284374055823863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.348747674768151e-08], [3.181310291029743e-08], [5.047700548295371e-08]]\n",
      "Losses: [0.07530959 0.03925954 0.07215739]\n",
      "Epoch 933, loss: 0.06224217430750529, windowed_loss: 0.0679739266153987\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.181310291029743e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.1287602  0.08899991 0.22656161]\n",
      "Epoch 934, loss: 0.14810723892847696, windowed_loss: 0.09229426461714356\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.181310291029743e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.01545587 0.04766653 0.04609328]\n",
      "Epoch 935, loss: 0.03640522507722965, windowed_loss: 0.08225154610440397\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.022244776478256e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.01454072 0.06552064 0.03654532]\n",
      "Epoch 936, loss: 0.038868893761593415, windowed_loss: 0.07446045258910002\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.022244776478256e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.08441924 0.07369774 0.1247855 ]\n",
      "Epoch 937, loss: 0.0943008254349988, windowed_loss: 0.05652498142460729\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.022244776478256e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.04911803 0.01564166 0.03692027]\n",
      "Epoch 938, loss: 0.03389332050789812, windowed_loss: 0.05568767990149678\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.181310291029743e-08], [3.022244776478256e-08], [4.795315520880602e-08]]\n",
      "Losses: [0.0638746  0.046445   0.08694776]\n",
      "Epoch 939, loss: 0.0657557897567749, windowed_loss: 0.06464997856655727\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.09510101 0.08057629 0.12257407]\n",
      "Epoch 940, loss: 0.09941712347666422, windowed_loss: 0.06635541124711242\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.08652527 0.07072646 0.08432523]\n",
      "Epoch 941, loss: 0.08052565247179515, windowed_loss: 0.08189952190174477\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.04752715 0.05799487 0.05301863]\n",
      "Epoch 942, loss: 0.05284688345591227, windowed_loss: 0.07759655313479054\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.04803091 0.39447258 0.03486734]\n",
      "Epoch 943, loss: 0.15912360737303058, windowed_loss: 0.09749871443357934\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.00141471 0.02623311 0.02924162]\n",
      "Epoch 944, loss: 0.018963146401217663, windowed_loss: 0.07697787907672017\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[3.022244776478256e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.00725462 0.01808939 0.08733884]\n",
      "Epoch 945, loss: 0.03756094854835199, windowed_loss: 0.07188256744086674\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.871132537654343e-08], [4.5555497448365717e-08]]\n",
      "Losses: [0.05519616 0.02254285 0.09610394]\n",
      "Epoch 946, loss: 0.057947652054852306, windowed_loss: 0.038157249001473985\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.7275759107716258e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.13968859 0.05127137 0.14213487]\n",
      "Epoch 947, loss: 0.11103160826365154, windowed_loss: 0.06884673628895194\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.7275759107716258e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.10406209 0.09097992 0.12011077]\n",
      "Epoch 948, loss: 0.10505092661621257, windowed_loss: 0.09134339564490547\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.7275759107716258e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.07075818 0.02828742 0.09324408]\n",
      "Epoch 949, loss: 0.06409656069799512, windowed_loss: 0.09339303185928642\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.7275759107716258e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.08083323 0.0670289  0.08986216]\n",
      "Epoch 950, loss: 0.07924143218484496, windowed_loss: 0.08279630649968422\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.5911971152330443e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.07648139 0.09598334 0.16525774]\n",
      "Epoch 951, loss: 0.11257415660222371, windowed_loss: 0.0853040498283546\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.5911971152330443e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.06156938 0.03595852 0.09433813]\n",
      "Epoch 952, loss: 0.06395534181594849, windowed_loss: 0.08525697686767238\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.871132537654343e-08], [2.5911971152330443e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.04169688 0.04885522 0.12323369]\n",
      "Epoch 953, loss: 0.07126193103904954, windowed_loss: 0.08259714315240725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.5911971152330443e-08], [4.327772257594743e-08]]\n",
      "Losses: [0.05273692 0.03407046 0.11322931]\n",
      "Epoch 954, loss: 0.06667889669567406, windowed_loss: 0.06729872318355735\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.5911971152330443e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.09192835 0.10299461 0.11566071]\n",
      "Epoch 955, loss: 0.10352788930267354, windowed_loss: 0.08048957234579905\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.5911971152330443e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.04731627 0.04498016 0.12347831]\n",
      "Epoch 956, loss: 0.071924915294609, windowed_loss: 0.08071056709765219\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.5911971152330443e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.00919864 0.01512349 0.01488558]\n",
      "Epoch 957, loss: 0.013069238197668122, windowed_loss: 0.06284068093165021\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.461637259471392e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.08029508 0.05329269 0.07471627]\n",
      "Epoch 958, loss: 0.06943467917691272, windowed_loss: 0.05147627755639661\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.461637259471392e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.02546259 0.04994027 0.04785312]\n",
      "Epoch 959, loss: 0.04108532540544957, windowed_loss: 0.04119641426001014\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.7275759107716258e-08], [2.461637259471392e-08], [4.111383644715006e-08]]\n",
      "Losses: [0.0109739  0.02720436 0.03479577]\n",
      "Epoch 960, loss: 0.024324675161675757, windowed_loss: 0.044948226581346014\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5911971152330443e-08], [2.461637259471392e-08], [3.905814462479255e-08]]\n",
      "Losses: [0.0649547  0.04647173 0.11183224]\n",
      "Epoch 961, loss: 0.07441955705284674, windowed_loss: 0.04660985253999069\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5911971152330443e-08], [2.461637259471392e-08], [3.905814462479255e-08]]\n",
      "Losses: [0.05964139 0.08160431 0.09642161]\n",
      "Epoch 962, loss: 0.07922243944293204, windowed_loss: 0.05932222388581818\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5911971152330443e-08], [2.461637259471392e-08], [3.905814462479255e-08]]\n",
      "Losses: [0.12030437 0.05317457 0.1891839 ]\n",
      "Epoch 963, loss: 0.12088761288159024, windowed_loss: 0.09150986979245634\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5911971152330443e-08], [2.338555396497822e-08], [3.905814462479255e-08]]\n",
      "Losses: [0.0455089  0.08073241 0.0346858 ]\n",
      "Epoch 964, loss: 0.05364236863454183, windowed_loss: 0.08458414031968804\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.5911971152330443e-08], [2.338555396497822e-08], [3.905814462479255e-08]]\n",
      "Losses: [0.05368896 0.07074727 0.10029721]\n",
      "Epoch 965, loss: 0.07491114265881953, windowed_loss: 0.08314704139165054\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.338555396497822e-08], [3.710523739355292e-08]]\n",
      "Losses: [0.11431346 0.05861622 0.10903804]\n",
      "Epoch 966, loss: 0.09398924171366047, windowed_loss: 0.07418091766900727\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.338555396497822e-08], [3.710523739355292e-08]]\n",
      "Losses: [0.04418497 0.1156738  0.0876633 ]\n",
      "Epoch 967, loss: 0.08250735852426899, windowed_loss: 0.083802580965583\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.338555396497822e-08], [3.710523739355292e-08]]\n",
      "Losses: [0.10916105 0.07077758 0.17455332]\n",
      "Epoch 968, loss: 0.1181639836641973, windowed_loss: 0.09822019463404225\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.338555396497822e-08], [3.710523739355292e-08]]\n",
      "Losses: [0.06820898 0.08800154 0.08790683]\n",
      "Epoch 969, loss: 0.08137244828542074, windowed_loss: 0.094014596824629\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.338555396497822e-08], [3.710523739355292e-08]]\n",
      "Losses: [0.02943416 0.01339573 0.08965201]\n",
      "Epoch 970, loss: 0.044160633999979, windowed_loss: 0.08123235531653235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.221627626672931e-08], [3.5249975523875276e-08]]\n",
      "Losses: [0.0608384  0.07189471 0.11601481]\n",
      "Epoch 971, loss: 0.08291597261218604, windowed_loss: 0.06948301829919527\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.461637259471392e-08], [2.221627626672931e-08], [3.5249975523875276e-08]]\n",
      "Losses: [0.05744112 0.03529297 0.1225086 ]\n",
      "Epoch 972, loss: 0.07174756197270028, windowed_loss: 0.06627472286162178\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.221627626672931e-08], [3.5249975523875276e-08]]\n",
      "Losses: [0.13002485 0.07002468 0.14006224]\n",
      "Epoch 973, loss: 0.11337059265478866, windowed_loss: 0.08934470907989167\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.221627626672931e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.09355239 0.10395345 0.16251068]\n",
      "Epoch 974, loss: 0.12000550858179727, windowed_loss: 0.10170788773642873\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.04820367 0.10538688 0.06771933]\n",
      "Epoch 975, loss: 0.07376995911658725, windowed_loss: 0.10238202011772439\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.08717882 0.05181801 0.07552742]\n",
      "Epoch 976, loss: 0.07150808380855746, windowed_loss: 0.088427850502314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.06184271 0.03762112 0.13678479]\n",
      "Epoch 977, loss: 0.0787495376275406, windowed_loss: 0.07467586018422843\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.05427942 0.18771803 0.07962916]\n",
      "Epoch 978, loss: 0.1072088705009246, windowed_loss: 0.08582216397900755\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.348747674768151e-08]]\n",
      "Losses: [0.03959261 0.1247775  0.04784443]\n",
      "Epoch 979, loss: 0.07073818174997966, windowed_loss: 0.08556552995948162\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.181310291029743e-08]]\n",
      "Losses: [0.06751505 0.04128952 0.05565067]\n",
      "Epoch 980, loss: 0.05481841405232748, windowed_loss: 0.07758848876774392\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.338555396497822e-08], [2.1105462453392842e-08], [3.181310291029743e-08]]\n",
      "Losses: [0.06255926 0.05027015 0.08660045]\n",
      "Epoch 981, loss: 0.06647661765416463, windowed_loss: 0.06401107115215725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [2.00501893307232e-08], [3.181310291029743e-08]]\n",
      "Losses: [0.06774945 0.05154244 0.06886301]\n",
      "Epoch 982, loss: 0.0627182992044575, windowed_loss: 0.06133777697031654\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [2.00501893307232e-08], [3.181310291029743e-08]]\n",
      "Losses: [0.01839107 0.01359981 0.07401941]\n",
      "Epoch 983, loss: 0.03533676376164397, windowed_loss: 0.054843893540088694\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [2.00501893307232e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.07953766 0.09815582 0.21385188]\n",
      "Epoch 984, loss: 0.13051512246141453, windowed_loss: 0.076190061809172\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [2.00501893307232e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.04060748 0.0357443  0.04804626]\n",
      "Epoch 985, loss: 0.04146601473719738, windowed_loss: 0.06910596698675196\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [2.00501893307232e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.07836049 0.08247777 0.12948655]\n",
      "Epoch 986, loss: 0.09677493516492619, windowed_loss: 0.0895853574545127\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.221627626672931e-08], [1.904767986418704e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.03202336 0.10769207 0.05593387]\n",
      "Epoch 987, loss: 0.06521643378691587, windowed_loss: 0.06781912789634648\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.904767986418704e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.06754639 0.11301312 0.08576058]\n",
      "Epoch 988, loss: 0.08877336215972902, windowed_loss: 0.08358824370385703\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.904767986418704e-08], [3.022244776478256e-08]]\n",
      "Losses: [0.0670603  0.14973996 0.04822148]\n",
      "Epoch 989, loss: 0.08834058249402858, windowed_loss: 0.08077679281355782\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.904767986418704e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.06439319 0.02402039 0.08991725]\n",
      "Epoch 990, loss: 0.05944360796610514, windowed_loss: 0.07885251753995424\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.8095295870977684e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.0292351  0.06522472 0.07945165]\n",
      "Epoch 991, loss: 0.05797049166285043, windowed_loss: 0.06858489404099471\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.8095295870977684e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.15792983 0.07027502 0.13087175]\n",
      "Epoch 992, loss: 0.11969219849917119, windowed_loss: 0.07903543270937559\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.8095295870977684e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.06573841 0.07306904 0.07565703]\n",
      "Epoch 993, loss: 0.0714881589294597, windowed_loss: 0.08305028303049378\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.1105462453392842e-08], [1.8095295870977684e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.09651966 0.06570876 0.09169653]\n",
      "Epoch 994, loss: 0.0846416498819987, windowed_loss: 0.09194066910354319\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.11495618 0.07445548 0.08828339]\n",
      "Epoch 995, loss: 0.09256501499811809, windowed_loss: 0.08289827460319216\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.871132537654343e-08]]\n",
      "Losses: [0.06986762 0.05815367 0.05911353]\n",
      "Epoch 996, loss: 0.06237827465386094, windowed_loss: 0.0798616465113259\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.06153559 0.12453573 0.22125204]\n",
      "Epoch 997, loss: 0.13577445236395003, windowed_loss: 0.09690591400530968\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.0525101  0.01866592 0.18749075]\n",
      "Epoch 998, loss: 0.08622225810466962, windowed_loss: 0.09479166170749354\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.02623474 0.06259094 0.0501987 ]\n",
      "Epoch 999, loss: 0.0463414611064679, windowed_loss: 0.08944605719169585\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.7190531077428798e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.06030331 0.06147717 0.0301026 ]\n",
      "Epoch 1000, loss: 0.05062769492467245, windowed_loss: 0.061063804711936655\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.6331004523557358e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.04109405 0.06214751 0.10038424]\n",
      "Epoch 1001, loss: 0.06787526870299436, windowed_loss: 0.054948141578044896\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[2.00501893307232e-08], [1.6331004523557358e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.05084332 0.19754796 0.12070806]\n",
      "Epoch 1002, loss: 0.12303311077753702, windowed_loss: 0.08051202480173461\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.904767986418704e-08], [1.6331004523557358e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.06569973 0.10632765 0.11180254]\n",
      "Epoch 1003, loss: 0.09460997405939471, windowed_loss: 0.0951727845133087\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.904767986418704e-08], [1.6331004523557358e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.0851867  0.02639396 0.08456552]\n",
      "Epoch 1004, loss: 0.06538206159710168, windowed_loss: 0.09434171547801114\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.904767986418704e-08], [1.6331004523557358e-08], [2.7275759107716258e-08]]\n",
      "Losses: [0.00899433 0.06277654 0.06922853]\n",
      "Epoch 1005, loss: 0.04699980271070039, windowed_loss: 0.06899727945573227\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.904767986418704e-08], [1.551445429737949e-08], [2.5911971152330443e-08]]\n",
      "Losses: [0.04214773 0.30253905 0.09177395]\n",
      "Epoch 1006, loss: 0.14548690874413792, windowed_loss: 0.08595625768398\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.551445429737949e-08], [2.5911971152330443e-08]]\n",
      "Losses: [0.09046116 0.08828743 0.13010592]\n",
      "Epoch 1007, loss: 0.10295150327682495, windowed_loss: 0.09847940491055442\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.551445429737949e-08], [2.5911971152330443e-08]]\n",
      "Losses: [0.05627447 0.06044417 0.06383087]\n",
      "Epoch 1008, loss: 0.06018317215587588, windowed_loss: 0.1028738613922796\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.551445429737949e-08], [2.5911971152330443e-08]]\n",
      "Losses: [0.04402107 0.06079646 0.04319714]\n",
      "Epoch 1009, loss: 0.049338220278422044, windowed_loss: 0.0708242985703743\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.551445429737949e-08], [2.5911971152330443e-08]]\n",
      "Losses: [0.043331   0.0810489  0.12452639]\n",
      "Epoch 1010, loss: 0.08296876456949341, windowed_loss: 0.06416338566793045\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.551445429737949e-08], [2.461637259471392e-08]]\n",
      "Losses: [0.02452365 0.03919962 0.14130153]\n",
      "Epoch 1011, loss: 0.068341598083914, windowed_loss: 0.06688286097727648\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.4738731582510513e-08], [2.461637259471392e-08]]\n",
      "Losses: [0.04736962 0.04296803 0.10979951]\n",
      "Epoch 1012, loss: 0.0667123843828837, windowed_loss: 0.07267424901209703\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.8095295870977684e-08], [1.4738731582510513e-08], [2.461637259471392e-08]]\n",
      "Losses: [0.05939261 0.02193329 0.13131969]\n",
      "Epoch 1013, loss: 0.07088186550140381, windowed_loss: 0.06864528265606717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7190531077428798e-08], [1.4738731582510513e-08], [2.461637259471392e-08]]\n",
      "Losses: [0.119975   0.04499683 0.14545256]\n",
      "Epoch 1014, loss: 0.10347479534149169, windowed_loss: 0.08035634840859307\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7190531077428798e-08], [1.4738731582510513e-08], [2.461637259471392e-08]]\n",
      "Losses: [0.07502572 0.1304981  0.12625703]\n",
      "Epoch 1015, loss: 0.11059361704222488, windowed_loss: 0.0949834259617068\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7190531077428798e-08], [1.4738731582510513e-08], [2.338555396497822e-08]]\n",
      "Losses: [0.16727446 0.09501338 0.2399076 ]\n",
      "Epoch 1016, loss: 0.16739847930272422, windowed_loss: 0.12715563056214693\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7190531077428798e-08], [1.4738731582510513e-08], [2.338555396497822e-08]]\n",
      "Losses: [0.04778099 0.03095225 0.06668018]\n",
      "Epoch 1017, loss: 0.04847113976258791, windowed_loss: 0.10882107870251234\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.7190531077428798e-08], [1.4001795003384986e-08], [2.338555396497822e-08]]\n",
      "Losses: [0.07792893 0.04981284 0.12468125]\n",
      "Epoch 1018, loss: 0.08414100852105007, windowed_loss: 0.1000035425287874\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.4001795003384986e-08], [2.338555396497822e-08]]\n",
      "Losses: [0.13034178 0.05901391 0.19457145]\n",
      "Epoch 1019, loss: 0.1279757123395621, windowed_loss: 0.08686262020773335\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.4001795003384986e-08], [2.338555396497822e-08]]\n",
      "Losses: [0.03287011 0.04066158 0.05448836]\n",
      "Epoch 1020, loss: 0.042673351132399895, windowed_loss: 0.08493002399767069\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.4001795003384986e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.09427095 0.05712673 0.09789245]\n",
      "Epoch 1021, loss: 0.08309671052296956, windowed_loss: 0.08458192466497717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.3301705253215736e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.05759849 0.07415328 0.05820671]\n",
      "Epoch 1022, loss: 0.06331949307270343, windowed_loss: 0.0630298515760243\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.3301705253215736e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.04523606 0.01908775 0.06160093]\n",
      "Epoch 1023, loss: 0.041974912643432616, windowed_loss: 0.06279703874636854\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.3301705253215736e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.15349288 0.11533268 0.21485636]\n",
      "Epoch 1024, loss: 0.16122730429967244, windowed_loss: 0.0888405700052695\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.6331004523557358e-08], [1.3301705253215736e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.03713195 0.0516203  0.08509031]\n",
      "Epoch 1025, loss: 0.05794752009709676, windowed_loss: 0.08704991234673394\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.551445429737949e-08], [1.3301705253215736e-08], [2.221627626672931e-08]]\n",
      "Losses: [0.05394766 0.03514547 0.07090669]\n",
      "Epoch 1026, loss: 0.05333327528942062, windowed_loss: 0.09083603322872995\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.551445429737949e-08], [1.3301705253215736e-08], [2.1105462453392842e-08]]\n",
      "Losses: [0.08881818 0.15047189 0.1060879 ]\n",
      "Epoch 1027, loss: 0.11512598981819, windowed_loss: 0.07546892840156912\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.551445429737949e-08], [1.3301705253215736e-08], [2.1105462453392842e-08]]\n",
      "Losses: [0.04431618 0.02198043 0.07788299]\n",
      "Epoch 1028, loss: 0.04805986613154891, windowed_loss: 0.07217304374638651\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.551445429737949e-08], [1.2636619990554948e-08], [2.1105462453392842e-08]]\n",
      "Losses: [0.03486134 0.12700513 0.10343202]\n",
      "Epoch 1029, loss: 0.08843282922108968, windowed_loss: 0.08387289505694286\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.551445429737949e-08], [1.2636619990554948e-08], [2.1105462453392842e-08]]\n",
      "Losses: [0.07685594 0.07269956 0.11847553]\n",
      "Epoch 1030, loss: 0.08934367634729297, windowed_loss: 0.07527879056664384\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.08157593 0.08050453 0.14865249]\n",
      "Epoch 1031, loss: 0.10357764943440755, windowed_loss: 0.0937847183342634\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.02608766 0.05240904 0.0525197 ]\n",
      "Epoch 1032, loss: 0.04367213380065468, windowed_loss: 0.07886448652745173\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.12378254 0.09137856 0.11814368]\n",
      "Epoch 1033, loss: 0.11110159016676856, windowed_loss: 0.08611712446727693\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.0723423  0.08103536 0.103149  ]\n",
      "Epoch 1034, loss: 0.0855088874499003, windowed_loss: 0.08009420380577452\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.07240955 0.05019365 0.1072796 ]\n",
      "Epoch 1035, loss: 0.07662760062390063, windowed_loss: 0.09107935941352317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4738731582510513e-08], [1.2636619990554948e-08], [2.00501893307232e-08]]\n",
      "Losses: [0.06086307 0.03008431 0.0274188 ]\n",
      "Epoch 1036, loss: 0.03945539307243214, windowed_loss: 0.06719729371541103\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.11641394 0.06405763 0.15798164]\n",
      "Epoch 1037, loss: 0.11281773789723715, windowed_loss: 0.0763002438645233\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.04044147 0.05869436 0.09226897]\n",
      "Epoch 1038, loss: 0.06380159755946802, windowed_loss: 0.07202490950971244\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.09270777 0.06472412 0.11118627]\n",
      "Epoch 1039, loss: 0.08953938570367286, windowed_loss: 0.08871957372012601\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.04731665 0.06413918 0.10906491]\n",
      "Epoch 1040, loss: 0.07350691191483055, windowed_loss: 0.07561596505932382\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.05507333 0.04817236 0.0509538 ]\n",
      "Epoch 1041, loss: 0.05139983170177431, windowed_loss: 0.07148204310675925\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.4001795003384986e-08], [1.20047889910272e-08], [1.904767986418704e-08]]\n",
      "Losses: [0.04152059 0.04327855 0.06904749]\n",
      "Epoch 1042, loss: 0.05128220971425374, windowed_loss: 0.0587296511102862\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.20047889910272e-08], [1.8095295870977684e-08]]\n",
      "Losses: [0.04955087 0.18533655 0.11557801]\n",
      "Epoch 1043, loss: 0.11682180833816529, windowed_loss: 0.07316794991806445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.20047889910272e-08], [1.8095295870977684e-08]]\n",
      "Losses: [0.04091171 0.06424138 0.11624298]\n",
      "Epoch 1044, loss: 0.07379868943132235, windowed_loss: 0.08063423582791379\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.20047889910272e-08], [1.8095295870977684e-08]]\n",
      "Losses: [0.05066416 0.0557875  0.1429424 ]\n",
      "Epoch 1045, loss: 0.08313135210290012, windowed_loss: 0.09125061662412925\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.1404549541475839e-08], [1.8095295870977684e-08]]\n",
      "Losses: [0.06252184 0.0590404  0.04651464]\n",
      "Epoch 1046, loss: 0.05602562587104808, windowed_loss: 0.07098522246842352\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.1404549541475839e-08], [1.7190531077428798e-08]]\n",
      "Losses: [0.042626   0.0196066  0.10511641]\n",
      "Epoch 1047, loss: 0.05578300145416056, windowed_loss: 0.06497999314270293\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.3301705253215736e-08], [1.1404549541475839e-08], [1.7190531077428798e-08]]\n",
      "Losses: [0.04161493 0.07063613 0.04475099]\n",
      "Epoch 1048, loss: 0.05233401521046957, windowed_loss: 0.05471421417855941\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.1404549541475839e-08], [1.7190531077428798e-08]]\n",
      "Losses: [0.04724162 0.04524357 0.06065801]\n",
      "Epoch 1049, loss: 0.051047732871539464, windowed_loss: 0.05305491651205654\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.1404549541475839e-08], [1.7190531077428798e-08]]\n",
      "Losses: [0.04155332 0.05555203 0.13574054]\n",
      "Epoch 1050, loss: 0.07761529595675115, windowed_loss: 0.06033234801292006\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.1404549541475839e-08], [1.7190531077428798e-08]]\n",
      "Losses: [0.07605254 0.02230629 0.05028139]\n",
      "Epoch 1051, loss: 0.049546741849992304, windowed_loss: 0.05940325689276097\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.0834322064402047e-08], [1.6331004523557358e-08]]\n",
      "Losses: [0.03722617 0.050157   0.07149519]\n",
      "Epoch 1052, loss: 0.05295945312790498, windowed_loss: 0.060040496978216146\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.0834322064402047e-08], [1.6331004523557358e-08]]\n",
      "Losses: [0.05208252 0.06390392 0.09227607]\n",
      "Epoch 1053, loss: 0.0694208385630616, windowed_loss: 0.057309011180319634\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.2636619990554948e-08], [1.0834322064402047e-08], [1.6331004523557358e-08]]\n",
      "Losses: [0.04625471 0.03729412 0.09812629]\n",
      "Epoch 1054, loss: 0.060558374467464184, windowed_loss: 0.06097955538614359\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0834322064402047e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.21581863 0.16543745 0.23580016]\n",
      "Epoch 1055, loss: 0.20568540992940676, windowed_loss: 0.11188820765331085\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0834322064402047e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.0991245  0.05083578 0.1471237 ]\n",
      "Epoch 1056, loss: 0.09902799424124942, windowed_loss: 0.12175725954604012\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.09513252 0.09348469 0.09937163]\n",
      "Epoch 1057, loss: 0.0959962790807088, windowed_loss: 0.13356989441712167\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.03445883 0.03522352 0.17066931]\n",
      "Epoch 1058, loss: 0.0801172214977872, windowed_loss: 0.09171383160658181\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.10896527 0.12165186 0.15496127]\n",
      "Epoch 1059, loss: 0.12852613274543065, windowed_loss: 0.10154654444130888\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.02929656 0.07520837 0.12598615]\n",
      "Epoch 1060, loss: 0.07683036083687761, windowed_loss: 0.09515790502669848\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.20047889910272e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.07886517 0.09372233 0.11256395]\n",
      "Epoch 1061, loss: 0.09505048322677612, windowed_loss: 0.10013565893636145\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1404549541475839e-08], [1.0292605961181944e-08], [1.551445429737949e-08]]\n",
      "Losses: [0.09907325 0.02515684 0.1103475 ]\n",
      "Epoch 1062, loss: 0.07819253142674765, windowed_loss: 0.0833577918301338\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1404549541475839e-08], [9.777975663122846e-09], [1.551445429737949e-08]]\n",
      "Losses: [0.02996718 0.0400598  0.16542753]\n",
      "Epoch 1063, loss: 0.07848483594258626, windowed_loss: 0.08390928353203668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1404549541475839e-08], [9.777975663122846e-09], [1.551445429737949e-08]]\n",
      "Losses: [0.03601396 0.04316439 0.09076605]\n",
      "Epoch 1064, loss: 0.05664813446855258, windowed_loss: 0.07110850061262883\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.1404549541475839e-08], [9.777975663122846e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.06680978 0.0628751  0.12409535]\n",
      "Epoch 1065, loss: 0.08459341287612915, windowed_loss: 0.07324212776242266\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.777975663122846e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.075003   0.03248781 0.09231762]\n",
      "Epoch 1066, loss: 0.06660281271340857, windowed_loss: 0.06928145335269677\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.06912211 0.06467904 0.16313087]\n",
      "Epoch 1067, loss: 0.09897734008794158, windowed_loss: 0.08339118855915977\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.1181776  0.05662223 0.10231977]\n",
      "Epoch 1068, loss: 0.0923731992781441, windowed_loss: 0.08598445069316474\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.0634969  0.09517169 0.11687413]\n",
      "Epoch 1069, loss: 0.09184757421613537, windowed_loss: 0.09439937119407367\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.05414206 0.05123875 0.10430782]\n",
      "Epoch 1070, loss: 0.06989620860417683, windowed_loss: 0.08470566069948543\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.05029295 0.02844423 0.07943536]\n",
      "Epoch 1071, loss: 0.05272417894999185, windowed_loss: 0.07148932059010135\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0834322064402047e-08], [9.289076879966704e-09], [1.4738731582510513e-08]]\n",
      "Losses: [0.05785129 0.07326018 0.06388046]\n",
      "Epoch 1072, loss: 0.06499730918302114, windowed_loss: 0.06253923224572994\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [9.289076879966704e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.08553231 0.03179854 0.1477225 ]\n",
      "Epoch 1073, loss: 0.08835111463874201, windowed_loss: 0.068690867590585\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [8.82462303596837e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.04891038 0.04391203 0.06918623]\n",
      "Epoch 1074, loss: 0.05400288001489225, windowed_loss: 0.06911710127888514\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [8.82462303596837e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.09298542 0.06564944 0.10254611]\n",
      "Epoch 1075, loss: 0.08706032393690578, windowed_loss: 0.07647143953018003\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [8.82462303596837e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.02814032 0.01336091 0.02734899]\n",
      "Epoch 1076, loss: 0.022950073361954215, windowed_loss: 0.05467109243791741\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [8.82462303596837e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.0790292  0.04962059 0.16448133]\n",
      "Epoch 1077, loss: 0.09771037675096898, windowed_loss: 0.06924025801660966\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[1.0292605961181944e-08], [8.82462303596837e-09], [1.4001795003384986e-08]]\n",
      "Losses: [0.02667966 0.04400508 0.08988872]\n",
      "Epoch 1078, loss: 0.053524488119101155, windowed_loss: 0.058061646077341454\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.777975663122846e-09], [8.38339188416995e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.10840624 0.04438146 0.13227918]\n",
      "Epoch 1079, loss: 0.09502228977047927, windowed_loss: 0.08208571821351647\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.777975663122846e-09], [8.38339188416995e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.12160186 0.10406929 0.10610166]\n",
      "Epoch 1080, loss: 0.11059093459415371, windowed_loss: 0.08637923749457804\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.777975663122846e-09], [8.38339188416995e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.11864344 0.13323429 0.1294702 ]\n",
      "Epoch 1081, loss: 0.12711597540096672, windowed_loss: 0.11090973325519989\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.777975663122846e-09], [8.38339188416995e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.05296871 0.01663829 0.05735672]\n",
      "Epoch 1082, loss: 0.04232123858465222, windowed_loss: 0.09334271619325755\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.777975663122846e-09], [7.964222289961453e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.07223922 0.06669855 0.0531015 ]\n",
      "Epoch 1083, loss: 0.06401309127628883, windowed_loss: 0.07781676842063594\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.289076879966704e-09], [7.964222289961453e-09], [1.3301705253215736e-08]]\n",
      "Losses: [0.0776064  0.09559784 0.08593117]\n",
      "Epoch 1084, loss: 0.08637847005325551, windowed_loss: 0.06423759997139884\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n",
      "Unsupervised Training.. 68.0\n",
      "Unsupervised Training.. 72.0\n",
      "Unsupervised Training.. 76.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 84.0\n",
      "Unsupervised Training.. 88.0\n",
      "Unsupervised Training.. 92.0\n",
      "Unsupervised Training.. 96.0\n",
      "LR: [[9.289076879966704e-09], [7.964222289961453e-09], [1.2636619990554948e-08]]\n",
      "Losses: [0.08707466 0.05254469 0.09262363]\n",
      "Epoch 1085, loss: 0.07741432650883993, windowed_loss: 0.07593529594612809\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 4.0\n",
      "Unsupervised Training.. 8.0\n",
      "Unsupervised Training.. 12.0\n",
      "Unsupervised Training.. 16.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 24.0\n",
      "Unsupervised Training.. 28.0\n",
      "Unsupervised Training.. 32.0\n",
      "Unsupervised Training.. 36.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 44.0\n",
      "Unsupervised Training.. 48.0\n",
      "Unsupervised Training.. 52.0\n",
      "Unsupervised Training.. 56.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 64.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [45], line 118\u001B[0m\n\u001B[1;32m    116\u001B[0m loss_history \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m loss \u001B[38;5;241m>\u001B[39m target:\n\u001B[0;32m--> 118\u001B[0m     losses, total_updates \u001B[38;5;241m=\u001B[39m \u001B[43mpretraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampled_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensemble\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_cutoff\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m     average_loss \u001B[38;5;241m=\u001B[39m losses \u001B[38;5;241m/\u001B[39m total_updates\n\u001B[1;32m    120\u001B[0m     lr \u001B[38;5;241m=\u001B[39m ensemble\u001B[38;5;241m.\u001B[39mevaluate_lr(average_loss)\n",
      "Cell \u001B[0;32mIn [45], line 99\u001B[0m, in \u001B[0;36mpretraining\u001B[0;34m(data, ensemble, data_cutoff, data_size)\u001B[0m\n\u001B[1;32m     97\u001B[0m anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([data[samples[i \u001B[38;5;241m+\u001B[39m (j \u001B[38;5;241m%\u001B[39m AUGMENT_SIZE)][\u001B[38;5;241m0\u001B[39m]][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[1;32m     98\u001B[0m positives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([getRandomTransformation(data[samples[i \u001B[38;5;241m+\u001B[39m (j \u001B[38;5;241m%\u001B[39m AUGMENT_SIZE)][\u001B[38;5;241m0\u001B[39m]][\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[0;32m---> 99\u001B[0m negatives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([data[samples[i \u001B[38;5;241m+\u001B[39m (j \u001B[38;5;241m%\u001B[39m AUGMENT_SIZE)][\u001B[38;5;241m1\u001B[39m]][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[1;32m    101\u001B[0m anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(anchors, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    102\u001B[0m positives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(positives, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn [45], line 99\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     97\u001B[0m anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([data[samples[i \u001B[38;5;241m+\u001B[39m (j \u001B[38;5;241m%\u001B[39m AUGMENT_SIZE)][\u001B[38;5;241m0\u001B[39m]][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[1;32m     98\u001B[0m positives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([getRandomTransformation(data[samples[i \u001B[38;5;241m+\u001B[39m (j \u001B[38;5;241m%\u001B[39m AUGMENT_SIZE)][\u001B[38;5;241m0\u001B[39m]][\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[0;32m---> 99\u001B[0m negatives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mAUGMENT_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(AUGMENT_SIZE \u001B[38;5;241m*\u001B[39m BATCH_SIZE)])\n\u001B[1;32m    101\u001B[0m anchors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(anchors, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    102\u001B[0m positives \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(positives, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/data/swarmset.py:103\u001B[0m, in \u001B[0;36mSwarmDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[1;32m    102\u001B[0m     folder \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdir, \u001B[38;5;28mstr\u001B[39m(index))\n\u001B[0;32m--> 103\u001B[0m     image \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbehavior.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mL\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    104\u001B[0m     context_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontext.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(context_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/.env/lib/python3.10/site-packages/PIL/Image.py:901\u001B[0m, in \u001B[0;36mImage.convert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39mPalette\u001B[38;5;241m.\u001B[39mWEB, colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[1;32m    858\u001B[0m ):\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    860\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    898\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    903\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    905\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/research/SwarmNoveltyNetwork/.env/lib/python3.10/site-packages/PIL/ImageFile.py:257\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    251\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[1;32m    252\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage file is truncated \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    253\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(b)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m bytes not processed)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    254\u001B[0m         )\n\u001B[1;32m    256\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 257\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "\n",
    "PRETRAINING = True\n",
    "target = 0.0001\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr_series=[1e-4, 1e-4, 1e-4], learning_decay=0.95, decay_step=3, threshold=11.0, weight_decay=1e-4, new_model=True)\n",
    "ensemble.load_ensemble(\"full-mini-A\")\n",
    "sampled_dataset = SwarmDataset(\"data/full-mini\", rank=0)\n",
    "\n",
    "def resizeInput(X, w=200):\n",
    "    frame = X.astype(np.uint8)\n",
    "    resized = cv2.resize(frame, dsize=(w, w), interpolation=cv2.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def translate(img, offset=(10, 10)):\n",
    "    h, w = img.shape\n",
    "    xoff, yoff = offset\n",
    "    if xoff < 0: xpadding = (0, -xoff)\n",
    "    else: xpadding = (xoff, 0)\n",
    "    if yoff < 0: ypadding = (0, -yoff)\n",
    "    else: ypadding = (yoff, 0)\n",
    "    img = np.pad(img, (xpadding, ypadding))\n",
    "\n",
    "    if xoff >= 0 and yoff >= 0:\n",
    "        return img[:w, :w]\n",
    "    elif xoff < 0 and yoff >= 0:\n",
    "        return img[-w:, :w]\n",
    "    elif xoff >= 0 and yoff < 0:\n",
    "        return img[:w, -w:]\n",
    "    return img[-w:, -w:]\n",
    "\n",
    "def zoom_at(img, zoom, coord=None):\n",
    "    # Adapted from https://stackoverflow.com/questions/69050464/zoom-into-image-with-opencv\n",
    "    h, w = [ zoom * i for i in img.shape ]\n",
    "    if coord is None: cx, cy = w/2, h/2\n",
    "    else: cx, cy = [ zoom*c for c in coord ]\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[ int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "               int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "def getRandomTransformation(image):\n",
    "    transformation_choices = [\"Rotation\", \"Blur\", \"Zoom\", \"Translate\"]\n",
    "    weights = [0.5, 0.3, 0.0, 0.2]\n",
    "    # weights = [1.0, 0.0, 0.0, 0.0]\n",
    "    choice = random.choices(transformation_choices, weights, k=1)[0]\n",
    "    if choice == \"Rotation\":\n",
    "        theta = random.choice([90, 180, 270])\n",
    "        return ndimage.rotate(image, theta)\n",
    "    elif choice == \"Blur\":\n",
    "        blur = random.choice([0.5, 1.0, 1.5])\n",
    "        return ndimage.gaussian_filter(image, sigma=blur)\n",
    "    elif choice == \"Zoom\":\n",
    "        # zoom = random.choice([1.06, 1.12, 1.18])\n",
    "        padding = random.choice([10])\n",
    "        padded = np.pad(image, padding, mode='constant')\n",
    "        return resizeInput(padded, 50)\n",
    "    elif choice == \"Translate\":\n",
    "        # offsets = [i for i in range(-10, 10, 2)]\n",
    "        # offset = (random.choice(offsets), random.choice(offsets))\n",
    "        offset = (2, 2)\n",
    "        return translate(image, offset)\n",
    "\n",
    "def pretraining(data, ensemble, data_cutoff=None, data_size=500):\n",
    "    if data_cutoff is None:\n",
    "        data_cutoff = len(data) - 1\n",
    "    # np.random.seed(0)\n",
    "    samples = np.random.random_integers(0, data_cutoff, (data_size, 2))\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "    total_updates = 0\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "    pull_set = [k for k in range(len(samples))]\n",
    "    random.shuffle(pull_set)\n",
    "    for index in range(0, len(pull_set), BATCH_SIZE):\n",
    "        i = pull_set[index]\n",
    "        if total_updates % 20 == 0:\n",
    "            print(f\"Unsupervised Training.. {(total_updates * BATCH_SIZE * 100) / data_size}\")\n",
    "\n",
    "        AUGMENT_SIZE = 1\n",
    "        if i + (BATCH_SIZE * AUGMENT_SIZE) >= len(pull_set):\n",
    "            continue\n",
    "\n",
    "        temp_losses = np.array([0.0 for _ in ensemble.ensemble])\n",
    "\n",
    "        anchors = np.array([data[samples[i + (j % AUGMENT_SIZE)][0]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        positives = np.array([getRandomTransformation(data[samples[i + (j % AUGMENT_SIZE)][0]][0]) for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "        negatives = np.array([data[samples[i + (j % AUGMENT_SIZE)][1]][0] for j in range(AUGMENT_SIZE * BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        temp_losses += losses\n",
    "\n",
    "        total_loss += temp_losses\n",
    "        total_updates += 1\n",
    "\n",
    "    return total_loss, total_updates\n",
    "\n",
    "t_1 = time.time()\n",
    "if PRETRAINING:\n",
    "    epochs = 0\n",
    "    loss_history = []\n",
    "    while loss > target:\n",
    "        losses, total_updates = pretraining(sampled_dataset, ensemble, data_cutoff=None, data_size=2000)\n",
    "        average_loss = losses / total_updates\n",
    "        lr = ensemble.evaluate_lr(average_loss)\n",
    "        locale_loss = sum(average_loss) / len(average_loss)\n",
    "        loss_history.append(locale_loss)\n",
    "        loss = (sum(loss_history[-3:]) / 3) if len(loss_history) > 3 else 50\n",
    "        print(f\"LR: {lr}\")\n",
    "        print(f\"Losses: {average_loss}\")\n",
    "        print(f\"Epoch {epochs}, loss: {locale_loss}, windowed_loss: {loss}\")\n",
    "        epochs += 1\n",
    "\n",
    "print(f\"Total Pre-training Time: {time.time() - t_1}\")\n",
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [11.54286151 11.83442778 12.2440053 ], LR: [[0.0015], [0.0015], [0.0015]], Loss: 11.873764862219494\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [10.03131055 10.08217909 10.07937417], LR: [[0.0015], [0.0015], [0.0015]], Loss: 10.064287937482199\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [9.55167725 9.97975469 9.74495038], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.75879410425822\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [9.71152709 9.95000814 9.47615086], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.712562029361726\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [ 9.33350379 10.01450524  9.46293617], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.603648402690887\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [9.09710578 9.9947085  8.80587229], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.299228858153027\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.91026346 9.93509552 9.16031048], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.335223155021668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.40066546 9.92950411 8.87925193], LR: [[0.0015], [0.0015], [0.0015]], Loss: 9.06980716784795\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.64950223 9.92057007 8.2323114 ], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.934127903779348\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.25686075 9.97247553 8.71675787], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.982031385103863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [ 7.70013315 10.00120161  8.18092563], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.627420132160188\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.12822819 9.97619547 8.60479373], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.903072460889817\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.05902464 9.87593992 7.47488219], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.469948918819426\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [7.43787046 9.8785648  6.96576973], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.094068327744802\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [7.50198532 9.94169431 7.00908328], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.150920967062314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [7.75968551 9.94537359 6.90227356], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.20244422107935\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [8.0155704  9.97623401 7.03152498], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.341109794538157\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [7.45088198 9.97293859 6.59897108], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.00759721716245\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [ 7.41986846 10.03413103  6.89673871], LR: [[0.0015], [0.0015], [0.0015]], Loss: 8.116912733217081\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [7.01900979 9.87267232 6.77253819], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.888073434829711\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.75211152 9.90436475 6.10641381], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.587630023901972\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.84182326 9.96503257 6.53013845], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.778998093927901\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.60221964 9.87453487 6.25555417], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.57743622769912\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [ 6.61524423 10.0143615   5.67933995], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.436315227349599\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.05512802 9.92812652 5.64197248], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.208409004497031\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.46452467 9.92842177 5.63036863], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.3411050231009725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.04868072 9.88512778 6.05260224], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.32880357970794\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.85153017 9.97711331 5.66931113], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.1659848711888\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.71714169 9.90998143 5.93541486], LR: [[0.0015], [0.0015], [0.0015]], Loss: 7.187512661119302\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.17634177 9.91243326 5.13218629], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.740320438724011\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.47215611 9.98466002 5.06872254], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.8418462212321645\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.18910736 9.66770233 5.42388403], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.760231236442923\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [6.00550227 9.68973694 5.19079848], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.962012565607826\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.9230442  9.61075416 5.17789245], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.903896935159961\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.19140284 8.62065623 4.46104732], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.091035462617874\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.04267646 9.3334226  5.33882548], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.571641515096029\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.11620723 8.75962962 4.77230551], LR: [[0.0015], [0.0015], [0.0015]], Loss: 6.2160474531725045\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.12174833 8.64686213 5.26316168], LR: [[0.0015], [0.0015], [0.00135]], Loss: 6.343924048667152\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.37080814 8.39948611 4.79166438], LR: [[0.00135], [0.0015], [0.00135]], Loss: 6.187319543361664\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.42898299 8.1489195  5.14903633], LR: [[0.00135], [0.0015], [0.00135]], Loss: 5.90897960462297\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.58388237 7.9007268  4.17938498], LR: [[0.00135], [0.0015], [0.00135]], Loss: 5.5546647169627255\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [5.15503706 7.68190894 4.7954903 ], LR: [[0.00135], [0.0015], [0.00135]], Loss: 5.877478765261671\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.39680599 6.87344503 4.78334437], LR: [[0.00135], [0.0015], [0.00135]], Loss: 5.351198460410039\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.45101414 6.80579298 4.67555413], LR: [[0.00135], [0.0015], [0.00135]], Loss: 5.31078708315889\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.60101609 7.17436835 4.01219123], LR: [[0.0012150000000000002], [0.0015], [0.00135]], Loss: 5.262525220972797\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.55802324 7.44657398 4.35004481], LR: [[0.0012150000000000002], [0.0015], [0.00135]], Loss: 5.45154734581088\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.32874249 6.62375756 5.93277549], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 5.628425180216631\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.69763012 6.70571937 4.23862952], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 4.880659667326448\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.09107905 6.63479654 4.0612635 ], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 4.92904636570563\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.74272164 6.45683231 4.85752161], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 5.352358520080646\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.38370491 5.83035251 4.41289438], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 4.542317263775815\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.64369799 6.76714124 4.58408549], LR: [[0.0012150000000000002], [0.0015], [0.0012150000000000002]], Loss: 4.998308237751286\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [4.25461501 6.06023707 3.74138995], LR: [[0.0010935], [0.0015], [0.0012150000000000002]], Loss: 4.6854140070453285\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.4551205  5.73239618 4.14445882], LR: [[0.0010935], [0.0015], [0.0012150000000000002]], Loss: 4.44399183334317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.88480191 5.8405744  3.99842857], LR: [[0.0010935], [0.0015], [0.0012150000000000002]], Loss: 4.574601625222713\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.27053207 5.42149493 3.75576358], LR: [[0.0010935], [0.0015], [0.0012150000000000002]], Loss: 4.149263526110444\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.70948059 5.68573786 4.14493096], LR: [[0.0010935], [0.0015], [0.0010935]], Loss: 4.51338313623642\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.626628   5.30912435 4.07287153], LR: [[0.0010935], [0.0015], [0.0010935]], Loss: 4.336207961241404\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.42357413 5.02469477 4.35700566], LR: [[0.0010935], [0.0015], [0.0010935]], Loss: 4.268424851885065\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.91291634 5.31530852 4.00206083], LR: [[0.0010935], [0.0015], [0.0010935]], Loss: 4.076761898212134\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.30076015 5.17062823 3.76513443], LR: [[0.0010935], [0.0015], [0.0010935]], Loss: 4.0788409344106915\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.17238566 5.39437147 3.23948217], LR: [[0.0010935], [0.00135], [0.0010935]], Loss: 3.9354130992169183\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.33012556 4.98889438 2.82368205], LR: [[0.00098415], [0.00135], [0.0010935]], Loss: 3.7142339929255344\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.20146038 4.87352396 3.56130013], LR: [[0.00098415], [0.00135], [0.0010935]], Loss: 3.878761489043633\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.84350486 4.78864308 3.28751671], LR: [[0.00098415], [0.00135], [0.0010935]], Loss: 3.639888216747592\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.80057346 4.1224886  3.35556485], LR: [[0.00098415], [0.00135], [0.0010935]], Loss: 3.4262089713041974\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.03077868 4.62520623 3.568857  ], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.7416139719883597\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.30067201 4.3782106  3.50032171], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.72640144108329\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.06879189 4.48028517 3.28604113], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.6117060637349887\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.94382322 6.38195228 3.47630174], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 4.267359081249064\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.92426746 4.65289866 3.12784415], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.568336756260445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.92097321 4.93649213 3.13845053], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.665305287422767\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.69004983 4.61068381 3.55357352], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.6181023877051977\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.59651831 4.30163208 3.00846003], LR: [[0.00098415], [0.00135], [0.00098415]], Loss: 3.302203474417329\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.63017923 4.47565468 2.65194955], LR: [[0.00098415], [0.0012150000000000002], [0.00098415]], Loss: 3.2525944861521325\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.34478259 4.03771047 2.64804261], LR: [[0.00098415], [0.0012150000000000002], [0.00098415]], Loss: 3.010178556796163\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.5242128  4.23873296 2.94962981], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 3.2375251938092213\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.06283649 4.1937265  2.95461918], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 3.4037273921072484\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.58745978 3.44915217 1.9972883 ], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 2.677966749928892\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.16306699 4.24984894 2.837409  ], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 3.083441641703248\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.37921894 4.20192327 2.79589123], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 3.1256778121801716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [3.03481497 3.89136136 2.67348453], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 3.199886952359229\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.32244248 3.28978539 2.70312349], LR: [[0.000885735], [0.0012150000000000002], [0.000885735]], Loss: 2.7717837889461467\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.4766448  3.36718237 2.42341238], LR: [[0.0007971615000000001], [0.0012150000000000002], [0.000885735]], Loss: 2.755746517398705\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.25402189 3.37939122 2.37361153], LR: [[0.0007971615000000001], [0.0010935], [0.000885735]], Loss: 2.6690082130332784\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.00158565 3.49268187 2.11618589], LR: [[0.0007971615000000001], [0.0010935], [0.000885735]], Loss: 2.536817804076709\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.4753462  3.16330879 2.96356701], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.867407337681701\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.36821252 3.60475715 2.59079988], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.854589849673211\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.33415858 3.03660118 3.12512448], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.8319614144911376\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.42265097 3.85803213 2.50294599], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.9278763614781202\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.09021344 3.56760898 2.64065548], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.7661593012015024\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.3684244  3.54469069 2.74874265], LR: [[0.0007971615000000001], [0.0010935], [0.0007971615000000001]], Loss: 2.8872859172088408\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.55687193 2.96307101 2.66299362], LR: [[0.00071744535], [0.0010935], [0.0007971615000000001]], Loss: 2.727645520654818\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.90266024 3.50346654 1.97704125], LR: [[0.00071744535], [0.00098415], [0.0007971615000000001]], Loss: 2.4610560109862125\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.89871858 3.2671367  2.54458144], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.5701455713482573\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.0351099  2.59596841 2.07584516], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.235641157180071\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.26974385 3.00184445 2.83311837], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.7015688936797475\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.12692432 3.42303717 1.68626431], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.4120752674154935\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.07437557 2.89708109 2.60796225], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.5264729719081274\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.15768942 3.11163545 2.47374877], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.581024547166501\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.79240529 2.82045231 1.99722674], LR: [[0.00071744535], [0.00098415], [0.00071744535]], Loss: 2.2033614470716567\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.91794256 2.84497732 2.15952952], LR: [[0.000645700815], [0.000885735], [0.00071744535]], Loss: 2.307483134184343\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.88871912 2.96803254 2.61135567], LR: [[0.000645700815], [0.000885735], [0.000645700815]], Loss: 2.4893691077285136\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.07032304 2.62166202 2.03771012], LR: [[0.000645700815], [0.000885735], [0.000645700815]], Loss: 2.243231727362533\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.32047134 2.78517985 2.15371129], LR: [[0.000645700815], [0.000885735], [0.000645700815]], Loss: 2.086454159468412\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.94499674 3.22982274 2.55015228], LR: [[0.000645700815], [0.000885735], [0.000645700815]], Loss: 2.574990586829372\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.49842109 2.38206149 1.7583593 ], LR: [[0.000645700815], [0.000885735], [0.000645700815]], Loss: 1.8796139591559768\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.62245005 2.40396761 2.33642098], LR: [[0.000645700815], [0.0007971615000000001], [0.000645700815]], Loss: 2.1209462143046163\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.62672251 2.590907   1.83218592], LR: [[0.0005811307335], [0.0007971615000000001], [0.000645700815]], Loss: 2.016605141106993\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.35750334 2.80242343 1.59791403], LR: [[0.0005811307335], [0.0007971615000000001], [0.000645700815]], Loss: 1.9192802668424944\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.36403119 2.09281765 1.7188988 ], LR: [[0.0005811307335], [0.0007971615000000001], [0.0005811307335]], Loss: 1.725249216283361\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.98851867 2.07250864 2.11149799], LR: [[0.0005811307335], [0.0007971615000000001], [0.0005811307335]], Loss: 2.0575084295940664\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.39431165 2.76572861 2.12879844], LR: [[0.0005811307335], [0.0007971615000000001], [0.0005811307335]], Loss: 2.0962795643415304\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.80119682 2.20569364 2.18169115], LR: [[0.0005811307335], [0.0007971615000000001], [0.0005811307335]], Loss: 2.0628605362648766\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.93276563 2.03203989 1.89329348], LR: [[0.0005230176601500001], [0.0007971615000000001], [0.0005811307335]], Loss: 1.9526996680845816\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.65606067 2.61049319 1.6773993 ], LR: [[0.0005230176601500001], [0.00071744535], [0.0005811307335]], Loss: 1.9813177191310871\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.59062243 2.52077847 2.23164716], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 2.11434935218965\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.53422565 2.751429   1.68482592], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 1.990160188861191\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.80058371 2.49560208 1.7080004 ], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 2.0013953971366085\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [2.08631592 2.30140253 1.6834305 ], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 2.0237163161455345\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.68565202 2.09827977 1.91019165], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 1.898041147496551\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.37796267 1.78944829 1.58634154], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 1.5845841658208517\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.42201934 2.38100474 1.43994515], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 1.7476564074804386\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.97580019 2.29060153 1.75450818], LR: [[0.0005230176601500001], [0.00071744535], [0.0005230176601500001]], Loss: 1.6736366288426023\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.59216743 2.29754242 1.86989413], LR: [[0.00047071589413500006], [0.00071744535], [0.00047071589413500006]], Loss: 1.9198679975420234\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.49846895 2.34171928 1.15172239], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.6639702045125888\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.22770532 1.8492935  1.0903212 ], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.3891066715404063\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.19129908 1.54429423 1.88219864], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.5392639843126137\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.29897244 2.01292002 1.73485473], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.682249060397347\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.94809748 2.34467536 1.61516618], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.6359796712175012\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.31103255 2.14995185 1.72262353], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.7278693088221673\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.1728214  2.202728   1.26349637], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.5463485895221432\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.38241837 1.8087298  2.03020638], LR: [[0.00047071589413500006], [0.000645700815], [0.00047071589413500006]], Loss: 1.7404515154426916\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.54475314 2.46011974 1.63097222], LR: [[0.0004236443047215001], [0.0005811307335], [0.00047071589413500006]], Loss: 1.87861503199907\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.86395169 1.59167679 1.40799494], LR: [[0.0004236443047215001], [0.0005811307335], [0.00047071589413500006]], Loss: 1.2878744697809452\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.97297165 1.92916169 1.51947443], LR: [[0.0004236443047215001], [0.0005811307335], [0.0004236443047215001]], Loss: 1.4738692548777907\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.13235301 1.93116933 1.29181288], LR: [[0.0004236443047215001], [0.0005811307335], [0.0004236443047215001]], Loss: 1.4517784076960136\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.33107423 2.19179514 1.50919459], LR: [[0.0004236443047215001], [0.0005811307335], [0.0004236443047215001]], Loss: 1.6773546558451684\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.45524484 2.2845374  1.31511881], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0004236443047215001]], Loss: 1.6849670179498693\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.88075144 1.88847186 1.20425748], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0004236443047215001]], Loss: 1.3244935917885352\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.05072736 1.56687122 1.21148804], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0004236443047215001]], Loss: 1.2763622078920405\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.03086842 1.56721137 1.39555502], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0004236443047215001]], Loss: 1.3312116047429543\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.77919786 1.62051361 1.31828344], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0004236443047215001]], Loss: 1.2393316374719143\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.23581674 1.60732067 1.57931507], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0003812798742493501]], Loss: 1.4741508247563615\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.03432371 1.55281051 1.2095124 ], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0003812798742493501]], Loss: 1.2655488732503726\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.81400273 1.26099069 1.46793318], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0003812798742493501]], Loss: 1.1809755326419449\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.37518281 1.66773938 1.41492531], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0003812798742493501]], Loss: 1.4859491658746264\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.11295788 1.51352183 1.17653997], LR: [[0.0003812798742493501], [0.0005230176601500001], [0.0003812798742493501]], Loss: 1.267673225357818\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.97432469 1.84207943 1.33782262], LR: [[0.0003812798742493501], [0.00047071589413500006], [0.0003812798742493501]], Loss: 1.3847422475319278\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.82496528 1.3606115  1.06751211], LR: [[0.0003812798742493501], [0.00047071589413500006], [0.0003812798742493501]], Loss: 1.0843629641396304\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.69100436 1.70774029 1.28569457], LR: [[0.0003812798742493501], [0.00047071589413500006], [0.0003812798742493501]], Loss: 1.22814640643696\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.820386   1.28098999 0.87536741], LR: [[0.0003431518868244151], [0.00047071589413500006], [0.0003812798742493501]], Loss: 0.9922477959825969\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.29063674 1.26771597 1.19452794], LR: [[0.0003431518868244151], [0.00047071589413500006], [0.0003431518868244151]], Loss: 1.2509602155536415\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.95812014 1.27893046 1.11542689], LR: [[0.0003431518868244151], [0.00047071589413500006], [0.0003431518868244151]], Loss: 1.1174924945427727\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.12593993 1.41549711 1.55663268], LR: [[0.0003431518868244151], [0.00047071589413500006], [0.0003431518868244151]], Loss: 1.3660232417269922\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.98804573 1.48708135 1.06215592], LR: [[0.0003431518868244151], [0.0004236443047215001], [0.0003431518868244151]], Loss: 1.1790943349866818\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.76391489 1.21324786 1.5362973 ], LR: [[0.0003431518868244151], [0.0004236443047215001], [0.0003431518868244151]], Loss: 1.1711533499734166\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.62496227 1.43973829 0.68735583], LR: [[0.0003431518868244151], [0.0004236443047215001], [0.0003431518868244151]], Loss: 0.9173521322570742\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.8778737  1.77857811 1.0505413 ], LR: [[0.0003431518868244151], [0.0004236443047215001], [0.0003431518868244151]], Loss: 1.2356643680731456\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.96835706 0.91287311 0.92667129], LR: [[0.0003088366981419736], [0.0004236443047215001], [0.0003431518868244151]], Loss: 0.9359671541505182\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.626725   1.24790175 1.12716001], LR: [[0.0003088366981419736], [0.0004236443047215001], [0.0003088366981419736]], Loss: 1.0005955888408546\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.36935089 1.59974499 0.66276867], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 1.2106215176459711\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.95802132 1.3395832  0.74943064], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 1.0156783849086302\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.92532541 1.4065413  0.95857099], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 1.0968125656805934\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57250451 1.0713329  0.79034549], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 0.8113943009714907\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.55138256 1.05672206 0.75765832], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 0.7885876487568021\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.85051012 1.33184018 1.19601457], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0003088366981419736]], Loss: 1.1261216243379748\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.43778237 1.05392828 1.22654993], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0002779530283277762]], Loss: 0.9060868591908365\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.51533942 1.42748606 0.71538371], LR: [[0.0003088366981419736], [0.0003812798742493501], [0.0002779530283277762]], Loss: 0.8860697313894829\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.87071148 1.52492326 0.86569379], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 1.0871095120025953\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.45118448 1.44598824 1.35973987], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 1.085637529088029\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.52589611 1.23819952 1.01072599], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 0.9249405405546228\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.73135601 1.36201286 1.39941765], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 1.164262174135074\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.61833152 1.42127805 0.81758659], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 0.9523987185272077\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.00179777 1.41625906 0.63813037], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002779530283277762]], Loss: 1.0187290673951308\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.91953906 1.33824392 0.94688382], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002501577254949986]], Loss: 1.0682222685044205\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57078457 0.97306363 0.79983635], LR: [[0.0002779530283277762], [0.0003431518868244151], [0.0002501577254949986]], Loss: 0.7812281855319937\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.6752726  1.21749077 0.79547446], LR: [[0.0002501577254949986], [0.0003431518868244151], [0.0002501577254949986]], Loss: 0.8960792763593295\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.49643053 1.12154599 0.65115192], LR: [[0.0002501577254949986], [0.0003431518868244151], [0.0002501577254949986]], Loss: 0.7563761457738778\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.73427806 0.87678155 0.7767692 ], LR: [[0.0002501577254949986], [0.0003431518868244151], [0.0002501577254949986]], Loss: 0.7959429354344806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.5061904  0.97187401 1.02105795], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.0002501577254949986]], Loss: 0.8330407835155104\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.5932032  1.06859195 0.80858414], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.0002501577254949986]], Loss: 0.8234597662122299\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.64591654 0.93001403 0.90830149], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.0002501577254949986]], Loss: 0.8280773510923609\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.63171672 0.69480159 0.50890517], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.0002501577254949986]], Loss: 0.611807826096192\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.59644296 1.06362556 0.43832942], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.0002501577254949986]], Loss: 0.6994659771335622\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57883949 1.03249747 0.7326754 ], LR: [[0.0002501577254949986], [0.0003088366981419736], [0.00022514195294549873]], Loss: 0.7813374540147683\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.58294992 1.25537614 0.71474046], LR: [[0.00022514195294549873], [0.0003088366981419736], [0.00022514195294549873]], Loss: 0.8510221733103389\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.74304484 0.89178502 0.73811059], LR: [[0.00022514195294549873], [0.0003088366981419736], [0.00022514195294549873]], Loss: 0.7909801490193544\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.70990268 0.77827824 0.56384688], LR: [[0.00022514195294549873], [0.0003088366981419736], [0.00022514195294549873]], Loss: 0.6840092686105829\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.52453354 0.91033056 0.81734794], LR: [[0.00022514195294549873], [0.0002779530283277762], [0.00022514195294549873]], Loss: 0.7507373452434938\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.50897214 0.84664686 0.78566562], LR: [[0.00022514195294549873], [0.0002779530283277762], [0.00022514195294549873]], Loss: 0.7137615401033933\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.56313467 0.6306685  0.52616754], LR: [[0.00022514195294549873], [0.0002779530283277762], [0.00022514195294549873]], Loss: 0.5733235702989623\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.37466626 0.82773404 0.88298877], LR: [[0.00022514195294549873], [0.0002779530283277762], [0.00022514195294549873]], Loss: 0.6951296921571096\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.39727828 0.67806322 0.41793133], LR: [[0.00022514195294549873], [0.0002779530283277762], [0.00022514195294549873]], Loss: 0.49775761050793027\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.5302191  0.89765231 0.54314314], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.6570048468622068\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.51238713 0.99880634 0.58985232], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.7003485972713679\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.54897205 0.94702383 0.47048544], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.6554937717070183\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.67954917 0.84853838 0.86319819], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.7970952446099061\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29443023 0.68613019 0.90763575], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.6293987216831495\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.38116526 0.60555624 0.59319271], LR: [[0.00020262775765094885], [0.0002779530283277762], [0.00020262775765094885]], Loss: 0.5266380706988275\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.43845921 1.02938007 0.60755837], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.6917992147368689\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.43813789 0.87261246 0.45633366], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.5890280028820659\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.82797116 0.73060832 0.65632272], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.7383007311541587\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.60850489 0.68266121 0.52752581], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.6062306386484609\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.59596274 0.66473212 0.73154776], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.6640808724425732\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.51516189 1.14545256 0.94797281], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.869529086908636\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.76012626 0.85372382 0.86160479], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.8251516207059225\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.45876396 0.76183924 0.68032126], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00018236498188585397]], Loss: 0.6336414898062747\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.52655948 0.52845776 0.74779102], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.6009360861902436\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.50184047 0.86476812 0.59240888], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.6530058243364328\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32871064 0.65106779 0.42942344], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.4697339524476168\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22274256 0.41645261 0.45245868], LR: [[0.00018236498188585397], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.36388461588164017\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.4907559  0.62919574 0.61861731], LR: [[0.00016412848369726858], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.5795229824321966\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.54874067 0.61688752 0.48481245], LR: [[0.00016412848369726858], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.5501468792743981\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.46226645 0.528048   0.58795387], LR: [[0.00016412848369726858], [0.0002501577254949986], [0.00016412848369726858]], Loss: 0.5260894375139227\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57190347 0.57959581 0.42647967], LR: [[0.00016412848369726858], [0.00022514195294549873], [0.00016412848369726858]], Loss: 0.5259929808058466\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.23483987 0.4817597  0.36730159], LR: [[0.00016412848369726858], [0.00022514195294549873], [0.00016412848369726858]], Loss: 0.36130038546149684\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18250362 0.56102317 0.15179276], LR: [[0.00016412848369726858], [0.00022514195294549873], [0.00016412848369726858]], Loss: 0.29843984806211665\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20777516 0.77526499 0.30193093], LR: [[0.00016412848369726858], [0.00022514195294549873], [0.00014771563532754172]], Loss: 0.42832369294638434\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.47844019 0.55618538 0.7588335 ], LR: [[0.00014771563532754172], [0.00022514195294549873], [0.00014771563532754172]], Loss: 0.5978196903007725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.697957   0.60614994 0.71466763], LR: [[0.00014771563532754172], [0.00022514195294549873], [0.00014771563532754172]], Loss: 0.672924856475244\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19145205 0.56566519 0.65341204], LR: [[0.00014771563532754172], [0.00022514195294549873], [0.00014771563532754172]], Loss: 0.47017642417301736\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.36611161 0.61629185 0.75185091], LR: [[0.00014771563532754172], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.5780847880554696\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18440874 0.75476617 0.48772078], LR: [[0.00014771563532754172], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.47563189937733114\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19950526 0.68903784 0.43401215], LR: [[0.00014771563532754172], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.44085174739360805\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.53562438 0.88417137 0.25577111], LR: [[0.00013294407179478756], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.5585222878058751\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32336155 0.51437925 0.57049731], LR: [[0.00013294407179478756], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.46941270134101315\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.48974881 0.80414517 0.35363246], LR: [[0.00013294407179478756], [0.00020262775765094885], [0.00014771563532754172]], Loss: 0.5491754795207332\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.58674818 0.44458158 0.58527416], LR: [[0.00013294407179478756], [0.00020262775765094885], [0.00013294407179478756]], Loss: 0.5388679733530929\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26364786 0.44569767 0.39334353], LR: [[0.00013294407179478756], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.36756302297115323\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.34851881 0.64345165 0.43056689], LR: [[0.00013294407179478756], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.47417911774013194\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17433115 0.39148327 0.61999251], LR: [[0.00013294407179478756], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.3952689764128688\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26252093 0.38677828 0.49324124], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.3808468166366219\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24638203 0.64138838 0.36388025], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.41721688601110757\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20149843 0.59096921 0.24066355], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.34437706699284415\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.34088567 0.24466125 0.49037962], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.3586421797300378\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.33544576 0.63802285 0.237044  ], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.00013294407179478756]], Loss: 0.40350420107133694\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.40620984 0.60972897 0.29427273], LR: [[0.0001196496646153088], [0.00018236498188585397], [0.0001196496646153088]], Loss: 0.43673717910656706\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29265143 0.68211728 0.53281155], LR: [[0.0001196496646153088], [0.00016412848369726858], [0.0001196496646153088]], Loss: 0.5025267547306915\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.232959   0.57077571 0.64722495], LR: [[0.0001196496646153088], [0.00016412848369726858], [0.0001196496646153088]], Loss: 0.48365322154015306\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26869797 0.71680942 0.1263296 ], LR: [[0.0001196496646153088], [0.00016412848369726858], [0.0001196496646153088]], Loss: 0.3706123321596533\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29588403 0.3644359  0.23913298], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.0001196496646153088]], Loss: 0.29981763871386646\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.30451909 0.2443541  0.33140811], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.29342709813577433\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.31583848 0.66929496 0.5174139 ], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.5008491119245688\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.55479328 0.50924972 0.78389185], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.6159782800730317\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.44647436 0.24497363 0.28590512], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.325784370303154\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1868538  0.55221886 0.63016125], LR: [[0.00010768469815377792], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.45641130485339093\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.41601213 0.50209419 0.2975129 ], LR: [[9.691622833840013e-05], [0.00016412848369726858], [0.00010768469815377792]], Loss: 0.40520640363295873\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.34111917 0.29149375 0.30935915], LR: [[9.691622833840013e-05], [0.00016412848369726858], [9.691622833840013e-05]], Loss: 0.313990687354235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13684331 0.22107818 0.14544108], LR: [[9.691622833840013e-05], [0.00016412848369726858], [9.691622833840013e-05]], Loss: 0.167787523806716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10119149 0.35516767 0.36318472], LR: [[9.691622833840013e-05], [0.00014771563532754172], [9.691622833840013e-05]], Loss: 0.27318129195366053\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.37867751 0.3709283  0.39604211], LR: [[9.691622833840013e-05], [0.00014771563532754172], [9.691622833840013e-05]], Loss: 0.3818826401163824\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12511534 0.42257083 0.28038488], LR: [[9.691622833840013e-05], [0.00014771563532754172], [9.691622833840013e-05]], Loss: 0.2760236844719232\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.31911369 0.21465445 0.42621758], LR: [[9.691622833840013e-05], [0.00014771563532754172], [9.691622833840013e-05]], Loss: 0.31999524171774585\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.36332899 0.25312645 0.16573363], LR: [[9.691622833840013e-05], [0.00014771563532754172], [9.691622833840013e-05]], Loss: 0.2607296904424826\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.45375322 0.45982422 0.50765623], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.4737445573105166\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57744017 0.5099448  0.4179614 ], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.5017821216645341\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18267836 0.38705018 0.28262772], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.28411875523626806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.33381836 0.41801172 0.24337438], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.33173482105446356\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32025487 0.52826967 0.33925593], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.39592682537894386\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.28840236 0.42926795 0.26086273], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.32617767883464693\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.42056654 0.33049885 0.38762383], LR: [[8.722460550456011e-05], [0.00013294407179478756], [8.722460550456011e-05]], Loss: 0.3795630729633073\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26626977 0.40189371 0.40997601], LR: [[8.722460550456011e-05], [0.0001196496646153088], [8.722460550456011e-05]], Loss: 0.35937983156957976\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.42773227 0.31263609 0.55567577], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.43201470864781494\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18714579 0.52736385 0.25120379], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.32190447380145387\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10057723 0.26519462 0.05924478], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.14167220899214347\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20903756 0.28893507 0.24433779], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.24743680727357664\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.34381067 0.45529761 0.32041649], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.37317492319115747\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08890281 0.23013119 0.4013731 ], LR: [[7.85021449541041e-05], [0.0001196496646153088], [7.85021449541041e-05]], Loss: 0.24013570089514058\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.35117653 0.29375266 0.49487118], LR: [[7.85021449541041e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.37993345575009396\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22874248 0.23905724 0.33100667], LR: [[7.85021449541041e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.26626879412525645\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.33976981 0.40152595 0.32949843], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.3569313991721719\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.28336872 0.35282925 0.26020229], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.29880008685247356\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32452633 0.27907016 0.3447152 ], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.31610389722821614\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.57182429 0.25102645 0.37999942], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.40095005308898785\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.28164115 0.41855292 0.11892207], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.2730387134461974\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18239126 0.15871784 0.4343896 ], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.25849956656495726\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24495539 0.25182982 0.28166307], LR: [[7.06519304586937e-05], [0.00010768469815377792], [7.06519304586937e-05]], Loss: 0.25948276094316197\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08851592 0.17959036 0.31705458], LR: [[7.06519304586937e-05], [0.00010768469815377792], [6.358673741282432e-05]], Loss: 0.195053618621702\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29846539 0.23074068 0.19443325], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.24121310781377056\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18876097 0.19170811 0.12362815], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.16803240888984874\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.33608774 0.19953048 0.29279354], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.27613725290323293\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21412565 0.34143859 0.15929185], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.23828536551756163\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1474632  0.21897827 0.36752669], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.2446560526608179\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14761416 0.13109456 0.05930502], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.11267124529462309\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1612809  0.2445587  0.27000575], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.22528178380957495\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03940216 0.08378739 0.08698135], LR: [[6.358673741282432e-05], [9.691622833840013e-05], [6.358673741282432e-05]], Loss: 0.0700569689863672\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13399419 0.32108865 0.24807606], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.23438629780119904\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.246204   0.20784169 0.08631361], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.18011976626391213\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.27469425 0.15261288 0.14611836], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.19114183101492624\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.27275202 0.24228588 0.32773406], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.2809239852024863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22826626 0.29600375 0.14199624], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.2220887504890561\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13388894 0.1670141  0.06360527], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.12150276974842807\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19037973 0.42387276 0.42557003], LR: [[5.722806367154189e-05], [8.722460550456011e-05], [5.722806367154189e-05]], Loss: 0.3466075061820448\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22342633 0.44539062 0.66065962], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.44315885900209345\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1583989  0.26147129 0.1927894 ], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.20421986093744635\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24601403 0.20543125 0.31902547], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.2568235853128135\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06529449 0.27911244 0.55052809], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.29831167286261917\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19754495 0.2881807  0.2019288 ], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.2292181512709552\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.31021123 0.09615657 0.34297742], LR: [[5.1505257304387705e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.24978173995700978\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.40097117 0.14130722 0.3155822 ], LR: [[4.635473157394894e-05], [7.85021449541041e-05], [5.1505257304387705e-05]], Loss: 0.28595352889504283\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.37604301 0.28423242 0.25759275], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [5.1505257304387705e-05]], Loss: 0.30595606188910707\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13227129 0.24999304 0.15748981], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [5.1505257304387705e-05]], Loss: 0.17991804697628444\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10375676 0.2563823  0.22542726], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.19518877544595548\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0355114  0.13627675 0.23723615], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.13634143370358895\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11010559 0.06357982 0.2111017 ], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.1282623705267906\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1507346  0.36550863 0.14460158], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.22028160264521532\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17636455 0.18344063 0.30711294], LR: [[4.635473157394894e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.2223060389383075\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21299449 0.11372902 0.25109141], LR: [[4.171925841655404e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.19260497553894917\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.23929846 0.29941329 0.07317246], LR: [[4.171925841655404e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.20396140022513765\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32910988 0.25746852 0.24963366], LR: [[4.171925841655404e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.27873735459521415\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09794718 0.109461   0.04460729], LR: [[4.171925841655404e-05], [7.06519304586937e-05], [4.635473157394894e-05]], Loss: 0.08400515681016259\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07783416 0.24561177 0.22658233], LR: [[4.171925841655404e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.18334275469028702\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07152316 0.20510154 0.30705465], LR: [[4.171925841655404e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.19455978425219655\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21954853 0.16817911 0.1151836 ], LR: [[4.171925841655404e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.16763708089788754\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04267468 0.13082089 0.15828545], LR: [[4.171925841655404e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.11059367642078238\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10293059 0.0838177  0.49374861], LR: [[3.754733257489864e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.2268322996996964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11972843 0.14285637 0.30133775], LR: [[3.754733257489864e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.18797418531030416\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20234401 0.24549517 0.18599183], LR: [[3.754733257489864e-05], [6.358673741282432e-05], [4.171925841655404e-05]], Loss: 0.21127700408920647\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17281299 0.21124524 0.19968052], LR: [[3.754733257489864e-05], [6.358673741282432e-05], [3.754733257489864e-05]], Loss: 0.19457958474444847\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18002954 0.14590109 0.16549401], LR: [[3.754733257489864e-05], [6.358673741282432e-05], [3.754733257489864e-05]], Loss: 0.16380821564545234\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26178502 0.26574995 0.09049832], LR: [[3.379259931740878e-05], [6.358673741282432e-05], [3.754733257489864e-05]], Loss: 0.20601109633843104\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11246227 0.11755659 0.16760729], LR: [[3.379259931740878e-05], [6.358673741282432e-05], [3.754733257489864e-05]], Loss: 0.1325420497613959\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20256489 0.16526221 0.1086162 ], LR: [[3.379259931740878e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.1588144361025964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.089945   0.09652075 0.38207993], LR: [[3.379259931740878e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.18951522582171795\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20813693 0.29753848 0.27696205], LR: [[3.379259931740878e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.26087915261305167\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25577332 0.19661408 0.29305152], LR: [[3.379259931740878e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.2484796389037122\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.33124069 0.15442197 0.23532069], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.24032778319669887\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21032469 0.25557473 0.12297582], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.19629174609920785\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12501293 0.03758945 0.09917764], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.754733257489864e-05]], Loss: 0.08726000622535746\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1939372  0.31440627 0.269213  ], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.379259931740878e-05]], Loss: 0.2591854895008752\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13362092 0.14612389 0.15097927], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.379259931740878e-05]], Loss: 0.14357469451303284\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10809806 0.11030359 0.37823584], LR: [[3.0413339385667903e-05], [5.722806367154189e-05], [3.379259931740878e-05]], Loss: 0.19887916751826804\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32073033 0.13611276 0.30768181], LR: [[3.0413339385667903e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.2548416317999363\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06498739 0.0706036  0.19742091], LR: [[3.0413339385667903e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.11100396555305149\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12233262 0.07927681 0.17539287], LR: [[3.0413339385667903e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.12566743593042096\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08168681 0.26086994 0.13207068], LR: [[3.0413339385667903e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.15820914344241221\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09454102 0.0164753  0.33912271], LR: [[2.7372005447101112e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.15004634210325699\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1553446  0.29543637 0.15604699], LR: [[2.7372005447101112e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.2022759866838654\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13978892 0.07904962 0.02311844], LR: [[2.7372005447101112e-05], [5.1505257304387705e-05], [3.379259931740878e-05]], Loss: 0.08065232581148545\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2146196  0.14718125 0.09847705], LR: [[2.7372005447101112e-05], [4.635473157394894e-05], [3.379259931740878e-05]], Loss: 0.153425963994038\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14291112 0.29635805 0.22974058], LR: [[2.7372005447101112e-05], [4.635473157394894e-05], [3.0413339385667903e-05]], Loss: 0.2230032521113753\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11895274 0.12794819 0.10057586], LR: [[2.7372005447101112e-05], [4.635473157394894e-05], [3.0413339385667903e-05]], Loss: 0.11582559384716053\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03346322 0.16020973 0.04496489], LR: [[2.7372005447101112e-05], [4.635473157394894e-05], [3.0413339385667903e-05]], Loss: 0.07954594887793064\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13717954 0.21471613 0.25892553], LR: [[2.7372005447101112e-05], [4.635473157394894e-05], [3.0413339385667903e-05]], Loss: 0.2036070683998211\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15303933 0.10232761 0.19372343], LR: [[2.4634804902391e-05], [4.635473157394894e-05], [3.0413339385667903e-05]], Loss: 0.1496967897266101\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07645652 0.20845573 0.08747461], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.12412895495382448\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16228177 0.17291899 0.42256264], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.2525877983619769\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29199073 0.22198029 0.24017955], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.251383521471483\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11361193 0.07378655 0.08063266], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.08934371593718728\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18379282 0.03652494 0.23005894], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.15012556940938035\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0835438  0.10234129 0.16065055], LR: [[2.4634804902391e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.11551187808935841\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24982781 0.11756776 0.06611385], LR: [[2.21713244121519e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.14450313886006674\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05246394 0.02398743 0.04604616], LR: [[2.21713244121519e-05], [4.171925841655404e-05], [3.0413339385667903e-05]], Loss: 0.04083250975701958\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13069418 0.12885431 0.12732838], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.12895895744829128\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25094597 0.04930153 0.14715418], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.14913389276713132\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16639525 0.06238872 0.1507304 ], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.12650479060597716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12402281 0.03354501 0.14101397], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.09952726365687947\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14355732 0.14519139 0.31443479], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.20106116792187093\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09868729 0.07893953 0.09310772], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.09024484824699659\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.047367   0.10904264 0.05098198], LR: [[2.21713244121519e-05], [3.754733257489864e-05], [2.7372005447101112e-05]], Loss: 0.06913054024179777\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08946335 0.21849068 0.20897327], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.1723091005037228\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11022383 0.12233941 0.04644552], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.09300292247595887\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.51937607 0.15501696 0.21900215], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.2977983954075413\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.28225589 0.08489277 0.05312061], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.14008975686583047\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16128456 0.07847205 0.13640144], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.12538601734704571\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29310525 0.09925736 0.05519833], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.14918698015933238\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15417794 0.06589721 0.04202967], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.08736827524825157\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05775577 0.06148164 0.10706025], LR: [[1.995419197093671e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.07543255145971973\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16091675 0.15953628 0.03181909], LR: [[1.795877277384304e-05], [3.379259931740878e-05], [2.4634804902391e-05]], Loss: 0.11742403996603873\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10408846 0.07830691 0.14056104], LR: [[1.795877277384304e-05], [3.379259931740878e-05], [2.21713244121519e-05]], Loss: 0.10765213804785162\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.30478685 0.03536448 0.21650054], LR: [[1.795877277384304e-05], [3.379259931740878e-05], [2.21713244121519e-05]], Loss: 0.18555062290591495\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03020502 0.05774878 0.04540965], LR: [[1.795877277384304e-05], [3.0413339385667903e-05], [2.21713244121519e-05]], Loss: 0.04445448313296462\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26616069 0.06758511 0.06549403], LR: [[1.795877277384304e-05], [3.0413339385667903e-05], [2.21713244121519e-05]], Loss: 0.1330799441660444\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17381283 0.08367677 0.18184905], LR: [[1.795877277384304e-05], [3.0413339385667903e-05], [2.21713244121519e-05]], Loss: 0.14644621361221652\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20893848 0.0635314  0.01225452], LR: [[1.795877277384304e-05], [3.0413339385667903e-05], [2.21713244121519e-05]], Loss: 0.0949081338228037\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10883692 0.01490472 0.3448592 ], LR: [[1.795877277384304e-05], [3.0413339385667903e-05], [1.995419197093671e-05]], Loss: 0.15620028261405725\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.23472662 0.24169822 0.2604864 ], LR: [[1.6162895496458737e-05], [3.0413339385667903e-05], [1.995419197093671e-05]], Loss: 0.24563707884090644\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12586245 0.31099212 0.22768898], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.22151451606613892\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04750991 0.04951961 0.10664498], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.067891500464951\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16058514 0.06156457 0.16097234], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.12770735058312613\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06846491 0.1204263  0.01992636], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.06960585965774953\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14859028 0.20955973 0.19215726], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.18343575498710077\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05604224 0.14972091 0.3212722 ], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.17567845307290555\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07070282 0.08168988 0.05911018], LR: [[1.6162895496458737e-05], [2.7372005447101112e-05], [1.995419197093671e-05]], Loss: 0.0705009587481618\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11255312 0.0979211  0.14157417], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.11734946390924354\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15126779 0.20309165 0.21883657], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.1910653368383646\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15156647 0.06310524 0.09730928], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.10399366390464516\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09713913 0.14102481 0.22223393], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.15346595855701403\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04728688 0.13654737 0.08543274], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.08975566438787307\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22816607 0.11097624 0.10052297], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.795877277384304e-05]], Loss: 0.14655509674921632\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07415048 0.08670911 0.15500946], LR: [[1.4546605946812864e-05], [2.4634804902391e-05], [1.6162895496458737e-05]], Loss: 0.10528968416076774\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18609006 0.11285515 0.06599592], LR: [[1.3091945352131578e-05], [2.4634804902391e-05], [1.6162895496458737e-05]], Loss: 0.12164704070426524\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20001053 0.07750528 0.18220743], LR: [[1.3091945352131578e-05], [2.4634804902391e-05], [1.6162895496458737e-05]], Loss: 0.15324108152339858\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11125416 0.06508719 0.03320976], LR: [[1.3091945352131578e-05], [2.4634804902391e-05], [1.6162895496458737e-05]], Loss: 0.06985037185251712\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14367402 0.08056817 0.17521799], LR: [[1.3091945352131578e-05], [2.21713244121519e-05], [1.6162895496458737e-05]], Loss: 0.13315339188401898\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18377315 0.08174783 0.42842438], LR: [[1.3091945352131578e-05], [2.21713244121519e-05], [1.6162895496458737e-05]], Loss: 0.23131511965300888\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18851549 0.12174875 0.03484431], LR: [[1.178275081691842e-05], [2.21713244121519e-05], [1.6162895496458737e-05]], Loss: 0.1150361814328547\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09595904 0.04816009 0.23661175], LR: [[1.178275081691842e-05], [2.21713244121519e-05], [1.4546605946812864e-05]], Loss: 0.12691029345151036\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09699855 0.13496719 0.20260654], LR: [[1.178275081691842e-05], [2.21713244121519e-05], [1.4546605946812864e-05]], Loss: 0.14485743058825998\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11424401 0.12074661 0.09831157], LR: [[1.178275081691842e-05], [2.21713244121519e-05], [1.4546605946812864e-05]], Loss: 0.11110073167830707\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.27937012 0.16530273 0.17374676], LR: [[1.178275081691842e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.2061398695127961\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07338394 0.04129808 0.04171534], LR: [[1.178275081691842e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.05213245542409519\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03583949 0.03323544 0.00950532], LR: [[1.178275081691842e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.026193416598252955\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14977527 0.1965     0.22548562], LR: [[1.0604475735226578e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.19058696702122688\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21817101 0.02536757 0.07157025], LR: [[1.0604475735226578e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.1050362746306928\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08674407 0.03690079 0.06024626], LR: [[1.0604475735226578e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.061297040622060504\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.23514144 0.10414908 0.30159299], LR: [[1.0604475735226578e-05], [1.995419197093671e-05], [1.4546605946812864e-05]], Loss: 0.21362783609113345\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16200462 0.11728979 0.12933676], LR: [[1.0604475735226578e-05], [1.795877277384304e-05], [1.4546605946812864e-05]], Loss: 0.1362103868213793\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21098498 0.07433306 0.05769793], LR: [[1.0604475735226578e-05], [1.795877277384304e-05], [1.4546605946812864e-05]], Loss: 0.11433865631852919\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04103008 0.06880856 0.10528673], LR: [[1.0604475735226578e-05], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.07170845359719048\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09293465 0.06461877 0.09259194], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.08338178836274891\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17944296 0.03567686 0.23513444], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.15008475397946314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13736221 0.01186484 0.01756839], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.05559847847558558\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07554115 0.04463381 0.2176067 ], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.11259388657364373\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20267266 0.26131647 0.14722222], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.20373711553091803\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.036045   0.11015189 0.15027167], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.09882285371383963\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0433786  0.05880837 0.06278926], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.3091945352131578e-05]], Loss: 0.054992077536880964\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01307968 0.16681172 0.13347528], LR: [[9.544028161703921e-06], [1.795877277384304e-05], [1.178275081691842e-05]], Loss: 0.1044555598770603\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.27221256 0.10583118 0.11649182], LR: [[8.58962534553353e-06], [1.795877277384304e-05], [1.178275081691842e-05]], Loss: 0.16484518595815947\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05341725 0.1167421  0.14152628], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.178275081691842e-05]], Loss: 0.10389520883230337\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1029677  0.10864073 0.05350252], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.178275081691842e-05]], Loss: 0.08837031637415445\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03173648 0.15303982 0.03783228], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.178275081691842e-05]], Loss: 0.07420286024532591\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19158116 0.09454223 0.0619348 ], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.178275081691842e-05]], Loss: 0.11601939817424863\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03663705 0.02271957 0.13743079], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.178275081691842e-05]], Loss: 0.06559580226118365\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13244957 0.09291446 0.16463505], LR: [[8.58962534553353e-06], [1.6162895496458737e-05], [1.0604475735226578e-05]], Loss: 0.1299996922692905\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18158652 0.15852436 0.14360641], LR: [[7.730662810980177e-06], [1.6162895496458737e-05], [1.0604475735226578e-05]], Loss: 0.16123909418005497\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.096301   0.02757175 0.00245393], LR: [[7.730662810980177e-06], [1.6162895496458737e-05], [1.0604475735226578e-05]], Loss: 0.042108893493811285\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01666872 0.089512   0.25882184], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.12166752009962996\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16965071 0.06753241 0.00512749], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.08077020451736946\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07392738 0.08668544 0.27012305], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.1435786264940786\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21852006 0.12409424 0.08920844], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.1439409148755173\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04098027 0.04498306 0.08984117], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.05860150222724769\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.00434541 0.0245359  0.00161938], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [1.0604475735226578e-05]], Loss: 0.010166896851733326\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12838367 0.01985864 0.08027658], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [9.544028161703921e-06]], Loss: 0.07617296252089241\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02720293 0.09838099 0.00580008], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [9.544028161703921e-06]], Loss: 0.043794662570580845\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02149778 0.07826016 0.02204353], LR: [[7.730662810980177e-06], [1.4546605946812864e-05], [9.544028161703921e-06]], Loss: 0.040600490607321266\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12558997 0.03532809 0.07065884], LR: [[6.95759652988216e-06], [1.4546605946812864e-05], [9.544028161703921e-06]], Loss: 0.07719230360739554\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05889402 0.10434981 0.04147746], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [9.544028161703921e-06]], Loss: 0.06824043042104071\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04112033 0.03247081 0.0223987 ], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [9.544028161703921e-06]], Loss: 0.03199661282318023\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11245157 0.05103342 0.04078169], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [9.544028161703921e-06]], Loss: 0.06808889236296332\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1489131  0.03671223 0.02410188], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [9.544028161703921e-06]], Loss: 0.06990907362662256\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07332696 0.02416964 0.00165996], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [9.544028161703921e-06]], Loss: 0.033052187144445876\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06534838 0.12833045 0.13159499], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.10842460553239412\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22082003 0.11309053 0.04527482], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.1263951268179032\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17205593 0.04893356 0.24377199], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.1549204916848491\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.130358   0.12616093 0.21547766], LR: [[6.95759652988216e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.15733219524379818\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16698898 0.09374706 0.00338728], LR: [[6.2618368768939444e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.08804110528193027\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04395777 0.04294149 0.02462388], LR: [[6.2618368768939444e-06], [1.3091945352131578e-05], [8.58962534553353e-06]], Loss: 0.037174376901239155\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0725865  0.05543053 0.00725155], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [8.58962534553353e-06]], Loss: 0.04508952391489099\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02083629 0.02046376 0.1359606 ], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [8.58962534553353e-06]], Loss: 0.05908688355993944\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07640145 0.01740199 0.15542868], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [7.730662810980177e-06]], Loss: 0.08307737172232009\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04748135 0.08198257 0.15892619], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [7.730662810980177e-06]], Loss: 0.09613003875187132\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.00745077 0.01597989 0.04270189], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [7.730662810980177e-06]], Loss: 0.022044183453544974\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11421975 0.08346607 0.02037224], LR: [[6.2618368768939444e-06], [1.178275081691842e-05], [7.730662810980177e-06]], Loss: 0.07268601895154765\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12680991 0.10414156 0.18749091], LR: [[5.6356531892045504e-06], [1.178275081691842e-05], [7.730662810980177e-06]], Loss: 0.1394807934388518\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04678357 0.15671671 0.24552506], LR: [[5.6356531892045504e-06], [1.0604475735226578e-05], [7.730662810980177e-06]], Loss: 0.1496751122510371\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1879996  0.07043729 0.10710018], LR: [[5.6356531892045504e-06], [1.0604475735226578e-05], [7.730662810980177e-06]], Loss: 0.12184569018737723\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.062991   0.04623147 0.11072732], LR: [[5.6356531892045504e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.07331659550468127\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07322392 0.09924987 0.04752953], LR: [[5.6356531892045504e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.07333443796262144\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09569882 0.04286499 0.15101135], LR: [[5.6356531892045504e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.09652505524262474\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11424865 0.08539215 0.24605204], LR: [[5.072087870284095e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.14856428005407604\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03739424 0.01911247 0.18853312], LR: [[5.072087870284095e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.0816799456917215\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0312728  0.00224574 0.12228767], LR: [[5.072087870284095e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.05193540034000762\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12183553 0.04355219 0.02410881], LR: [[5.072087870284095e-06], [1.0604475735226578e-05], [6.95759652988216e-06]], Loss: 0.0631655058908897\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2226145  0.10515415 0.13441429], LR: [[5.072087870284095e-06], [9.544028161703921e-06], [6.95759652988216e-06]], Loss: 0.1540609831735492\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2701532  0.13104903 0.02025136], LR: [[5.072087870284095e-06], [9.544028161703921e-06], [6.95759652988216e-06]], Loss: 0.14048452714535717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1187747  0.09775559 0.13084887], LR: [[5.072087870284095e-06], [9.544028161703921e-06], [6.2618368768939444e-06]], Loss: 0.11579304979338001\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15394945 0.00642363 0.00452233], LR: [[4.564879083255686e-06], [9.544028161703921e-06], [6.2618368768939444e-06]], Loss: 0.054965137244046974\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12054791 0.08673257 0.11282401], LR: [[4.564879083255686e-06], [9.544028161703921e-06], [6.2618368768939444e-06]], Loss: 0.10670149852521717\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13993748 0.01987984 0.13328887], LR: [[4.564879083255686e-06], [9.544028161703921e-06], [6.2618368768939444e-06]], Loss: 0.09770206197553004\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08909306 0.0403044  0.1494556 ], LR: [[4.564879083255686e-06], [9.544028161703921e-06], [6.2618368768939444e-06]], Loss: 0.0929510162761532\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05984871 0.05953691 0.19856474], LR: [[4.564879083255686e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.10598345163588722\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26899712 0.13885589 0.11549988], LR: [[4.564879083255686e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.17445096589780104\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18434108 0.08373842 0.08444029], LR: [[4.564879083255686e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.11750659790510933\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20072954 0.12496758 0.15611031], LR: [[4.564879083255686e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.16060247699419658\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02980643 0.02273403 0.1643386 ], LR: [[4.564879083255686e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.07229302280582488\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09003457 0.1067743  0.13851522], LR: [[4.1083911749301174e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.11177469456878801\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11396273 0.05670233 0.05292322], LR: [[4.1083911749301174e-06], [8.58962534553353e-06], [5.6356531892045504e-06]], Loss: 0.07452942866713176\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07598847 0.06629923 0.1808012 ], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.6356531892045504e-06]], Loss: 0.10769629714079203\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02578599 0.04253669 0.04797313], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.6356531892045504e-06]], Loss: 0.03876526947812333\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11553288 0.0473329  0.13666165], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.072087870284095e-06]], Loss: 0.09984247740047673\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21599036 0.08264658 0.09586354], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.072087870284095e-06]], Loss: 0.13150016291998326\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2043399  0.06320649 0.3143485 ], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.072087870284095e-06]], Loss: 0.1939649648824707\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10407971 0.14737496 0.05812312], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.072087870284095e-06]], Loss: 0.10319259689965594\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09120162 0.02251794 0.03903644], LR: [[4.1083911749301174e-06], [7.730662810980177e-06], [5.072087870284095e-06]], Loss: 0.050918667339719836\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11838259 0.1142261  0.00193915], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.07818261458926525\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10468039 0.04024135 0.17487921], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.1066003141916978\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13148826 0.02122897 0.02801567], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.060244300247480474\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08066136 0.1479473  0.14585669], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.1248217834128688\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04479631 0.07746503 0.1164411 ], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.07956748237057278\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05577646 0.02629942 0.09646024], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.05951203993676851\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01583381 0.0359529  0.01453569], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.022107464875443836\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13150396 0.01783369 0.00061299], LR: [[3.697552057437106e-06], [6.95759652988216e-06], [5.072087870284095e-06]], Loss: 0.04998354975755016\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13450326 0.09146872 0.18704573], LR: [[3.3277968516933954e-06], [6.95759652988216e-06], [4.564879083255686e-06]], Loss: 0.13767257087553542\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19872329 0.02166428 0.13796093], LR: [[3.3277968516933954e-06], [6.95759652988216e-06], [4.564879083255686e-06]], Loss: 0.1194494977343129\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20998129 0.08034407 0.02056103], LR: [[3.3277968516933954e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.10362879929016344\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19404588 0.02382889 0.04576019], LR: [[3.3277968516933954e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.08787831996257107\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15763946 0.13039438 0.04494299], LR: [[3.3277968516933954e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.11099227736393609\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18330452 0.03351453 0.00706747], LR: [[3.3277968516933954e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.07462884185370057\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01612915 0.01396339 0.03232968], LR: [[3.3277968516933954e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.020807410075018806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10113078 0.06362472 0.16931519], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.11135689565601448\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05088378 0.00383324 0.16571747], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.0734781640364478\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.227082   0.15946738 0.05063016], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.14572651057550803\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15150908 0.07829575 0.02203074], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.564879083255686e-06]], Loss: 0.08394518791659115\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1983015  0.03899558 0.15734694], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.1083911749301174e-06]], Loss: 0.13154800574605663\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14066203 0.03664456 0.0555688 ], LR: [[2.995017166524056e-06], [6.2618368768939444e-06], [4.1083911749301174e-06]], Loss: 0.07762512969978465\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18494294 0.04316126 0.12473326], LR: [[2.995017166524056e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.11761248704325529\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04212915 0.0258969  0.14882363], LR: [[2.995017166524056e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.0722832251060754\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17474741 0.10947148 0.09549254], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.12657047955493908\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08161961 0.10441603 0.00124414], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.06242659357589825\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06061241 0.0634384  0.20213123], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.10872734581527765\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04535001 0.0378388  0.02088048], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [4.1083911749301174e-06]], Loss: 0.03468976241691659\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19220096 0.10569048 0.07416386], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [3.697552057437106e-06]], Loss: 0.12401843401448182\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09164438 0.0962737  0.14947355], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [3.697552057437106e-06]], Loss: 0.11246387556893751\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2090539  0.03374422 0.02381812], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [3.697552057437106e-06]], Loss: 0.08887208343638726\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12565612 0.015313   0.10840264], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [3.697552057437106e-06]], Loss: 0.08312391909770668\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08855291 0.08193746 0.12152791], LR: [[2.69551544987165e-06], [5.6356531892045504e-06], [3.697552057437106e-06]], Loss: 0.09733942476964634\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25132406 0.14578447 0.05818771], LR: [[2.69551544987165e-06], [5.072087870284095e-06], [3.697552057437106e-06]], Loss: 0.15176541705518806\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2817454  0.13013916 0.05632439], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.697552057437106e-06]], Loss: 0.1560696500702761\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10700121 0.06115851 0.13316914], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.1004429538951566\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22664955 0.02076302 0.12923086], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.12554780741144592\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16466678 0.09246305 0.02046175], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.09253052514550897\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19021032 0.00341415 0.07044098], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.08802181826972326\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13078997 0.10423451 0.00085338], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.07862595467440163\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02082836 0.02217497 0.17463382], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.07254571911995299\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0258742  0.04727815 0.09198531], LR: [[2.425963904884485e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.055045886940715716\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16195424 0.00289742 0.04446848], LR: [[2.1833675143960364e-06], [5.072087870284095e-06], [3.3277968516933954e-06]], Loss: 0.06977337824374748\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0232263  0.14176847 0.02404315], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [3.3277968516933954e-06]], Loss: 0.06301263834427422\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05778358 0.06746126 0.10407796], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [3.3277968516933954e-06]], Loss: 0.07644093263583879\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2373712  0.07227581 0.06902312], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [3.3277968516933954e-06]], Loss: 0.12622337564011105\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09816181 0.05008603 0.06398227], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [3.3277968516933954e-06]], Loss: 0.07074336983030662\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02249813 0.07674726 0.06574946], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [2.995017166524056e-06]], Loss: 0.054998284967150535\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02557554 0.04587557 0.02040305], LR: [[2.1833675143960364e-06], [4.564879083255686e-06], [2.995017166524056e-06]], Loss: 0.030618049988212687\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22519138 0.02482111 0.17373047], LR: [[1.965030762956433e-06], [4.564879083255686e-06], [2.995017166524056e-06]], Loss: 0.14124765129585284\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01428456 0.02640958 0.00096265], LR: [[1.965030762956433e-06], [4.564879083255686e-06], [2.995017166524056e-06]], Loss: 0.013885594855067516\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17400318 0.05965725 0.20727764], LR: [[1.965030762956433e-06], [4.1083911749301174e-06], [2.995017166524056e-06]], Loss: 0.14697935529906925\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18223516 0.06668945 0.04058575], LR: [[1.965030762956433e-06], [4.1083911749301174e-06], [2.995017166524056e-06]], Loss: 0.09650345685193314\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19211372 0.12723016 0.10815125], LR: [[1.965030762956433e-06], [4.1083911749301174e-06], [2.995017166524056e-06]], Loss: 0.1424983758215482\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01762521 0.01658323 0.04455655], LR: [[1.965030762956433e-06], [4.1083911749301174e-06], [2.995017166524056e-06]], Loss: 0.026254995188986264\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04072349 0.05362842 0.0580423 ], LR: [[1.7685276866607898e-06], [4.1083911749301174e-06], [2.69551544987165e-06]], Loss: 0.050798070367576054\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10152719 0.00051782 0.04408496], LR: [[1.7685276866607898e-06], [4.1083911749301174e-06], [2.69551544987165e-06]], Loss: 0.048709991937503215\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.19197975 0.15784015 0.12576224], LR: [[1.7685276866607898e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.1585273791066235\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12809099 0.02210695 0.02249987], LR: [[1.7685276866607898e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.057565936780107824\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15218574 0.01419217 0.17611101], LR: [[1.7685276866607898e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.11416297322197351\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24075616 0.01486478 0.02592174], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.09384755770035554\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22490814 0.04628961 0.18574164], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.15231313023716211\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.29777028 0.06282105 0.16675526], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.1757821956851209\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02095631 0.02254256 0.0292841 ], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.024260991448148462\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.11166049 0.01799144 0.00192742], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.69551544987165e-06]], Loss: 0.04385978405286248\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17323259 0.00577403 0.10188224], LR: [[1.591674917994711e-06], [3.697552057437106e-06], [2.425963904884485e-06]], Loss: 0.09362961979718724\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08809516 0.08169525 0.18108483], LR: [[1.591674917994711e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.11695841277639073\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02581847 0.04382796 0.02115471], LR: [[1.591674917994711e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.030267046458320696\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25868262 0.08812128 0.04967619], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.13216002974551277\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08551492 0.04562653 0.        ], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.04371381593480086\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13102379 0.10041555 0.1529563 ], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.12813188054598867\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13108333 0.02094888 0.05921481], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.07041567449535553\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.08291563 0.00096075 0.00017226], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.425963904884485e-06]], Loss: 0.02801621283947801\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06861775 0.08015169 0.08398141], LR: [[1.43250742619524e-06], [3.3277968516933954e-06], [2.1833675143960364e-06]], Loss: 0.07758361864058923\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.17188484 0.15001982 0.08372125], LR: [[1.43250742619524e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.135208635797729\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07047243 0.02051311 0.07179763], LR: [[1.43250742619524e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.05426105317465651\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.090959   0.04168414 0.10211798], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.07825370905416397\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06388051 0.03721506 0.03514158], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.04541238190795411\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25016845 0.16087382 0.06      ], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.15701408903812988\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13502348 0.06188435 0.06015088], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.0856862366492957\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2144262  0.04461286 0.02386734], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.09430213371446977\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.05380548 0.08750093 0.01421729], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [2.1833675143960364e-06]], Loss: 0.051841233576027046\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06617539 0.00474924 0.12574997], LR: [[1.289256683575716e-06], [2.995017166524056e-06], [1.965030762956433e-06]], Loss: 0.06555819877578567\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21304039 0.04861967 0.14265123], LR: [[1.1603310152181443e-06], [2.69551544987165e-06], [1.965030762956433e-06]], Loss: 0.1347704325352485\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04425207 0.05894751 0.08594762], LR: [[1.1603310152181443e-06], [2.69551544987165e-06], [1.965030762956433e-06]], Loss: 0.0630490649753483\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04182846 0.108004   0.04397287], LR: [[1.1603310152181443e-06], [2.69551544987165e-06], [1.965030762956433e-06]], Loss: 0.06460177580670765\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10840173 0.01539944 0.05089847], LR: [[1.1603310152181443e-06], [2.69551544987165e-06], [1.965030762956433e-06]], Loss: 0.05823321238082523\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02355925 0.03340384 0.12873272], LR: [[1.1603310152181443e-06], [2.69551544987165e-06], [1.965030762956433e-06]], Loss: 0.061898600218895206\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10287684 0.09253061 0.04123985], LR: [[1.1603310152181443e-06], [2.425963904884485e-06], [1.965030762956433e-06]], Loss: 0.0788824315648526\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02924095 0.03503181 0.08958044], LR: [[1.1603310152181443e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.05128440196975135\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.22860306 0.0680941  0.02025589], LR: [[1.1603310152181443e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.10565101760051525\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04385161 0.08572279 0.06149928], LR: [[1.1603310152181443e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.06369122823700309\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.27708523 0.03734051 0.04452866], LR: [[1.04429791369633e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.11965146698406898\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.15207548 0.02556729 0.02135319], LR: [[1.04429791369633e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.06633198499291514\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04348814 0.04521614 0.18713146], LR: [[1.04429791369633e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.09194524687870094\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13530453 0.04053436 0.0400554 ], LR: [[1.04429791369633e-06], [2.425963904884485e-06], [1.7685276866607898e-06]], Loss: 0.07196476295202349\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10995502 0.08672297 0.02012032], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.7685276866607898e-06]], Loss: 0.07226610104708621\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26255747 0.15084833 0.06364666], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.7685276866607898e-06]], Loss: 0.15901748367158386\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1431092  0.013504   0.00054564], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.7685276866607898e-06]], Loss: 0.05238627783522437\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.20391057 0.03506597 0.00024859], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.7685276866607898e-06]], Loss: 0.07974171021667037\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.18329362 0.05027216 0.12890056], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.591674917994711e-06]], Loss: 0.1208221122546456\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0318661 0.0337025 0.02     ], LR: [[1.04429791369633e-06], [2.1833675143960364e-06], [1.591674917994711e-06]], Loss: 0.028522867136246837\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.10479436 0.00108638 0.02443184], LR: [[9.39868122326697e-07], [2.1833675143960364e-06], [1.591674917994711e-06]], Loss: 0.04343752522487194\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.32263207 0.06301503 0.17574796], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.591674917994711e-06]], Loss: 0.18713168828806373\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03798232 0.03973565 0.02020912], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.591674917994711e-06]], Loss: 0.032642364637771\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1225077  0.04550861 0.02003551], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.591674917994711e-06]], Loss: 0.06268393967401305\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1811044 0.0200937 0.0854492], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.591674917994711e-06]], Loss: 0.09554910211211487\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03445579 0.08563211 0.02782481], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.591674917994711e-06]], Loss: 0.04930423457728466\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02371411 0.04344298 0.22243602], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.0965310362279221\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.00940591 0.03444627 0.00035625], LR: [[9.39868122326697e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.014736142557424803\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16060413 0.02798262 0.0295941 ], LR: [[8.458813100940273e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.072726949856927\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.21682709 0.00410065 0.10007154], LR: [[8.458813100940273e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.10699975695072983\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04484211 0.08523821 0.02860323], LR: [[8.458813100940273e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.0528945145336911\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12130696 0.06       0.17287418], LR: [[8.458813100940273e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.11806038125418128\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.03238596 0.02       0.02      ], LR: [[8.458813100940273e-07], [1.965030762956433e-06], [1.43250742619524e-06]], Loss: 0.024128651980621123\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07432186 0.02373764 0.22148608], LR: [[8.458813100940273e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.10651519416132942\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02917242 0.01675966 0.23009882], LR: [[8.458813100940273e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.09201029905673447\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.00187987 0.08220775 0.1114162 ], LR: [[8.458813100940273e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.0651679388138776\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12926357 0.03471593 0.17255259], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.11217736209315869\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [1.02068513e-01 1.52725221e-04 2.00009295e-01], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.10074351136184607\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.2202184  0.06014671 0.12480104], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.13505538498284295\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.09843318 0.05712753 0.02911763], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.289256683575716e-06]], Loss: 0.06155944845561559\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16976327 0.0454534  0.14700369], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.1603310152181443e-06]], Loss: 0.1207401206078551\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14147852 0.02039553 0.02029477], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.1603310152181443e-06]], Loss: 0.06072293926185618\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.12257371 0.00346006 0.00054919], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.1603310152181443e-06]], Loss: 0.04219432190312849\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.02336254 0.02       0.02727672], LR: [[7.612931790846246e-07], [1.7685276866607898e-06], [1.1603310152181443e-06]], Loss: 0.023546419881361847\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.25408526 0.070993   0.02051991], LR: [[7.612931790846246e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.11519939074215169\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.01279114 0.00071329 0.01953396], LR: [[7.612931790846246e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.011012794464671363\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.0401322  0.04985465 0.16980427], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.08659703940153123\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04423237 0.05604367 0.07909269], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.059789579625551904\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.26362431 0.05423047 0.11900381], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.1456195303638621\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14533538 0.05087285 0.10715259], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.1603310152181443e-06]], Loss: 0.10112027101102285\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.16454686 0.04008107 0.11666074], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.04429791369633e-06]], Loss: 0.10709622169379145\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04038283 0.03646013 0.00682806], LR: [[6.851638611761621e-07], [1.591674917994711e-06], [1.04429791369633e-06]], Loss: 0.027890338112677757\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.13334183 0.02624264 0.04238071], LR: [[6.166474750585459e-07], [1.591674917994711e-06], [1.04429791369633e-06]], Loss: 0.06732172667805571\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07593644 0.04480953 0.03558713], LR: [[6.166474750585459e-07], [1.591674917994711e-06], [1.04429791369633e-06]], Loss: 0.05211103383839751\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.07821662 0.         0.02864504], LR: [[6.166474750585459e-07], [1.591674917994711e-06], [1.04429791369633e-06]], Loss: 0.0356205520479125\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1724067  0.0796397  0.16071022], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [1.04429791369633e-06]], Loss: 0.13758553738628201\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.24623403 0.0467114  0.03216689], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [1.04429791369633e-06]], Loss: 0.1083707686366203\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.14100888 0.03475632 0.02045975], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [1.04429791369633e-06]], Loss: 0.06540831764626394\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.1062206  0.04864687 0.06200707], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [1.04429791369633e-06]], Loss: 0.07229150996310636\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.06561073 0.         0.01841707], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [1.04429791369633e-06]], Loss: 0.02800926552464565\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.04599999 0.11228952 0.11869078], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [9.39868122326697e-07]], Loss: 0.09232676494924817\n",
      "Unsupervised Training.. 0.0\n",
      "Unsupervised Training.. 10.0\n",
      "Unsupervised Training.. 20.0\n",
      "Unsupervised Training.. 30.0\n",
      "Unsupervised Training.. 40.0\n",
      "Unsupervised Training.. 50.0\n",
      "Unsupervised Training.. 60.0\n",
      "Unsupervised Training.. 70.0\n",
      "Unsupervised Training.. 80.0\n",
      "Unsupervised Training.. 90.0\n",
      "Losses: [0.00924122 0.00363525 0.00058917], LR: [[6.166474750585459e-07], [1.43250742619524e-06], [9.39868122326697e-07]], Loss: 0.004488549557281659\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "classification_set = {\n",
    "    0 : [],\n",
    "    1 : [],\n",
    "    2 : []\n",
    "}\n",
    "\n",
    "PRETRAINING = True\n",
    "target = 0.01\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=3, output_size=5, lr_series=[15e-4, 15e-4, 15e-4], learning_decay=0.9, decay_step=4, threshold=6.0, weight_decay=1e-4)\n",
    "ensemble.load_ensemble(\"toy-surgery\")\n",
    "sampled_dataset = SwarmDataset(\"data/toy\", rank=0)\n",
    "data = sampled_dataset\n",
    "\n",
    "# Separate\n",
    "for i in range(len(sampled_dataset)):\n",
    "    _class = sampled_dataset[i][1][0]\n",
    "    classification_set[_class].append(i)\n",
    "\n",
    "# Pair Up\n",
    "SAMPLES = 3000\n",
    "triplets = []\n",
    "for i in range(SAMPLES):\n",
    "    classA = random.randint(0, 2)\n",
    "    classB = random.randint(0, 2)\n",
    "\n",
    "    anchor = random.choice(classification_set[classA])\n",
    "    positive = random.choice(classification_set[classA])\n",
    "    negative = random.choice(classification_set[classB])\n",
    "    triplet = [anchor, positive, negative]\n",
    "    if triplet not in triplets:\n",
    "        triplets.append(triplet)\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 5\n",
    "EPOCH_DATA_LIM = 500\n",
    "while loss > target:\n",
    "    total_updates = 0\n",
    "    total_loss = np.array([0.0 for i in range(len(ensemble.ensemble))])\n",
    "    random.shuffle(triplets)\n",
    "    temp_triplets = triplets[:EPOCH_DATA_LIM]\n",
    "    for i in range(0, len(temp_triplets), BATCH_SIZE):\n",
    "        if total_updates % 10 == 0:\n",
    "            print(f\"Unsupervised Training.. {(total_updates * BATCH_SIZE * 100) / len(temp_triplets)}\")\n",
    "\n",
    "        if i + BATCH_SIZE > len(triplets):\n",
    "            break\n",
    "\n",
    "        anchors = np.array([data[temp_triplets[i + j][0]][0] for j in range(BATCH_SIZE)])\n",
    "        positives = np.array([data[temp_triplets[i + j][1]][0] for j in range(BATCH_SIZE)])\n",
    "        negatives = np.array([data[temp_triplets[i + j][2]][0] for j in range(BATCH_SIZE)])\n",
    "\n",
    "        anchors = np.expand_dims(anchors, axis=1)\n",
    "        positives = np.expand_dims(positives, axis=1)\n",
    "        negatives = np.expand_dims(negatives, axis=1)\n",
    "\n",
    "        losses = ensemble.train_batch(anchors, positives, negatives)\n",
    "        total_loss += losses\n",
    "        total_updates += 1\n",
    "\n",
    "    l = total_loss / total_updates\n",
    "    lr = ensemble.evaluate_lr(l)\n",
    "    loss = sum(l) / len(l)\n",
    "    print(f\"Losses: {l}, LR: {lr}, Loss: {loss}\")\n",
    "\n",
    "print(\"Complete!\")\n",
    "# ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "ensemble.save_ensemble(f\"{int(time.time())}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Embeddings with Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from data.swarmset import ContinuingDataset, SwarmDataset\n",
    "from networks.embedding import NoveltyEmbedding\n",
    "from networks.archive import DataAggregationArchive\n",
    "from networks.ensemble import Ensemble\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "PRETRAINING = True\n",
    "ENSEMBLE_MEMBER = 0\n",
    "target = 0.01\n",
    "loss = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ensemble = Ensemble(size=1, output_size=5, lr_series=[15e-4], learning_decay=0.7, decay_step=1, threshold=9.0, weight_decay=1e-4, new_model=True)\n",
    "ensemble.load_ensemble(\"full-mini-SIMCLR-3\")\n",
    "# ensemble.load_ensemble(\"full-mini-HIL\")\n",
    "# ensemble.load_ensemble(\"tiny-toy-C\")\n",
    "# ensemble.load_ensemble(\"toy-HIL-forced\")\n",
    "ensemble.eval_mode()\n",
    "sampled_dataset = SwarmDataset(\"data/full-mini\", rank=0)\n",
    "data = sampled_dataset\n",
    "\n",
    "embeddings = []\n",
    "classes = []\n",
    "# for i in range(len(data)):\n",
    "for i in range(1000):\n",
    "    image, _class = sampled_dataset[i][0], sampled_dataset[i][1][0]\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    embed = ensemble.ensemble[ENSEMBLE_MEMBER].forward(torch.tensor(image, device=device, dtype=torch.float))\n",
    "    embed = embed.detach().cpu().squeeze(dim=0).numpy()\n",
    "    embeddings.append(embed)\n",
    "    classes.append(_class)\n",
    "\n",
    "embeddings = np.array(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/Desktop/research/SwarmNoveltyNetwork/.env/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reduced = TSNE(\n",
    "    n_components=2,\n",
    "    learning_rate=\"auto\",\n",
    "    init=\"pca\",\n",
    "    perplexity=40,\n",
    "    early_exaggeration=1\n",
    ").fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7f73c0174fd0>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import os\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list\n",
    "\n",
    "color_classes = {\n",
    "    -1: [0.33, 0.33, 0.33],\n",
    "    0: [1, 0, 0],\n",
    "    1: [0, 1, 0],\n",
    "    2: [0, 0, 1],\n",
    "    3: [0, 1, 1], # Cyan\n",
    "    4: [1, 1, 0], # Yellow\n",
    "    5: [0.5, 0, 0.25] # Pink\n",
    "}\n",
    "\n",
    "label_classes = {\n",
    "    -1: \"Unlabeled\",\n",
    "    0: \"Random\",\n",
    "    1: \"Cyclic Pursuit\",\n",
    "    2: \"Milling\",\n",
    "    3: \"Aggregation\",\n",
    "    4: \"Dispersal\",\n",
    "    5: \"Wall Following\"\n",
    "}\n",
    "\n",
    "lim = len(reduced)\n",
    "classes = [-1 for i in range(lim)]\n",
    "\n",
    "OUT = \"data/oracle\"\n",
    "with open(os.path.join(OUT, \"original-hand-labeled-classes.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "x = [reduced[i][0] for i in range(lim)]\n",
    "y = [reduced[i][1] for i in range(lim)]\n",
    "colors = [color_classes[classes[i]] for i in range(lim)]\n",
    "labels = [label_classes[classes[i]] for i in range(lim)]\n",
    "plot.grid(True)\n",
    "# plot.xlim(-5000, 20000)\n",
    "# plot.ylim(-15000, 10000)\n",
    "plot.scatter(x, y, c=colors)\n",
    "plot.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x7f9c8cfff490>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def CSVLineToVec(line):\n",
    "    line_list = line.strip().replace(\"\\n\", \"\").split(\",\")\n",
    "    float_list = []\n",
    "    for i in line_list:\n",
    "        float_list.append(float(i))\n",
    "    float_list = np.array(float_list)\n",
    "    return float_list\n",
    "\n",
    "color_classes = {\n",
    "    0: [1, 0, 0],\n",
    "    1: [0, 1, 0],\n",
    "    2: [0, 0, 1],\n",
    "}\n",
    "\n",
    "label_classes = {\n",
    "    0: \"Circles\",\n",
    "    1: \"Triangles\",\n",
    "    2: \"Squares\",\n",
    "}\n",
    "\n",
    "triples = []\n",
    "ensemble.eval_mode()\n",
    "OUT = \"data/toy-oracle\"\n",
    "with open(os.path.join(OUT, \"triplets.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        triples.append([int(triplet[0]), int(triplet[1]), int(triplet[2])])\n",
    "\n",
    "target_triplet = triples[13]\n",
    "lim = 500\n",
    "x = [reduced[i][0] for i in range(lim)]\n",
    "y = [reduced[i][1] for i in range(lim)]\n",
    "colors = [color_classes[classes[i]] for i in range(lim)]\n",
    "labels = [label_classes[classes[i]] for i in range(lim)]\n",
    "\n",
    "# colors[target_triplet[0]] = [0, 0, 0]\n",
    "# colors[target_triplet[1]] = [0, 0, 0]\n",
    "# colors[target_triplet[2]] = [0.2, 0, 0]\n",
    "\n",
    "plot.grid(True)\n",
    "plot.scatter(x, y, c=colors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connor/Desktop/research/SwarmNoveltyNetwork/.env/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reduced = TSNE(\n",
    "    n_components=3,\n",
    "    learning_rate=\"auto\",\n",
    "    init=\"pca\",\n",
    "    perplexity=200,\n",
    "    early_exaggeration=1\n",
    ").fit_transform(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_classes = {\n",
    "    -1: [0.33, 0.33, 0.33],\n",
    "    0: [1, 0, 0],\n",
    "    1: [0, 1, 0],\n",
    "    2: [0, 0, 1],\n",
    "    3: [0, 1, 1], # Cyan\n",
    "    4: [1, 1, 0], # Yellow\n",
    "    5: [0.5, 0, 0.25], # Pink\n",
    "    6: [0, 0, 0]\n",
    "}\n",
    "\n",
    "label_classes = {\n",
    "    -1: \"Unlabeled\",\n",
    "    0: \"Random\",\n",
    "    1: \"Cyclic Pursuit\",\n",
    "    2: \"Milling\",\n",
    "    3: \"Aggregation\",\n",
    "    4: \"Dispersal\",\n",
    "    5: \"Wall Following\",\n",
    "    6: \"Special\"\n",
    "}\n",
    "\n",
    "classes = [-1 for i in range(lim)]\n",
    "with open(os.path.join(OUT, \"original-hand-labeled-classes.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        triplet = CSVLineToVec(line)\n",
    "        classes[int(triplet[0])] = int(triplet[1])\n",
    "\n",
    "lim = len(reduced)\n",
    "RANDOM = 0\n",
    "x = [reduced[i][0] for i in range(lim) if classes[i] != RANDOM]\n",
    "y = [reduced[i][1] for i in range(lim) if classes[i] != RANDOM]\n",
    "z = [reduced[i][2] for i in range(lim) if classes[i] != RANDOM]\n",
    "colors = [color_classes[classes[i]] for i in range(lim)  if classes[i] != RANDOM]\n",
    "# labels = [label_classes[classes[i]] for i in range(lim)  if classes[i] != RANDOM]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x, y, z, c=colors)\n",
    "# ax.set_xlim(-200, 175)\n",
    "# ax.set_ylim(-50, 400)\n",
    "# ax.set_zlim(-2, 2)\n",
    "ax.set_title(\"Learned Embedding Space (User-Led Pretraining Only)\")\n",
    "ax.set_xlabel(\"t-SNE X Projection\")\n",
    "ax.set_ylabel(\"t-SNE Y Projection\")\n",
    "ax.set_zlabel(\"t-SNE Z Projection\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
